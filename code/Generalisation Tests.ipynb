{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.565410199556541\n",
      "0.43458980044345896\n",
      "0.8870290465631929\n",
      "0.014066962305986697\n",
      "0.8872042128603104\n",
      "0.01276629711751663\n"
     ]
    }
   ],
   "source": [
    "alpha = 255.0/(255+196)\n",
    "beta = 1.0 - alpha\n",
    "print(alpha)\n",
    "print(beta)\n",
    "\n",
    "#CNN\n",
    "cnn1 = 0.9427\n",
    "cnn2 = 0.8146\n",
    "print(alpha * cnn1 + beta * cnn2)\n",
    "dsv_cnn1 = 0.0082\n",
    "dsv_cnn2 = 0.0217\n",
    "print(alpha * dsv_cnn1 + beta * dsv_cnn2)\n",
    "\n",
    "\n",
    "#RF\n",
    "rf1 = 0.9261\n",
    "rf2 = 0.8366\n",
    "print(alpha * rf1 + beta * rf2)\n",
    "dsv_rf1 = 0.0152\n",
    "dsv_rf2 = 0.0096\n",
    "print(alpha * dsv_rf1 + beta * dsv_rf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Brayan\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "2.0.8\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'known' train, 'unknown' test - Best CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10320, 3, 12, 11)\n",
      "(485, 3, 12, 11)\n"
     ]
    }
   ],
   "source": [
    "train_tactile_images = np.load('images-known-t7-cero2mean-stdnorm-3d.npy')\n",
    "train_labels = np.load('labels-known-t7-cero2mean-stdnorm-3d.npy')\n",
    "\n",
    "test_tactile_images = np.load('images-unknown-t7-cero2mean-stdnorm-3d.npy')\n",
    "test_labels = np.load('labels-unknown-t7-cero2mean-stdnorm-3d.npy')\n",
    "\n",
    "FINGERS = 3\n",
    "TACTILE_IMAGE_ROWS = 12\n",
    "TACTILE_IMAGE_COLS = 11\n",
    "\n",
    "train_labels_cat = np_utils.to_categorical(train_labels, num_classes=2)\n",
    "test_labels_cat = np_utils.to_categorical(test_labels, num_classes=2)\n",
    "\n",
    "print(train_tactile_images.shape)\n",
    "print(test_tactile_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/10\n",
      "Epoch 1/300\n",
      "2064/2064 [==============================] - 1s - loss: 14.0601 - acc: 0.8542     \n",
      "Epoch 2/300\n",
      "2064/2064 [==============================] - 0s - loss: 11.5612 - acc: 0.9036     \n",
      "Epoch 3/300\n",
      "2064/2064 [==============================] - 0s - loss: 9.9372 - acc: 0.9172     \n",
      "Epoch 4/300\n",
      "2064/2064 [==============================] - 0s - loss: 8.7771 - acc: 0.9273     \n",
      "Epoch 5/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.9054 - acc: 0.9419     \n",
      "Epoch 6/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.2133 - acc: 0.9530     \n",
      "Epoch 7/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.6621 - acc: 0.9540     \n",
      "Epoch 8/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.2209 - acc: 0.9491     \n",
      "Epoch 9/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.8375 - acc: 0.9603     \n",
      "Epoch 10/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.5166 - acc: 0.9608     \n",
      "Epoch 11/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.2440 - acc: 0.9622     \n",
      "Epoch 12/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.9986 - acc: 0.9632     \n",
      "Epoch 13/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.7844 - acc: 0.9651     \n",
      "Epoch 14/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.5981 - acc: 0.9646     \n",
      "Epoch 15/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.4228 - acc: 0.9680     \n",
      "Epoch 16/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.2765 - acc: 0.9700     \n",
      "Epoch 17/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.1327 - acc: 0.9743     \n",
      "Epoch 18/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.0088 - acc: 0.9748     \n",
      "Epoch 19/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.8917 - acc: 0.9792     \n",
      "Epoch 20/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.7858 - acc: 0.9811     \n",
      "Epoch 21/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.6881 - acc: 0.9782     \n",
      "Epoch 22/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.6060 - acc: 0.9758     \n",
      "Epoch 23/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.5244 - acc: 0.9724     \n",
      "Epoch 24/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.4369 - acc: 0.9806     \n",
      "Epoch 25/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.3629 - acc: 0.9840     \n",
      "Epoch 26/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2996 - acc: 0.9835     \n",
      "Epoch 27/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2313 - acc: 0.9830     \n",
      "Epoch 28/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1748 - acc: 0.9806     \n",
      "Epoch 29/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1213 - acc: 0.9811     \n",
      "Epoch 30/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0605 - acc: 0.9840     \n",
      "Epoch 31/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0090 - acc: 0.9859     \n",
      "Epoch 32/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9554 - acc: 0.9884     \n",
      "Epoch 33/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9146 - acc: 0.9845     \n",
      "Epoch 34/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8682 - acc: 0.9869     \n",
      "Epoch 35/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8246 - acc: 0.9903     \n",
      "Epoch 36/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7888 - acc: 0.9826     \n",
      "Epoch 37/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7515 - acc: 0.9855     \n",
      "Epoch 38/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7223 - acc: 0.9797     \n",
      "Epoch 39/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6791 - acc: 0.9855     \n",
      "Epoch 40/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6464 - acc: 0.9864     \n",
      "Epoch 41/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6128 - acc: 0.9869     \n",
      "Epoch 42/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5828 - acc: 0.9864     \n",
      "Epoch 43/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5480 - acc: 0.9908     \n",
      "Epoch 44/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5239 - acc: 0.9879     \n",
      "Epoch 45/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4987 - acc: 0.9859     \n",
      "Epoch 46/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4707 - acc: 0.9889     \n",
      "Epoch 47/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4342 - acc: 0.9932     \n",
      "Epoch 48/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4205 - acc: 0.9874     \n",
      "Epoch 49/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3941 - acc: 0.9884     \n",
      "Epoch 50/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3670 - acc: 0.9913     \n",
      "Epoch 51/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3462 - acc: 0.9908     \n",
      "Epoch 52/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3187 - acc: 0.9927     \n",
      "Epoch 53/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3010 - acc: 0.9898     \n",
      "Epoch 54/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2805 - acc: 0.9913     \n",
      "Epoch 55/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2610 - acc: 0.9898     \n",
      "Epoch 56/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2431 - acc: 0.9913     \n",
      "Epoch 57/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2220 - acc: 0.9922     \n",
      "Epoch 58/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2077 - acc: 0.9898     \n",
      "Epoch 59/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1873 - acc: 0.9908     \n",
      "Epoch 60/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1708 - acc: 0.9908     \n",
      "Epoch 61/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1570 - acc: 0.9864     \n",
      "Epoch 62/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1350 - acc: 0.9898     \n",
      "Epoch 63/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1220 - acc: 0.9889     \n",
      "Epoch 64/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1012 - acc: 0.9922     \n",
      "Epoch 65/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0836 - acc: 0.9942     \n",
      "Epoch 66/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0755 - acc: 0.9908     \n",
      "Epoch 67/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0582 - acc: 0.9942     \n",
      "Epoch 68/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0416 - acc: 0.9932     \n",
      "Epoch 69/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0264 - acc: 0.9956     \n",
      "Epoch 70/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0164 - acc: 0.9918     \n",
      "Epoch 71/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0009 - acc: 0.9952     \n",
      "Epoch 72/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9887 - acc: 0.9942     \n",
      "Epoch 73/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9772 - acc: 0.9903     \n",
      "Epoch 74/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9646 - acc: 0.9961     \n",
      "Epoch 75/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9551 - acc: 0.9922     \n",
      "Epoch 76/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9383 - acc: 0.9937     \n",
      "Epoch 77/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9253 - acc: 0.9947     \n",
      "Epoch 78/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9154 - acc: 0.9932     \n",
      "Epoch 79/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9041 - acc: 0.9932     \n",
      "Epoch 80/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8951 - acc: 0.9927     \n",
      "Epoch 81/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8833 - acc: 0.9927     \n",
      "Epoch 82/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8728 - acc: 0.9952     \n",
      "Epoch 83/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8596 - acc: 0.9942     \n",
      "Epoch 84/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8509 - acc: 0.9952     \n",
      "Epoch 85/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8405 - acc: 0.9947     \n",
      "Epoch 86/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8314 - acc: 0.9937     \n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 1.8185 - acc: 0.9942     \n",
      "Epoch 88/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8090 - acc: 0.9952     \n",
      "Epoch 89/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7993 - acc: 0.9947     \n",
      "Epoch 90/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7926 - acc: 0.9942     \n",
      "Epoch 91/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7816 - acc: 0.9961     \n",
      "Epoch 92/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7692 - acc: 0.9952     \n",
      "Epoch 93/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7630 - acc: 0.9956     \n",
      "Epoch 94/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7573 - acc: 0.9932     \n",
      "Epoch 95/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7462 - acc: 0.9952     \n",
      "Epoch 96/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7391 - acc: 0.9927     \n",
      "Epoch 97/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7292 - acc: 0.9947     \n",
      "Epoch 98/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7213 - acc: 0.9956     \n",
      "Epoch 99/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7151 - acc: 0.9942     \n",
      "Epoch 100/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7065 - acc: 0.9952     \n",
      "Epoch 101/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7050 - acc: 0.9893     \n",
      "Epoch 102/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6889 - acc: 0.9966     \n",
      "Epoch 103/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6814 - acc: 0.9956     \n",
      "Epoch 104/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6733 - acc: 0.9956     \n",
      "Epoch 105/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6661 - acc: 0.9961     \n",
      "Epoch 106/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6616 - acc: 0.9942     \n",
      "Epoch 107/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6553 - acc: 0.9947     \n",
      "Epoch 108/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6466 - acc: 0.9952     \n",
      "Epoch 109/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6364 - acc: 0.9981     \n",
      "Epoch 110/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6339 - acc: 0.9961     \n",
      "Epoch 111/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6251 - acc: 0.9971     \n",
      "Epoch 112/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6223 - acc: 0.9942     \n",
      "Epoch 113/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6111 - acc: 0.9966     \n",
      "Epoch 114/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6065 - acc: 0.9961     \n",
      "Epoch 115/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6020 - acc: 0.9966     \n",
      "Epoch 116/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5936 - acc: 0.9956     \n",
      "Epoch 117/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5863 - acc: 0.9966     \n",
      "Epoch 118/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5831 - acc: 0.9971     \n",
      "Epoch 119/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5754 - acc: 0.9952     \n",
      "Epoch 120/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5681 - acc: 0.9971     \n",
      "Epoch 121/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5641 - acc: 0.9956     \n",
      "Epoch 122/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5567 - acc: 0.9956     \n",
      "Epoch 123/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5500 - acc: 0.9966     \n",
      "Epoch 124/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5418 - acc: 0.9981     \n",
      "Epoch 125/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5400 - acc: 0.9961     \n",
      "Epoch 126/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5373 - acc: 0.9937     \n",
      "Epoch 127/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5313 - acc: 0.9961     \n",
      "Epoch 128/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5239 - acc: 0.9971     \n",
      "Epoch 129/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5178 - acc: 0.9961     \n",
      "Epoch 130/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5117 - acc: 0.9966     \n",
      "Epoch 131/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5082 - acc: 0.9961     \n",
      "Epoch 132/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5045 - acc: 0.9952     \n",
      "Epoch 133/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4991 - acc: 0.9971     \n",
      "Epoch 134/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4910 - acc: 0.9971     \n",
      "Epoch 135/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4864 - acc: 0.9971     \n",
      "Epoch 136/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4829 - acc: 0.9971     \n",
      "Epoch 137/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4791 - acc: 0.9976     \n",
      "Epoch 138/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4714 - acc: 0.9966     \n",
      "Epoch 139/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4705 - acc: 0.9966     \n",
      "Epoch 140/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4624 - acc: 0.9956     \n",
      "Epoch 141/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4576 - acc: 0.9976     \n",
      "Epoch 142/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4556 - acc: 0.9952     \n",
      "Epoch 143/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4487 - acc: 0.9971     \n",
      "Epoch 144/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4453 - acc: 0.9952     \n",
      "Epoch 145/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4418 - acc: 0.9956     \n",
      "Epoch 146/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4353 - acc: 0.9966     \n",
      "Epoch 147/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4296 - acc: 0.9981     \n",
      "Epoch 148/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4276 - acc: 0.9961     \n",
      "Epoch 149/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4262 - acc: 0.9947     \n",
      "Epoch 150/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4190 - acc: 0.9942     \n",
      "Epoch 151/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4159 - acc: 0.9976     \n",
      "Epoch 152/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4094 - acc: 0.9966     \n",
      "Epoch 153/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4050 - acc: 0.9971     \n",
      "Epoch 154/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4026 - acc: 0.9971     \n",
      "Epoch 155/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3965 - acc: 0.9971     \n",
      "Epoch 156/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3958 - acc: 0.9971     \n",
      "Epoch 157/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3922 - acc: 0.9952     \n",
      "Epoch 158/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3834 - acc: 0.9981     \n",
      "Epoch 159/300\n",
      "2064/2064 [==============================] - ETA: 0s - loss: 1.3809 - acc: 0.998 - 0s - loss: 1.3808 - acc: 0.9981     \n",
      "Epoch 160/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3772 - acc: 0.9966     \n",
      "Epoch 161/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3788 - acc: 0.9952     \n",
      "Epoch 162/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3694 - acc: 0.9981     \n",
      "Epoch 163/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3692 - acc: 0.9947     \n",
      "Epoch 164/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3618 - acc: 0.9976     \n",
      "Epoch 165/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3555 - acc: 0.9985     \n",
      "Epoch 166/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3550 - acc: 0.9976     \n",
      "Epoch 167/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3526 - acc: 0.9961     \n",
      "Epoch 168/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3520 - acc: 0.9966     \n",
      "Epoch 169/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3435 - acc: 0.9976     \n",
      "Epoch 170/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3423 - acc: 0.9971     \n",
      "Epoch 171/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3366 - acc: 0.9976     \n",
      "Epoch 172/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3381 - acc: 0.9952     \n",
      "Epoch 173/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3287 - acc: 0.9981     \n",
      "Epoch 174/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3241 - acc: 0.9976     \n",
      "Epoch 175/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3271 - acc: 0.9952     \n",
      "Epoch 176/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3237 - acc: 0.9966     \n",
      "Epoch 177/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3152 - acc: 0.9981     \n",
      "Epoch 178/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3141 - acc: 0.9966     \n",
      "Epoch 179/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3153 - acc: 0.9966     \n",
      "Epoch 180/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3073 - acc: 0.9971     \n",
      "Epoch 181/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3032 - acc: 0.9981     \n",
      "Epoch 182/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3002 - acc: 0.9981     \n",
      "Epoch 183/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2991 - acc: 0.9976     \n",
      "Epoch 184/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2936 - acc: 0.9981     \n",
      "Epoch 185/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2897 - acc: 0.9966     \n",
      "Epoch 186/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2912 - acc: 0.9956     \n",
      "Epoch 187/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2851 - acc: 0.9981     \n",
      "Epoch 188/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2856 - acc: 0.9981     \n",
      "Epoch 189/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2824 - acc: 0.9966     \n",
      "Epoch 190/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2769 - acc: 0.9985     \n",
      "Epoch 191/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2704 - acc: 0.9985     \n",
      "Epoch 192/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2741 - acc: 0.9971     \n",
      "Epoch 193/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2716 - acc: 0.9971     \n",
      "Epoch 194/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2667 - acc: 0.9976     \n",
      "Epoch 195/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2593 - acc: 0.9985     \n",
      "Epoch 196/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2579 - acc: 0.9985     \n",
      "Epoch 197/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2575 - acc: 0.9971     \n",
      "Epoch 198/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2545 - acc: 0.9971     \n",
      "Epoch 199/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2516 - acc: 0.9985     \n",
      "Epoch 200/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2525 - acc: 0.9961     \n",
      "Epoch 201/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2430 - acc: 0.9981     \n",
      "Epoch 202/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2420 - acc: 0.9981     \n",
      "Epoch 203/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2387 - acc: 0.9985     \n",
      "Epoch 204/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2356 - acc: 0.9985     \n",
      "Epoch 205/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2335 - acc: 0.9981     \n",
      "Epoch 206/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2331 - acc: 0.9981     \n",
      "Epoch 207/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2286 - acc: 0.9985     \n",
      "Epoch 208/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2286 - acc: 0.9985     \n",
      "Epoch 209/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2217 - acc: 0.9981     \n",
      "Epoch 210/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2201 - acc: 0.9976     \n",
      "Epoch 211/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2216 - acc: 0.9961     \n",
      "Epoch 212/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2173 - acc: 0.9981     \n",
      "Epoch 213/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2173 - acc: 0.9956     \n",
      "Epoch 214/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2113 - acc: 0.9981     \n",
      "Epoch 215/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2063 - acc: 0.9985     \n",
      "Epoch 216/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2052 - acc: 0.9976     \n",
      "Epoch 217/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2031 - acc: 0.9981     \n",
      "Epoch 218/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2027 - acc: 0.9961     \n",
      "Epoch 219/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2005 - acc: 0.9976     \n",
      "Epoch 220/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1992 - acc: 0.9952     \n",
      "Epoch 221/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1961 - acc: 0.9981     \n",
      "Epoch 222/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1887 - acc: 0.9981     \n",
      "Epoch 223/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1875 - acc: 0.9981     \n",
      "Epoch 224/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1853 - acc: 0.9985     \n",
      "Epoch 225/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1838 - acc: 0.9981     \n",
      "Epoch 226/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1795 - acc: 0.9985     \n",
      "Epoch 227/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1820 - acc: 0.9976     \n",
      "Epoch 228/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1784 - acc: 0.9976     \n",
      "Epoch 229/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1772 - acc: 0.9966     \n",
      "Epoch 230/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1758 - acc: 0.9976     \n",
      "Epoch 231/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1691 - acc: 0.9985     \n",
      "Epoch 232/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1671 - acc: 0.9981     \n",
      "Epoch 233/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1675 - acc: 0.9956     \n",
      "Epoch 234/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1635 - acc: 0.9976     \n",
      "Epoch 235/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1612 - acc: 0.9985     \n",
      "Epoch 236/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1624 - acc: 0.9976     \n",
      "Epoch 237/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1580 - acc: 0.9971     \n",
      "Epoch 238/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1541 - acc: 0.9990     \n",
      "Epoch 239/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1534 - acc: 0.9985     \n",
      "Epoch 240/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1540 - acc: 0.9981     \n",
      "Epoch 241/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1548 - acc: 0.9981     \n",
      "Epoch 242/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1489 - acc: 0.9976     \n",
      "Epoch 243/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1460 - acc: 0.9971     \n",
      "Epoch 244/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1414 - acc: 0.9981     \n",
      "Epoch 245/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1416 - acc: 0.9981     \n",
      "Epoch 246/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1405 - acc: 0.9981     \n",
      "Epoch 247/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1383 - acc: 0.9976     \n",
      "Epoch 248/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1333 - acc: 0.9981     \n",
      "Epoch 249/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1357 - acc: 0.9971     \n",
      "Epoch 250/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1303 - acc: 0.9985     \n",
      "Epoch 251/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1308 - acc: 0.9976     \n",
      "Epoch 252/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1267 - acc: 0.9985     \n",
      "Epoch 253/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1274 - acc: 0.9971     \n",
      "Epoch 254/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1229 - acc: 0.9985     \n",
      "Epoch 255/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1202 - acc: 0.9990     \n",
      "Epoch 256/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1196 - acc: 0.9981     \n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 1.1173 - acc: 0.9981     \n",
      "Epoch 258/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1158 - acc: 0.9976     \n",
      "Epoch 259/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1154 - acc: 0.9981     \n",
      "Epoch 260/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1140 - acc: 0.9981     \n",
      "Epoch 261/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1126 - acc: 0.9971     \n",
      "Epoch 262/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1086 - acc: 0.9990     \n",
      "Epoch 263/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1064 - acc: 0.9985     \n",
      "Epoch 264/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1073 - acc: 0.9971     \n",
      "Epoch 265/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1016 - acc: 0.9995     \n",
      "Epoch 266/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0984 - acc: 0.9985     \n",
      "Epoch 267/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0977 - acc: 0.9990     \n",
      "Epoch 268/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0984 - acc: 0.9985     \n",
      "Epoch 269/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0951 - acc: 0.9990     \n",
      "Epoch 270/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0932 - acc: 0.9981     \n",
      "Epoch 271/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0904 - acc: 0.9990     \n",
      "Epoch 272/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0901 - acc: 0.9985     \n",
      "Epoch 273/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0904 - acc: 0.9976     \n",
      "Epoch 274/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0865 - acc: 0.9981     \n",
      "Epoch 275/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0864 - acc: 0.9976     \n",
      "Epoch 276/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0819 - acc: 0.9990     \n",
      "Epoch 277/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0840 - acc: 0.9981     \n",
      "Epoch 278/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0803 - acc: 0.9990     \n",
      "Epoch 279/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0767 - acc: 0.9985     \n",
      "Epoch 280/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0775 - acc: 0.9981     \n",
      "Epoch 281/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0754 - acc: 0.9981     \n",
      "Epoch 282/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0763 - acc: 0.9985     \n",
      "Epoch 283/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0721 - acc: 0.9985     \n",
      "Epoch 284/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0700 - acc: 0.9981     \n",
      "Epoch 285/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0673 - acc: 0.9981     \n",
      "Epoch 286/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0667 - acc: 0.9981     \n",
      "Epoch 287/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0669 - acc: 0.9981     \n",
      "Epoch 288/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0644 - acc: 0.9990     \n",
      "Epoch 289/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0629 - acc: 0.9971     \n",
      "Epoch 290/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0653 - acc: 0.9961     \n",
      "Epoch 291/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0575 - acc: 0.9990     \n",
      "Epoch 292/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0590 - acc: 0.9985     \n",
      "Epoch 293/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0548 - acc: 0.9985     \n",
      "Epoch 294/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0529 - acc: 0.9985     \n",
      "Epoch 295/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0532 - acc: 0.9985     \n",
      "Epoch 296/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0507 - acc: 0.9981     \n",
      "Epoch 297/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0472 - acc: 0.9990     \n",
      "Epoch 298/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0493 - acc: 0.9976     \n",
      "Epoch 299/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0457 - acc: 0.9985     \n",
      "Epoch 300/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0461 - acc: 0.9985     \n",
      "# # # Evaluating cv-fold...\n",
      "485/485 [==============================] - 0s     \n",
      "\n",
      "accuracy: 88.24742269270199\n",
      "precision: 87.91666666666667\n",
      "recall: 88.28451882845188\n",
      "f1_score: 88.10020876826722\n",
      "Training fold 2/10\n",
      "Epoch 1/300\n",
      "2064/2064 [==============================] - 1s - loss: 13.9851 - acc: 0.8493     \n",
      "Epoch 2/300\n",
      "2064/2064 [==============================] - 0s - loss: 11.4347 - acc: 0.9084     \n",
      "Epoch 3/300\n",
      "2064/2064 [==============================] - 0s - loss: 9.7657 - acc: 0.9205     \n",
      "Epoch 4/300\n",
      "2064/2064 [==============================] - 0s - loss: 8.5749 - acc: 0.9414     \n",
      "Epoch 5/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.6924 - acc: 0.9423     \n",
      "Epoch 6/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.9945 - acc: 0.9511     \n",
      "Epoch 7/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.4362 - acc: 0.9549     \n",
      "Epoch 8/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.0010 - acc: 0.9530     \n",
      "Epoch 9/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.6085 - acc: 0.9627     \n",
      "Epoch 10/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.2883 - acc: 0.9671     \n",
      "Epoch 11/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.0148 - acc: 0.9627     \n",
      "Epoch 12/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.7843 - acc: 0.9651     \n",
      "Epoch 13/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.5648 - acc: 0.9685     \n",
      "Epoch 14/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.3723 - acc: 0.9763     \n",
      "Epoch 15/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.2090 - acc: 0.9714     \n",
      "Epoch 16/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.0580 - acc: 0.9797     \n",
      "Epoch 17/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.9264 - acc: 0.9734     \n",
      "Epoch 18/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.7965 - acc: 0.9816     \n",
      "Epoch 19/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.6967 - acc: 0.9729     \n",
      "Epoch 20/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.5862 - acc: 0.9782     \n",
      "Epoch 21/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.4888 - acc: 0.9826     \n",
      "Epoch 22/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.3971 - acc: 0.9835     \n",
      "Epoch 23/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.3242 - acc: 0.9782     \n",
      "Epoch 24/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2539 - acc: 0.9792     \n",
      "Epoch 25/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1812 - acc: 0.9782     \n",
      "Epoch 26/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1057 - acc: 0.9850     \n",
      "Epoch 27/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0390 - acc: 0.9884     \n",
      "Epoch 28/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9880 - acc: 0.9830     \n",
      "Epoch 29/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9387 - acc: 0.9835     \n",
      "Epoch 30/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8812 - acc: 0.9869     \n",
      "Epoch 31/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8309 - acc: 0.9869     \n",
      "Epoch 32/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7927 - acc: 0.9821     \n",
      "Epoch 33/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7394 - acc: 0.9869     \n",
      "Epoch 34/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6944 - acc: 0.9879     \n",
      "Epoch 35/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6567 - acc: 0.9840     \n",
      "Epoch 36/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6224 - acc: 0.9898     \n",
      "Epoch 37/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5836 - acc: 0.9884     \n",
      "Epoch 38/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5497 - acc: 0.9869     \n",
      "Epoch 39/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5133 - acc: 0.9893     \n",
      "Epoch 40/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4819 - acc: 0.9893     \n",
      "Epoch 41/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4519 - acc: 0.9864     \n",
      "Epoch 42/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4201 - acc: 0.9918     \n",
      "Epoch 43/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3983 - acc: 0.9884     \n",
      "Epoch 44/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3708 - acc: 0.9893     \n",
      "Epoch 45/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3396 - acc: 0.9893     \n",
      "Epoch 46/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3178 - acc: 0.9889     \n",
      "Epoch 47/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2889 - acc: 0.9913     \n",
      "Epoch 48/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2654 - acc: 0.9927     \n",
      "Epoch 49/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2468 - acc: 0.9913     \n",
      "Epoch 50/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2183 - acc: 0.9937     \n",
      "Epoch 51/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1991 - acc: 0.9918     \n",
      "Epoch 52/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1780 - acc: 0.9942     \n",
      "Epoch 53/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1549 - acc: 0.9947     \n",
      "Epoch 54/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1371 - acc: 0.9913     \n",
      "Epoch 55/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1178 - acc: 0.9913     \n",
      "Epoch 56/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1002 - acc: 0.9908     \n",
      "Epoch 57/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0862 - acc: 0.9898     \n",
      "Epoch 58/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0601 - acc: 0.9922     \n",
      "Epoch 59/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0449 - acc: 0.9932     \n",
      "Epoch 60/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0318 - acc: 0.9889     \n",
      "Epoch 61/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0128 - acc: 0.9932     \n",
      "Epoch 62/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9966 - acc: 0.9918     \n",
      "Epoch 63/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9855 - acc: 0.9908     \n",
      "Epoch 64/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9650 - acc: 0.9942     \n",
      "Epoch 65/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9491 - acc: 0.9947     \n",
      "Epoch 66/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9405 - acc: 0.9937     \n",
      "Epoch 67/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9207 - acc: 0.9956     \n",
      "Epoch 68/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9064 - acc: 0.9942     - ETA: 0s - loss: 1.9180 - a\n",
      "Epoch 69/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8967 - acc: 0.9947     \n",
      "Epoch 70/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8801 - acc: 0.9966     \n",
      "Epoch 71/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8722 - acc: 0.9918     \n",
      "Epoch 72/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8595 - acc: 0.9942     \n",
      "Epoch 73/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8472 - acc: 0.9927     \n",
      "Epoch 74/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8313 - acc: 0.9952     \n",
      "Epoch 75/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8228 - acc: 0.9932     \n",
      "Epoch 76/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8071 - acc: 0.9956     \n",
      "Epoch 77/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8034 - acc: 0.9903     \n",
      "Epoch 78/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7902 - acc: 0.9947     \n",
      "Epoch 79/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7765 - acc: 0.9947     \n",
      "Epoch 80/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7735 - acc: 0.9918     \n",
      "Epoch 81/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7521 - acc: 0.9961     \n",
      "Epoch 82/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7468 - acc: 0.9937     \n",
      "Epoch 83/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7354 - acc: 0.9952     \n",
      "Epoch 84/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7285 - acc: 0.9932     \n",
      "Epoch 85/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7201 - acc: 0.9932     \n",
      "Epoch 86/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7104 - acc: 0.9932     \n",
      "Epoch 87/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6997 - acc: 0.9956     \n",
      "Epoch 88/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6883 - acc: 0.9971     \n",
      "Epoch 89/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6792 - acc: 0.9961     \n",
      "Epoch 90/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6702 - acc: 0.9966     \n",
      "Epoch 91/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6616 - acc: 0.9956     \n",
      "Epoch 92/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6579 - acc: 0.9947     \n",
      "Epoch 93/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6493 - acc: 0.9947     \n",
      "Epoch 94/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6392 - acc: 0.9971     \n",
      "Epoch 95/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6293 - acc: 0.9947     \n",
      "Epoch 96/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6247 - acc: 0.9942     \n",
      "Epoch 97/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6167 - acc: 0.9922     \n",
      "Epoch 98/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6065 - acc: 0.9956     \n",
      "Epoch 99/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6000 - acc: 0.9976     \n",
      "Epoch 100/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5871 - acc: 0.9981     \n",
      "Epoch 101/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5825 - acc: 0.9961     \n",
      "Epoch 102/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5779 - acc: 0.9947     \n",
      "Epoch 103/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5703 - acc: 0.9956     \n",
      "Epoch 104/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5627 - acc: 0.9961     \n",
      "Epoch 105/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5569 - acc: 0.9956     \n",
      "Epoch 106/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5518 - acc: 0.9937     \n",
      "Epoch 107/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5440 - acc: 0.9961     \n",
      "Epoch 108/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5352 - acc: 0.9985     \n",
      "Epoch 109/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5256 - acc: 0.9976     \n",
      "Epoch 110/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5304 - acc: 0.9898     \n",
      "Epoch 111/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5155 - acc: 0.9976     \n",
      "Epoch 112/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5090 - acc: 0.9956     \n",
      "Epoch 113/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5044 - acc: 0.9952     \n",
      "Epoch 114/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4975 - acc: 0.9956     \n",
      "Epoch 115/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4926 - acc: 0.9956     \n",
      "Epoch 116/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4867 - acc: 0.9971     \n",
      "Epoch 117/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4760 - acc: 0.9981     \n",
      "Epoch 118/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4757 - acc: 0.9956     \n",
      "Epoch 119/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4657 - acc: 0.9976     \n",
      "Epoch 120/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4632 - acc: 0.9956     \n",
      "Epoch 121/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4552 - acc: 0.9976     \n",
      "Epoch 122/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4512 - acc: 0.9981     \n",
      "Epoch 123/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4443 - acc: 0.9971     \n",
      "Epoch 124/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4410 - acc: 0.9961     \n",
      "Epoch 125/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 1.4354 - acc: 0.9971     \n",
      "Epoch 126/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4287 - acc: 0.9981     \n",
      "Epoch 127/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4205 - acc: 0.9971     \n",
      "Epoch 128/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4180 - acc: 0.9952     \n",
      "Epoch 129/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4140 - acc: 0.9961     \n",
      "Epoch 130/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4108 - acc: 0.9956     \n",
      "Epoch 131/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4071 - acc: 0.9956     \n",
      "Epoch 132/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3983 - acc: 0.9966     \n",
      "Epoch 133/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3903 - acc: 0.9981     \n",
      "Epoch 134/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3899 - acc: 0.9956     \n",
      "Epoch 135/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3865 - acc: 0.9956     \n",
      "Epoch 136/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3798 - acc: 0.9976     \n",
      "Epoch 137/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3754 - acc: 0.9971     \n",
      "Epoch 138/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3702 - acc: 0.9981     \n",
      "Epoch 139/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3658 - acc: 0.9976     \n",
      "Epoch 140/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3639 - acc: 0.9966     \n",
      "Epoch 141/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3552 - acc: 0.9971     \n",
      "Epoch 142/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3496 - acc: 0.9981     \n",
      "Epoch 143/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3499 - acc: 0.9971     \n",
      "Epoch 144/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3434 - acc: 0.9971     \n",
      "Epoch 145/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3439 - acc: 0.9966     \n",
      "Epoch 146/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3379 - acc: 0.9966     \n",
      "Epoch 147/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3314 - acc: 0.9966     \n",
      "Epoch 148/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3255 - acc: 0.9981     \n",
      "Epoch 149/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3237 - acc: 0.9971     \n",
      "Epoch 150/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3172 - acc: 0.9981     \n",
      "Epoch 151/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3151 - acc: 0.9966     \n",
      "Epoch 152/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3090 - acc: 0.9971     \n",
      "Epoch 153/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3062 - acc: 0.9985     \n",
      "Epoch 154/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3021 - acc: 0.9985     \n",
      "Epoch 155/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2973 - acc: 0.9981     \n",
      "Epoch 156/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2911 - acc: 0.9985     \n",
      "Epoch 157/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2890 - acc: 0.9985     \n",
      "Epoch 158/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2876 - acc: 0.9971     \n",
      "Epoch 159/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2853 - acc: 0.9961     \n",
      "Epoch 160/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2790 - acc: 0.9981     \n",
      "Epoch 161/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2745 - acc: 0.9971     \n",
      "Epoch 162/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2710 - acc: 0.9981     \n",
      "Epoch 163/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2659 - acc: 0.9985     \n",
      "Epoch 164/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2646 - acc: 0.9966     \n",
      "Epoch 165/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2619 - acc: 0.9981     \n",
      "Epoch 166/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2565 - acc: 0.9981     \n",
      "Epoch 167/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2542 - acc: 0.9981     \n",
      "Epoch 168/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2488 - acc: 0.9976     \n",
      "Epoch 169/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2461 - acc: 0.9971     \n",
      "Epoch 170/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2402 - acc: 0.9990     \n",
      "Epoch 171/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2431 - acc: 0.9971     \n",
      "Epoch 172/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2390 - acc: 0.9961     \n",
      "Epoch 173/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2340 - acc: 0.9966     \n",
      "Epoch 174/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2334 - acc: 0.9971     \n",
      "Epoch 175/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2295 - acc: 0.9952     \n",
      "Epoch 176/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2238 - acc: 0.9971     \n",
      "Epoch 177/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2201 - acc: 0.9990     \n",
      "Epoch 178/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2179 - acc: 0.9976     \n",
      "Epoch 179/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2147 - acc: 0.9981     \n",
      "Epoch 180/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2181 - acc: 0.9952     \n",
      "Epoch 181/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2089 - acc: 0.9981     \n",
      "Epoch 182/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2047 - acc: 0.9990     \n",
      "Epoch 183/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2026 - acc: 0.9976     \n",
      "Epoch 184/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1986 - acc: 0.9985     \n",
      "Epoch 185/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1951 - acc: 0.9985     \n",
      "Epoch 186/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1938 - acc: 0.9985     \n",
      "Epoch 187/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1923 - acc: 0.9976     \n",
      "Epoch 188/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1859 - acc: 0.9976     \n",
      "Epoch 189/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1847 - acc: 0.9981     \n",
      "Epoch 190/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1853 - acc: 0.9966     \n",
      "Epoch 191/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1790 - acc: 0.9985     \n",
      "Epoch 192/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1771 - acc: 0.9981     \n",
      "Epoch 193/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1728 - acc: 0.9985     \n",
      "Epoch 194/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1715 - acc: 0.9981     \n",
      "Epoch 195/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1697 - acc: 0.9985     \n",
      "Epoch 196/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1652 - acc: 0.9976     \n",
      "Epoch 197/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1631 - acc: 0.9985     \n",
      "Epoch 198/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1607 - acc: 0.9976     \n",
      "Epoch 199/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1578 - acc: 0.9976     \n",
      "Epoch 200/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1569 - acc: 0.9971     \n",
      "Epoch 201/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1485 - acc: 0.9990     \n",
      "Epoch 202/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1518 - acc: 0.9971     \n",
      "Epoch 203/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1471 - acc: 0.9971     \n",
      "Epoch 204/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1438 - acc: 0.9976     \n",
      "Epoch 205/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1431 - acc: 0.9971     \n",
      "Epoch 206/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1399 - acc: 0.9976     \n",
      "Epoch 207/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1385 - acc: 0.9976     \n",
      "Epoch 208/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1351 - acc: 0.9976     \n",
      "Epoch 209/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1316 - acc: 0.9985     \n",
      "Epoch 210/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1291 - acc: 0.9976     \n",
      "Epoch 211/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1258 - acc: 0.9990     \n",
      "Epoch 212/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1250 - acc: 0.9971     \n",
      "Epoch 213/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1216 - acc: 0.9985     \n",
      "Epoch 214/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1247 - acc: 0.9961     \n",
      "Epoch 215/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1234 - acc: 0.9961     \n",
      "Epoch 216/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1153 - acc: 0.9985     \n",
      "Epoch 217/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1118 - acc: 0.9985     \n",
      "Epoch 218/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1136 - acc: 0.9971     \n",
      "Epoch 219/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1114 - acc: 0.9976     \n",
      "Epoch 220/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1064 - acc: 0.9981     \n",
      "Epoch 221/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1038 - acc: 0.9985     \n",
      "Epoch 222/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1017 - acc: 0.9985     \n",
      "Epoch 223/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1020 - acc: 0.9976     \n",
      "Epoch 224/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0978 - acc: 0.9981     \n",
      "Epoch 225/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0972 - acc: 0.9971     \n",
      "Epoch 226/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0936 - acc: 0.9981     \n",
      "Epoch 227/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0894 - acc: 0.9990     \n",
      "Epoch 228/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0875 - acc: 0.9981     \n",
      "Epoch 229/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0869 - acc: 0.9990     \n",
      "Epoch 230/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0846 - acc: 0.9985     \n",
      "Epoch 231/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0831 - acc: 0.9976     \n",
      "Epoch 232/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0809 - acc: 0.9985     \n",
      "Epoch 233/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0769 - acc: 0.9985     \n",
      "Epoch 234/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0788 - acc: 0.9971     \n",
      "Epoch 235/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0750 - acc: 0.9976     \n",
      "Epoch 236/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0721 - acc: 0.9985     \n",
      "Epoch 237/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0715 - acc: 0.9976     \n",
      "Epoch 238/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0685 - acc: 0.9990     \n",
      "Epoch 239/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0697 - acc: 0.9971     \n",
      "Epoch 240/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0628 - acc: 0.9981     \n",
      "Epoch 241/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0644 - acc: 0.9981     \n",
      "Epoch 242/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0607 - acc: 0.9976     \n",
      "Epoch 243/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0593 - acc: 0.9981     \n",
      "Epoch 244/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0570 - acc: 0.9985     \n",
      "Epoch 245/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0574 - acc: 0.9981     \n",
      "Epoch 246/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0528 - acc: 0.9985     \n",
      "Epoch 247/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0517 - acc: 0.9981     \n",
      "Epoch 248/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0499 - acc: 0.9985     \n",
      "Epoch 249/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0457 - acc: 0.9985     \n",
      "Epoch 250/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0447 - acc: 0.9990     \n",
      "Epoch 251/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0420 - acc: 0.9990     \n",
      "Epoch 252/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0398 - acc: 0.9985     \n",
      "Epoch 253/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0399 - acc: 0.9971     \n",
      "Epoch 254/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0386 - acc: 0.9985     \n",
      "Epoch 255/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0355 - acc: 0.9990     \n",
      "Epoch 256/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0375 - acc: 0.9976     \n",
      "Epoch 257/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0340 - acc: 0.9971     \n",
      "Epoch 258/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0282 - acc: 0.9990     \n",
      "Epoch 259/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0306 - acc: 0.9981     \n",
      "Epoch 260/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0269 - acc: 0.9990     \n",
      "Epoch 261/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0243 - acc: 0.9990     \n",
      "Epoch 262/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0248 - acc: 0.9985     \n",
      "Epoch 263/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0236 - acc: 0.9981     \n",
      "Epoch 264/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0185 - acc: 0.9985     \n",
      "Epoch 265/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0182 - acc: 0.9990     \n",
      "Epoch 266/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0159 - acc: 0.9981     \n",
      "Epoch 267/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0184 - acc: 0.9966     \n",
      "Epoch 268/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0133 - acc: 0.9981     \n",
      "Epoch 269/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0117 - acc: 0.9990     \n",
      "Epoch 270/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0077 - acc: 0.9985     \n",
      "Epoch 271/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0074 - acc: 0.9990     \n",
      "Epoch 272/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0042 - acc: 0.9990     \n",
      "Epoch 273/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0064 - acc: 0.9985     \n",
      "Epoch 274/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0029 - acc: 0.9990     \n",
      "Epoch 275/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0015 - acc: 0.9981     \n",
      "Epoch 276/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9992 - acc: 0.9981     \n",
      "Epoch 277/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9977 - acc: 0.9985     \n",
      "Epoch 278/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9941 - acc: 0.9995     \n",
      "Epoch 279/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9979 - acc: 0.9981     \n",
      "Epoch 280/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9904 - acc: 0.9985     \n",
      "Epoch 281/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9894 - acc: 0.9990     \n",
      "Epoch 282/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9881 - acc: 0.9990     \n",
      "Epoch 283/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9884 - acc: 0.9990     \n",
      "Epoch 284/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9867 - acc: 0.9985     \n",
      "Epoch 285/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9839 - acc: 0.9990     \n",
      "Epoch 286/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9831 - acc: 0.9985     \n",
      "Epoch 287/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9849 - acc: 0.9985     \n",
      "Epoch 288/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9810 - acc: 0.9981     \n",
      "Epoch 289/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9781 - acc: 0.9985     \n",
      "Epoch 290/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9775 - acc: 0.9985     \n",
      "Epoch 291/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9766 - acc: 0.9985     \n",
      "Epoch 292/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9733 - acc: 0.9990     \n",
      "Epoch 293/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9735 - acc: 0.9985     \n",
      "Epoch 294/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9716 - acc: 0.9981     \n",
      "Epoch 295/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 0.9682 - acc: 0.9990     \n",
      "Epoch 296/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9694 - acc: 0.9990     \n",
      "Epoch 297/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9663 - acc: 0.9985     \n",
      "Epoch 298/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9666 - acc: 0.9981     \n",
      "Epoch 299/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9637 - acc: 0.9985     \n",
      "Epoch 300/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9652 - acc: 0.9981     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 3s\n",
      "accuracy: 87.83505155868137\n",
      "precision: 89.47368421052632\n",
      "recall: 85.35564853556485\n",
      "f1_score: 87.36616702355462\n",
      "Training fold 3/10\n",
      "Epoch 1/300\n",
      "2064/2064 [==============================] - 1s - loss: 14.0985 - acc: 0.8498     \n",
      "Epoch 2/300\n",
      "2064/2064 [==============================] - 0s - loss: 11.5922 - acc: 0.9031     \n",
      "Epoch 3/300\n",
      "2064/2064 [==============================] - 0s - loss: 9.9369 - acc: 0.9220     \n",
      "Epoch 4/300\n",
      "2064/2064 [==============================] - 0s - loss: 8.7686 - acc: 0.9307     \n",
      "Epoch 5/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.8838 - acc: 0.9414     \n",
      "Epoch 6/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.1923 - acc: 0.9457     \n",
      "Epoch 7/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.6435 - acc: 0.9511     \n",
      "Epoch 8/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.1952 - acc: 0.9554     \n",
      "Epoch 9/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.8121 - acc: 0.9574     \n",
      "Epoch 10/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.4986 - acc: 0.9583     \n",
      "Epoch 11/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.2215 - acc: 0.9612     \n",
      "Epoch 12/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.9762 - acc: 0.9695     \n",
      "Epoch 13/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.7643 - acc: 0.9656     \n",
      "Epoch 14/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.5790 - acc: 0.9787     \n",
      "Epoch 15/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.4125 - acc: 0.9709     \n",
      "Epoch 16/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.2598 - acc: 0.9704     \n",
      "Epoch 17/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.1218 - acc: 0.9704     \n",
      "Epoch 18/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.9987 - acc: 0.9743     \n",
      "Epoch 19/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.8855 - acc: 0.9767     \n",
      "Epoch 20/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.7728 - acc: 0.9787     \n",
      "Epoch 21/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.6890 - acc: 0.9758     \n",
      "Epoch 22/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.6028 - acc: 0.9767     \n",
      "Epoch 23/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.5059 - acc: 0.9845     \n",
      "Epoch 24/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.4325 - acc: 0.9772     \n",
      "Epoch 25/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.3608 - acc: 0.9821     \n",
      "Epoch 26/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2918 - acc: 0.9830     \n",
      "Epoch 27/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2308 - acc: 0.9816     \n",
      "Epoch 28/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1724 - acc: 0.9797     \n",
      "Epoch 29/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1121 - acc: 0.9840     \n",
      "Epoch 30/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0543 - acc: 0.9874     \n",
      "Epoch 31/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0147 - acc: 0.9782     \n",
      "Epoch 32/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9680 - acc: 0.9826     \n",
      "Epoch 33/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9210 - acc: 0.9835     \n",
      "Epoch 34/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8801 - acc: 0.9855     \n",
      "Epoch 35/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8354 - acc: 0.9889     \n",
      "Epoch 36/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7956 - acc: 0.9845     \n",
      "Epoch 37/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7532 - acc: 0.9874     \n",
      "Epoch 38/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7180 - acc: 0.9893     \n",
      "Epoch 39/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6883 - acc: 0.9869     \n",
      "Epoch 40/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6619 - acc: 0.9864     \n",
      "Epoch 41/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6233 - acc: 0.9869     \n",
      "Epoch 42/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5970 - acc: 0.9859     \n",
      "Epoch 43/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5645 - acc: 0.9879     \n",
      "Epoch 44/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5343 - acc: 0.9893     \n",
      "Epoch 45/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5114 - acc: 0.9884     \n",
      "Epoch 46/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4821 - acc: 0.9893     \n",
      "Epoch 47/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4601 - acc: 0.9879     \n",
      "Epoch 48/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4304 - acc: 0.9918     \n",
      "Epoch 49/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4078 - acc: 0.9893     \n",
      "Epoch 50/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3843 - acc: 0.9898     \n",
      "Epoch 51/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3622 - acc: 0.9879     \n",
      "Epoch 52/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3393 - acc: 0.9903     \n",
      "Epoch 53/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3165 - acc: 0.9937     \n",
      "Epoch 54/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2950 - acc: 0.9937     \n",
      "Epoch 55/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2867 - acc: 0.9879     \n",
      "Epoch 56/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2549 - acc: 0.9922     \n",
      "Epoch 57/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2388 - acc: 0.9908     \n",
      "Epoch 58/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2222 - acc: 0.9908     \n",
      "Epoch 59/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2083 - acc: 0.9908     \n",
      "Epoch 60/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1852 - acc: 0.9937     \n",
      "Epoch 61/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1695 - acc: 0.9927     \n",
      "Epoch 62/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1516 - acc: 0.9956     \n",
      "Epoch 63/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1380 - acc: 0.9918     \n",
      "Epoch 64/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1214 - acc: 0.9947     \n",
      "Epoch 65/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1084 - acc: 0.9922     \n",
      "Epoch 66/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0909 - acc: 0.9932     \n",
      "Epoch 67/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0819 - acc: 0.9898     \n",
      "Epoch 68/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0633 - acc: 0.9932     \n",
      "Epoch 69/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0482 - acc: 0.9952     \n",
      "Epoch 70/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0395 - acc: 0.9927     \n",
      "Epoch 71/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0229 - acc: 0.9937     \n",
      "Epoch 72/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0072 - acc: 0.9937     \n",
      "Epoch 73/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9944 - acc: 0.9952     \n",
      "Epoch 74/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9826 - acc: 0.9932     \n",
      "Epoch 75/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9709 - acc: 0.9947     \n",
      "Epoch 76/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9612 - acc: 0.9903     \n",
      "Epoch 77/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9468 - acc: 0.9927     \n",
      "Epoch 78/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9361 - acc: 0.9932     \n",
      "Epoch 79/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9230 - acc: 0.9956     \n",
      "Epoch 80/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9128 - acc: 0.9952     \n",
      "Epoch 81/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9011 - acc: 0.9961     \n",
      "Epoch 82/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8916 - acc: 0.9927     \n",
      "Epoch 83/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8781 - acc: 0.9976     \n",
      "Epoch 84/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8715 - acc: 0.9932     \n",
      "Epoch 85/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8588 - acc: 0.9966     \n",
      "Epoch 86/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8507 - acc: 0.9942     \n",
      "Epoch 87/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8398 - acc: 0.9956     \n",
      "Epoch 88/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8281 - acc: 0.9947     \n",
      "Epoch 89/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8178 - acc: 0.9952     \n",
      "Epoch 90/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8122 - acc: 0.9947     \n",
      "Epoch 91/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7995 - acc: 0.9952     \n",
      "Epoch 92/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7940 - acc: 0.9952     \n",
      "Epoch 93/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7887 - acc: 0.9932     \n",
      "Epoch 94/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7763 - acc: 0.9956     \n",
      "Epoch 95/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7630 - acc: 0.9961     \n",
      "Epoch 96/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7577 - acc: 0.9952     \n",
      "Epoch 97/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7492 - acc: 0.9952     \n",
      "Epoch 98/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7383 - acc: 0.9966     \n",
      "Epoch 99/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7286 - acc: 0.9971     \n",
      "Epoch 100/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7226 - acc: 0.9966     \n",
      "Epoch 101/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7156 - acc: 0.9956     \n",
      "Epoch 102/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7061 - acc: 0.9971     \n",
      "Epoch 103/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7044 - acc: 0.9947     \n",
      "Epoch 104/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6916 - acc: 0.9956     \n",
      "Epoch 105/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6859 - acc: 0.9947     \n",
      "Epoch 106/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6800 - acc: 0.9947     \n",
      "Epoch 107/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6709 - acc: 0.9961     \n",
      "Epoch 108/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6598 - acc: 0.9976     \n",
      "Epoch 109/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6523 - acc: 0.9976     \n",
      "Epoch 110/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6476 - acc: 0.9966     \n",
      "Epoch 111/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6408 - acc: 0.9966     \n",
      "Epoch 112/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6327 - acc: 0.9961     \n",
      "Epoch 113/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6276 - acc: 0.9966     \n",
      "Epoch 114/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6215 - acc: 0.9961     \n",
      "Epoch 115/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6135 - acc: 0.9961     \n",
      "Epoch 116/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6080 - acc: 0.9961     \n",
      "Epoch 117/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5997 - acc: 0.9971     \n",
      "Epoch 118/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5939 - acc: 0.9971     \n",
      "Epoch 119/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5841 - acc: 0.9976     \n",
      "Epoch 120/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5824 - acc: 0.9952     \n",
      "Epoch 121/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5742 - acc: 0.9976     \n",
      "Epoch 122/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5671 - acc: 0.9976     \n",
      "Epoch 123/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5619 - acc: 0.9961     \n",
      "Epoch 124/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5553 - acc: 0.9961     \n",
      "Epoch 125/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5500 - acc: 0.9966     \n",
      "Epoch 126/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5417 - acc: 0.9985     \n",
      "Epoch 127/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5396 - acc: 0.9956     \n",
      "Epoch 128/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5366 - acc: 0.9966     \n",
      "Epoch 129/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5282 - acc: 0.9976     \n",
      "Epoch 130/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5222 - acc: 0.9971     \n",
      "Epoch 131/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5164 - acc: 0.9971     \n",
      "Epoch 132/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5126 - acc: 0.9956     \n",
      "Epoch 133/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5060 - acc: 0.9952     \n",
      "Epoch 134/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5006 - acc: 0.9981     \n",
      "Epoch 135/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4969 - acc: 0.9971     \n",
      "Epoch 136/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4932 - acc: 0.9966     - ETA: 0s - loss: 1.4915 - a\n",
      "Epoch 137/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4864 - acc: 0.9976     \n",
      "Epoch 138/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4791 - acc: 0.9976     \n",
      "Epoch 139/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4769 - acc: 0.9971     \n",
      "Epoch 140/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4682 - acc: 0.9966     \n",
      "Epoch 141/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4654 - acc: 0.9981     \n",
      "Epoch 142/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4596 - acc: 0.9971     \n",
      "Epoch 143/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4575 - acc: 0.9966     \n",
      "Epoch 144/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4518 - acc: 0.9966     \n",
      "Epoch 145/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4456 - acc: 0.9971     \n",
      "Epoch 146/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4440 - acc: 0.9976     \n",
      "Epoch 147/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4363 - acc: 0.9990     \n",
      "Epoch 148/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4328 - acc: 0.9981     \n",
      "Epoch 149/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4284 - acc: 0.9971     \n",
      "Epoch 150/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4232 - acc: 0.9966     \n",
      "Epoch 151/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4203 - acc: 0.9981     \n",
      "Epoch 152/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4166 - acc: 0.9976     \n",
      "Epoch 153/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4132 - acc: 0.9952     \n",
      "Epoch 154/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4063 - acc: 0.9971     \n",
      "Epoch 155/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4003 - acc: 0.9981     \n",
      "Epoch 156/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3988 - acc: 0.9981     \n",
      "Epoch 157/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3930 - acc: 0.9981     \n",
      "Epoch 158/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3890 - acc: 0.9966     \n",
      "Epoch 159/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3881 - acc: 0.9952     \n",
      "Epoch 160/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3812 - acc: 0.9971     \n",
      "Epoch 161/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3799 - acc: 0.9971     \n",
      "Epoch 162/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3753 - acc: 0.9981     \n",
      "Epoch 163/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3762 - acc: 0.9956     \n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 1.3647 - acc: 0.9981     \n",
      "Epoch 165/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3635 - acc: 0.9976     \n",
      "Epoch 166/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3581 - acc: 0.9985     \n",
      "Epoch 167/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3516 - acc: 0.9981     \n",
      "Epoch 168/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3521 - acc: 0.9981     \n",
      "Epoch 169/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3472 - acc: 0.9966     \n",
      "Epoch 170/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3429 - acc: 0.9976     \n",
      "Epoch 171/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3390 - acc: 0.9981     \n",
      "Epoch 172/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3359 - acc: 0.9976     \n",
      "Epoch 173/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3336 - acc: 0.9976     \n",
      "Epoch 174/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3255 - acc: 0.9985     \n",
      "Epoch 175/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3245 - acc: 0.9976     \n",
      "Epoch 176/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3234 - acc: 0.9956     \n",
      "Epoch 177/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3166 - acc: 0.9990     \n",
      "Epoch 178/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3145 - acc: 0.9985     \n",
      "Epoch 179/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3152 - acc: 0.9971     \n",
      "Epoch 180/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3082 - acc: 0.9990     \n",
      "Epoch 181/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3048 - acc: 0.9961     \n",
      "Epoch 182/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3005 - acc: 0.9985     \n",
      "Epoch 183/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2959 - acc: 0.9981     \n",
      "Epoch 184/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2936 - acc: 0.9981     \n",
      "Epoch 185/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2902 - acc: 0.9981     \n",
      "Epoch 186/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2870 - acc: 0.9985     \n",
      "Epoch 187/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2830 - acc: 0.9985     \n",
      "Epoch 188/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2846 - acc: 0.9971     \n",
      "Epoch 189/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2789 - acc: 0.9981     \n",
      "Epoch 190/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2763 - acc: 0.9971     \n",
      "Epoch 191/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2697 - acc: 0.9990     \n",
      "Epoch 192/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2663 - acc: 0.9981     \n",
      "Epoch 193/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2643 - acc: 0.9990     \n",
      "Epoch 194/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2641 - acc: 0.9961     \n",
      "Epoch 195/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2583 - acc: 0.9981     \n",
      "Epoch 196/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2555 - acc: 0.9981     \n",
      "Epoch 197/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2514 - acc: 0.9990     \n",
      "Epoch 198/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2495 - acc: 0.9976     \n",
      "Epoch 199/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2456 - acc: 0.9985     \n",
      "Epoch 200/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2445 - acc: 0.9981     \n",
      "Epoch 201/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2390 - acc: 0.9985     \n",
      "Epoch 202/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2387 - acc: 0.9976     \n",
      "Epoch 203/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2328 - acc: 0.9990     \n",
      "Epoch 204/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2333 - acc: 0.9981     \n",
      "Epoch 205/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2323 - acc: 0.9966     \n",
      "Epoch 206/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2267 - acc: 0.9981     \n",
      "Epoch 207/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2238 - acc: 0.9990     \n",
      "Epoch 208/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2201 - acc: 0.9981     \n",
      "Epoch 209/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2203 - acc: 0.9971     \n",
      "Epoch 210/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2166 - acc: 0.9990     \n",
      "Epoch 211/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2152 - acc: 0.9985     \n",
      "Epoch 212/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2116 - acc: 0.9981     \n",
      "Epoch 213/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2108 - acc: 0.9966     \n",
      "Epoch 214/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2083 - acc: 0.9976     \n",
      "Epoch 215/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2029 - acc: 0.9985     \n",
      "Epoch 216/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2019 - acc: 0.9981     \n",
      "Epoch 217/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1972 - acc: 0.9981     \n",
      "Epoch 218/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1987 - acc: 0.9976     \n",
      "Epoch 219/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1927 - acc: 0.9976     \n",
      "Epoch 220/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1882 - acc: 0.9985     \n",
      "Epoch 221/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1860 - acc: 0.9985     \n",
      "Epoch 222/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1883 - acc: 0.9976     \n",
      "Epoch 223/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1849 - acc: 0.9985     \n",
      "Epoch 224/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1791 - acc: 0.9990     \n",
      "Epoch 225/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1789 - acc: 0.9985     \n",
      "Epoch 226/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1751 - acc: 0.9985     \n",
      "Epoch 227/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1726 - acc: 0.9976     \n",
      "Epoch 228/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1700 - acc: 0.9985     \n",
      "Epoch 229/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1687 - acc: 0.9985     \n",
      "Epoch 230/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1656 - acc: 0.9985     \n",
      "Epoch 231/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1653 - acc: 0.9981     \n",
      "Epoch 232/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1624 - acc: 0.9981     \n",
      "Epoch 233/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1600 - acc: 0.9976     \n",
      "Epoch 234/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1568 - acc: 0.9985     \n",
      "Epoch 235/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1556 - acc: 0.9971     \n",
      "Epoch 236/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1539 - acc: 0.9976     \n",
      "Epoch 237/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1487 - acc: 0.9995     \n",
      "Epoch 238/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1483 - acc: 0.9990     \n",
      "Epoch 239/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1466 - acc: 0.9981     \n",
      "Epoch 240/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1454 - acc: 0.9976     \n",
      "Epoch 241/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1411 - acc: 0.9976     \n",
      "Epoch 242/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1387 - acc: 0.9990     \n",
      "Epoch 243/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1371 - acc: 0.9990     \n",
      "Epoch 244/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1356 - acc: 0.9976     \n",
      "Epoch 245/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1400 - acc: 0.9966     \n",
      "Epoch 246/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1301 - acc: 0.9985     \n",
      "Epoch 247/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1303 - acc: 0.9981     \n",
      "Epoch 248/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1277 - acc: 0.9981     \n",
      "Epoch 249/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1263 - acc: 0.9981     \n",
      "Epoch 250/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1240 - acc: 0.9985     \n",
      "Epoch 251/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1207 - acc: 0.9990     \n",
      "Epoch 252/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1205 - acc: 0.9981     \n",
      "Epoch 253/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1192 - acc: 0.9976     \n",
      "Epoch 254/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1171 - acc: 0.9981     \n",
      "Epoch 255/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1129 - acc: 0.9985     \n",
      "Epoch 256/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1097 - acc: 0.9990     \n",
      "Epoch 257/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1109 - acc: 0.9990     \n",
      "Epoch 258/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1073 - acc: 0.9981     \n",
      "Epoch 259/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1055 - acc: 0.9990     \n",
      "Epoch 260/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1043 - acc: 0.9981     \n",
      "Epoch 261/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1018 - acc: 0.9985     \n",
      "Epoch 262/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1006 - acc: 0.9990     \n",
      "Epoch 263/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0988 - acc: 0.9981     \n",
      "Epoch 264/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0967 - acc: 0.9985     \n",
      "Epoch 265/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0948 - acc: 0.9985     \n",
      "Epoch 266/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0925 - acc: 0.9990     \n",
      "Epoch 267/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0906 - acc: 0.9985     \n",
      "Epoch 268/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0886 - acc: 0.9985     \n",
      "Epoch 269/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0882 - acc: 0.9976     \n",
      "Epoch 270/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0853 - acc: 0.9990     \n",
      "Epoch 271/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0841 - acc: 0.9971     \n",
      "Epoch 272/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0803 - acc: 0.9981     \n",
      "Epoch 273/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0809 - acc: 0.9981     \n",
      "Epoch 274/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0777 - acc: 0.9985     \n",
      "Epoch 275/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0759 - acc: 0.9985     \n",
      "Epoch 276/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0753 - acc: 0.9976     \n",
      "Epoch 277/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0746 - acc: 0.9981     \n",
      "Epoch 278/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0707 - acc: 0.9985     \n",
      "Epoch 279/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0708 - acc: 0.9976     \n",
      "Epoch 280/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0689 - acc: 0.9976     \n",
      "Epoch 281/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0650 - acc: 0.9985     \n",
      "Epoch 282/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0622 - acc: 0.9995     \n",
      "Epoch 283/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0624 - acc: 0.9985     \n",
      "Epoch 284/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0608 - acc: 0.9985     \n",
      "Epoch 285/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0600 - acc: 0.9985     \n",
      "Epoch 286/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0580 - acc: 0.9985     \n",
      "Epoch 287/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0586 - acc: 0.9961     \n",
      "Epoch 288/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0540 - acc: 0.9981     \n",
      "Epoch 289/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0528 - acc: 0.9981     \n",
      "Epoch 290/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0522 - acc: 0.9981     \n",
      "Epoch 291/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0504 - acc: 0.9990     \n",
      "Epoch 292/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0456 - acc: 0.9990     \n",
      "Epoch 293/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0461 - acc: 0.9990     \n",
      "Epoch 294/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0447 - acc: 0.9985     \n",
      "Epoch 295/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0429 - acc: 0.9981     \n",
      "Epoch 296/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0426 - acc: 0.9981     \n",
      "Epoch 297/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0389 - acc: 0.9985     \n",
      "Epoch 298/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0384 - acc: 0.9990     \n",
      "Epoch 299/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0368 - acc: 0.9985     \n",
      "Epoch 300/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0348 - acc: 0.9990     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 3s\n",
      "accuracy: 87.83505155868137\n",
      "precision: 88.79310344827587\n",
      "recall: 86.19246861924687\n",
      "f1_score: 87.47346072186838\n",
      "Training fold 4/10\n",
      "Epoch 1/300\n",
      "2064/2064 [==============================] - 1s - loss: 14.1487 - acc: 0.8464     \n",
      "Epoch 2/300\n",
      "2064/2064 [==============================] - 0s - loss: 11.6467 - acc: 0.9118     \n",
      "Epoch 3/300\n",
      "2064/2064 [==============================] - 0s - loss: 10.0008 - acc: 0.9297     \n",
      "Epoch 4/300\n",
      "2064/2064 [==============================] - 0s - loss: 8.8265 - acc: 0.9360     \n",
      "Epoch 5/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.9413 - acc: 0.9453     \n",
      "Epoch 6/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.2586 - acc: 0.9462     \n",
      "Epoch 7/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.7019 - acc: 0.9569     \n",
      "Epoch 8/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.2341 - acc: 0.9545     \n",
      "Epoch 9/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.8510 - acc: 0.9612     \n",
      "Epoch 10/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.5329 - acc: 0.9632     \n",
      "Epoch 11/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.2475 - acc: 0.9685     \n",
      "Epoch 12/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.0090 - acc: 0.9675     \n",
      "Epoch 13/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.7987 - acc: 0.9704     \n",
      "Epoch 14/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.5965 - acc: 0.9743     \n",
      "Epoch 15/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.4320 - acc: 0.9719     \n",
      "Epoch 16/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.2777 - acc: 0.9753     \n",
      "Epoch 17/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.1459 - acc: 0.9724     \n",
      "Epoch 18/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.0112 - acc: 0.9782     \n",
      "Epoch 19/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.8978 - acc: 0.9792     \n",
      "Epoch 20/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.7876 - acc: 0.9830     \n",
      "Epoch 21/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.7007 - acc: 0.9763     \n",
      "Epoch 22/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.5956 - acc: 0.9859     \n",
      "Epoch 23/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.5125 - acc: 0.9816     \n",
      "Epoch 24/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.4383 - acc: 0.9845     \n",
      "Epoch 25/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.3662 - acc: 0.9830     \n",
      "Epoch 26/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2917 - acc: 0.9855     \n",
      "Epoch 27/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2251 - acc: 0.9864     \n",
      "Epoch 28/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1695 - acc: 0.9850     \n",
      "Epoch 29/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1171 - acc: 0.9797     \n",
      "Epoch 30/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0532 - acc: 0.9889     \n",
      "Epoch 31/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0005 - acc: 0.9845     \n",
      "Epoch 32/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 2.9537 - acc: 0.9840     \n",
      "Epoch 33/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9084 - acc: 0.9874     \n",
      "Epoch 34/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8613 - acc: 0.9855     \n",
      "Epoch 35/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8196 - acc: 0.9855     \n",
      "Epoch 36/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7835 - acc: 0.9845     \n",
      "Epoch 37/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7420 - acc: 0.9889     \n",
      "Epoch 38/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7043 - acc: 0.9869     \n",
      "Epoch 39/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6743 - acc: 0.9884     \n",
      "Epoch 40/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6336 - acc: 0.9893     \n",
      "Epoch 41/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6008 - acc: 0.9893     \n",
      "Epoch 42/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5741 - acc: 0.9869     \n",
      "Epoch 43/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5363 - acc: 0.9927     \n",
      "Epoch 44/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5048 - acc: 0.9913     \n",
      "Epoch 45/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4810 - acc: 0.9913     \n",
      "Epoch 46/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4538 - acc: 0.9908     \n",
      "Epoch 47/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4279 - acc: 0.9913     \n",
      "Epoch 48/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3998 - acc: 0.9932     \n",
      "Epoch 49/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3763 - acc: 0.9927     \n",
      "Epoch 50/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3527 - acc: 0.9913     \n",
      "Epoch 51/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3321 - acc: 0.9869     \n",
      "Epoch 52/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3084 - acc: 0.9922     \n",
      "Epoch 53/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2846 - acc: 0.9913     \n",
      "Epoch 54/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2636 - acc: 0.9908     \n",
      "Epoch 55/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2448 - acc: 0.9889     - ETA: 0s - loss: 2.2475 - acc: 0.\n",
      "Epoch 56/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2292 - acc: 0.9927     \n",
      "Epoch 57/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2029 - acc: 0.9913     \n",
      "Epoch 58/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1856 - acc: 0.9927     \n",
      "Epoch 59/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1669 - acc: 0.9942     \n",
      "Epoch 60/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1540 - acc: 0.9927     \n",
      "Epoch 61/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1325 - acc: 0.9952     \n",
      "Epoch 62/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1171 - acc: 0.9927     \n",
      "Epoch 63/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0990 - acc: 0.9927     \n",
      "Epoch 64/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0804 - acc: 0.9922     \n",
      "Epoch 65/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0687 - acc: 0.9927     \n",
      "Epoch 66/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0536 - acc: 0.9937     \n",
      "Epoch 67/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0376 - acc: 0.9937     \n",
      "Epoch 68/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0212 - acc: 0.9932     \n",
      "Epoch 69/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0035 - acc: 0.9956     \n",
      "Epoch 70/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9950 - acc: 0.9947     \n",
      "Epoch 71/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9820 - acc: 0.9927     \n",
      "Epoch 72/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9656 - acc: 0.9922     \n",
      "Epoch 73/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9554 - acc: 0.9932     \n",
      "Epoch 74/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9393 - acc: 0.9947     \n",
      "Epoch 75/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9280 - acc: 0.9942     \n",
      "Epoch 76/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9181 - acc: 0.9913     \n",
      "Epoch 77/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9074 - acc: 0.9913     \n",
      "Epoch 78/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8878 - acc: 0.9942     \n",
      "Epoch 79/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8796 - acc: 0.9956     \n",
      "Epoch 80/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8706 - acc: 0.9942     \n",
      "Epoch 81/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8563 - acc: 0.9966     \n",
      "Epoch 82/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8472 - acc: 0.9937     \n",
      "Epoch 83/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8357 - acc: 0.9966     \n",
      "Epoch 84/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8263 - acc: 0.9952     \n",
      "Epoch 85/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8127 - acc: 0.9956     \n",
      "Epoch 86/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8076 - acc: 0.9956     \n",
      "Epoch 87/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7927 - acc: 0.9976     \n",
      "Epoch 88/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7841 - acc: 0.9952     \n",
      "Epoch 89/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7780 - acc: 0.9961     \n",
      "Epoch 90/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7652 - acc: 0.9956     \n",
      "Epoch 91/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7538 - acc: 0.9976     \n",
      "Epoch 92/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7468 - acc: 0.9956     \n",
      "Epoch 93/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7378 - acc: 0.9966     \n",
      "Epoch 94/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7271 - acc: 0.9956     \n",
      "Epoch 95/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7228 - acc: 0.9947     \n",
      "Epoch 96/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7081 - acc: 0.9985     \n",
      "Epoch 97/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7037 - acc: 0.9947     \n",
      "Epoch 98/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6946 - acc: 0.9952     \n",
      "Epoch 99/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6897 - acc: 0.9952     \n",
      "Epoch 100/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6808 - acc: 0.9956     \n",
      "Epoch 101/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6760 - acc: 0.9918     \n",
      "Epoch 102/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6618 - acc: 0.9971     \n",
      "Epoch 103/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6544 - acc: 0.9961     \n",
      "Epoch 104/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6482 - acc: 0.9961     \n",
      "Epoch 105/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6376 - acc: 0.9976     \n",
      "Epoch 106/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6314 - acc: 0.9952     \n",
      "Epoch 107/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6264 - acc: 0.9961     \n",
      "Epoch 108/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6188 - acc: 0.9961     \n",
      "Epoch 109/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6104 - acc: 0.9961     \n",
      "Epoch 110/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6025 - acc: 0.9947     \n",
      "Epoch 111/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5966 - acc: 0.9985     \n",
      "Epoch 112/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5896 - acc: 0.9966     \n",
      "Epoch 113/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5850 - acc: 0.9956     \n",
      "Epoch 114/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5756 - acc: 0.9971     \n",
      "Epoch 115/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5708 - acc: 0.9966     \n",
      "Epoch 116/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5654 - acc: 0.9947     \n",
      "Epoch 117/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5575 - acc: 0.9961     \n",
      "Epoch 118/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5499 - acc: 0.9971     \n",
      "Epoch 119/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5440 - acc: 0.9976     \n",
      "Epoch 120/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5365 - acc: 0.9990     \n",
      "Epoch 121/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5338 - acc: 0.9971     \n",
      "Epoch 122/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5268 - acc: 0.9985     \n",
      "Epoch 123/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5191 - acc: 0.9976     \n",
      "Epoch 124/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5126 - acc: 0.9981     \n",
      "Epoch 125/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5120 - acc: 0.9942     \n",
      "Epoch 126/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5038 - acc: 0.9985     \n",
      "Epoch 127/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4954 - acc: 0.9976     \n",
      "Epoch 128/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4930 - acc: 0.9961     \n",
      "Epoch 129/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4865 - acc: 0.9971     \n",
      "Epoch 130/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4834 - acc: 0.9966     \n",
      "Epoch 131/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4737 - acc: 0.9966     \n",
      "Epoch 132/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4716 - acc: 0.9976     \n",
      "Epoch 133/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4622 - acc: 0.9976     \n",
      "Epoch 134/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4586 - acc: 0.9981     \n",
      "Epoch 135/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4535 - acc: 0.9981     \n",
      "Epoch 136/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4489 - acc: 0.9976     \n",
      "Epoch 137/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4463 - acc: 0.9961     \n",
      "Epoch 138/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4386 - acc: 0.9971     \n",
      "Epoch 139/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4291 - acc: 0.9990     \n",
      "Epoch 140/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4281 - acc: 0.9971     \n",
      "Epoch 141/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4228 - acc: 0.9981     \n",
      "Epoch 142/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4184 - acc: 0.9971     \n",
      "Epoch 143/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4177 - acc: 0.9961     \n",
      "Epoch 144/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4148 - acc: 0.9971     \n",
      "Epoch 145/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4035 - acc: 0.9981     \n",
      "Epoch 146/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3996 - acc: 0.9971     \n",
      "Epoch 147/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3945 - acc: 0.9981     \n",
      "Epoch 148/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3922 - acc: 0.9971     \n",
      "Epoch 149/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3859 - acc: 0.9976     \n",
      "Epoch 150/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3830 - acc: 0.9961     \n",
      "Epoch 151/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3747 - acc: 0.9981     \n",
      "Epoch 152/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3740 - acc: 0.9981     \n",
      "Epoch 153/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3706 - acc: 0.9971     \n",
      "Epoch 154/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3636 - acc: 0.9981     \n",
      "Epoch 155/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3609 - acc: 0.9971     \n",
      "Epoch 156/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3564 - acc: 0.9966     \n",
      "Epoch 157/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3525 - acc: 0.9976     \n",
      "Epoch 158/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3478 - acc: 0.9971     \n",
      "Epoch 159/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3424 - acc: 0.9976     \n",
      "Epoch 160/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3372 - acc: 0.9990     \n",
      "Epoch 161/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3366 - acc: 0.9981     \n",
      "Epoch 162/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3350 - acc: 0.9966     \n",
      "Epoch 163/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3320 - acc: 0.9947     \n",
      "Epoch 164/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3241 - acc: 0.9981     \n",
      "Epoch 165/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3247 - acc: 0.9961     \n",
      "Epoch 166/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3182 - acc: 0.9985     \n",
      "Epoch 167/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3143 - acc: 0.9952     \n",
      "Epoch 168/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3094 - acc: 0.9981     \n",
      "Epoch 169/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3049 - acc: 0.9985     \n",
      "Epoch 170/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3012 - acc: 0.9981     \n",
      "Epoch 171/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2985 - acc: 0.9985     \n",
      "Epoch 172/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2955 - acc: 0.9981     \n",
      "Epoch 173/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2923 - acc: 0.9981     \n",
      "Epoch 174/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2874 - acc: 0.9981     \n",
      "Epoch 175/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2850 - acc: 0.9976     \n",
      "Epoch 176/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2804 - acc: 0.9976     \n",
      "Epoch 177/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2815 - acc: 0.9981     \n",
      "Epoch 178/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2740 - acc: 0.9976     \n",
      "Epoch 179/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2720 - acc: 0.9976     \n",
      "Epoch 180/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2647 - acc: 0.9985     \n",
      "Epoch 181/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2649 - acc: 0.9981     \n",
      "Epoch 182/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2641 - acc: 0.9971     \n",
      "Epoch 183/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2571 - acc: 0.9985     \n",
      "Epoch 184/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2549 - acc: 0.9976     \n",
      "Epoch 185/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2515 - acc: 0.9976     \n",
      "Epoch 186/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2473 - acc: 0.9981     \n",
      "Epoch 187/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2459 - acc: 0.9966     \n",
      "Epoch 188/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2418 - acc: 0.9976     \n",
      "Epoch 189/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2382 - acc: 0.9981     \n",
      "Epoch 190/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2349 - acc: 0.9981     \n",
      "Epoch 191/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2333 - acc: 0.9981     \n",
      "Epoch 192/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2288 - acc: 0.9990     \n",
      "Epoch 193/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2274 - acc: 0.9976     \n",
      "Epoch 194/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2238 - acc: 0.9981     \n",
      "Epoch 195/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2219 - acc: 0.9976     \n",
      "Epoch 196/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2178 - acc: 0.9990     \n",
      "Epoch 197/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2157 - acc: 0.9971     \n",
      "Epoch 198/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2109 - acc: 0.9985     \n",
      "Epoch 199/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2089 - acc: 0.9985     \n",
      "Epoch 200/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2091 - acc: 0.9981     \n",
      "Epoch 201/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2035 - acc: 0.9981     \n",
      "Epoch 202/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 1.1984 - acc: 0.9985     \n",
      "Epoch 203/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1967 - acc: 0.9985     \n",
      "Epoch 204/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1953 - acc: 0.9971     \n",
      "Epoch 205/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1937 - acc: 0.9976     \n",
      "Epoch 206/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1871 - acc: 0.9990     \n",
      "Epoch 207/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1870 - acc: 0.9981     \n",
      "Epoch 208/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1823 - acc: 0.9985     \n",
      "Epoch 209/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1806 - acc: 0.9985     \n",
      "Epoch 210/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1784 - acc: 0.9981     \n",
      "Epoch 211/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1750 - acc: 0.9985     \n",
      "Epoch 212/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1746 - acc: 0.9976     \n",
      "Epoch 213/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1725 - acc: 0.9981     \n",
      "Epoch 214/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1719 - acc: 0.9976     \n",
      "Epoch 215/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1668 - acc: 0.9976     \n",
      "Epoch 216/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1658 - acc: 0.9966     \n",
      "Epoch 217/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1609 - acc: 0.9985     \n",
      "Epoch 218/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1589 - acc: 0.9981     \n",
      "Epoch 219/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1534 - acc: 0.9985     \n",
      "Epoch 220/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1526 - acc: 0.9985     \n",
      "Epoch 221/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1519 - acc: 0.9981     \n",
      "Epoch 222/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1585 - acc: 0.9956     \n",
      "Epoch 223/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1465 - acc: 0.9976     \n",
      "Epoch 224/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1463 - acc: 0.9985     \n",
      "Epoch 225/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1425 - acc: 0.9985     \n",
      "Epoch 226/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1367 - acc: 0.9990     \n",
      "Epoch 227/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1381 - acc: 0.9966     \n",
      "Epoch 228/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1364 - acc: 0.9990     \n",
      "Epoch 229/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1332 - acc: 0.9985     \n",
      "Epoch 230/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1310 - acc: 0.9981     \n",
      "Epoch 231/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1280 - acc: 0.9981     \n",
      "Epoch 232/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1274 - acc: 0.9966     \n",
      "Epoch 233/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1256 - acc: 0.9985     \n",
      "Epoch 234/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1204 - acc: 0.9990     \n",
      "Epoch 235/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1192 - acc: 0.9971     \n",
      "Epoch 236/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1192 - acc: 0.9981     \n",
      "Epoch 237/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1160 - acc: 0.9985     \n",
      "Epoch 238/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1146 - acc: 0.9985     \n",
      "Epoch 239/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1140 - acc: 0.9981     \n",
      "Epoch 240/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1114 - acc: 0.9976     \n",
      "Epoch 241/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1115 - acc: 0.9981     \n",
      "Epoch 242/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1043 - acc: 0.9990     \n",
      "Epoch 243/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1025 - acc: 0.9981     \n",
      "Epoch 244/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1016 - acc: 0.9990     \n",
      "Epoch 245/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0982 - acc: 0.9985     \n",
      "Epoch 246/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0986 - acc: 0.9971     \n",
      "Epoch 247/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0925 - acc: 0.9990     \n",
      "Epoch 248/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0921 - acc: 0.9981     \n",
      "Epoch 249/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0900 - acc: 0.9985     \n",
      "Epoch 250/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0868 - acc: 0.9985     \n",
      "Epoch 251/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0860 - acc: 0.9990     \n",
      "Epoch 252/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0847 - acc: 0.9985     \n",
      "Epoch 253/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0824 - acc: 0.9985     \n",
      "Epoch 254/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0823 - acc: 0.9985     \n",
      "Epoch 255/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0803 - acc: 0.9971     \n",
      "Epoch 256/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0754 - acc: 0.9985     \n",
      "Epoch 257/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0746 - acc: 0.9985     \n",
      "Epoch 258/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0727 - acc: 0.9985     \n",
      "Epoch 259/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0739 - acc: 0.9981     \n",
      "Epoch 260/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0679 - acc: 0.9985     \n",
      "Epoch 261/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0684 - acc: 0.9990     \n",
      "Epoch 262/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0671 - acc: 0.9976     \n",
      "Epoch 263/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0648 - acc: 0.9966     \n",
      "Epoch 264/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0615 - acc: 0.9995     \n",
      "Epoch 265/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0587 - acc: 0.9981     \n",
      "Epoch 266/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0566 - acc: 0.9981     \n",
      "Epoch 267/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0539 - acc: 0.9990     \n",
      "Epoch 268/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0529 - acc: 0.9990     \n",
      "Epoch 269/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0530 - acc: 0.9976     \n",
      "Epoch 270/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0501 - acc: 0.9990     \n",
      "Epoch 271/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0503 - acc: 0.9981     \n",
      "Epoch 272/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0482 - acc: 0.9985     \n",
      "Epoch 273/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0432 - acc: 0.9990     \n",
      "Epoch 274/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0438 - acc: 0.9990     \n",
      "Epoch 275/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0399 - acc: 0.9990     \n",
      "Epoch 276/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0394 - acc: 0.9981     \n",
      "Epoch 277/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0366 - acc: 0.9990     \n",
      "Epoch 278/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0360 - acc: 0.9981     \n",
      "Epoch 279/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0336 - acc: 0.9981     \n",
      "Epoch 280/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0317 - acc: 0.9985     \n",
      "Epoch 281/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0302 - acc: 0.9985     \n",
      "Epoch 282/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0293 - acc: 0.9981     \n",
      "Epoch 283/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0260 - acc: 0.9985     \n",
      "Epoch 284/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0256 - acc: 0.9985     \n",
      "Epoch 285/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0225 - acc: 0.9981     \n",
      "Epoch 286/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0224 - acc: 0.9990     \n",
      "Epoch 287/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0225 - acc: 0.9976     \n",
      "Epoch 288/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0207 - acc: 0.9976     \n",
      "Epoch 289/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0161 - acc: 0.9985     \n",
      "Epoch 290/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0133 - acc: 0.9990     \n",
      "Epoch 291/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0133 - acc: 0.9995     \n",
      "Epoch 292/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0103 - acc: 0.9985     \n",
      "Epoch 293/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0075 - acc: 0.9990     \n",
      "Epoch 294/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0096 - acc: 0.9981     \n",
      "Epoch 295/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0073 - acc: 0.9981     \n",
      "Epoch 296/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0059 - acc: 0.9985     \n",
      "Epoch 297/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0041 - acc: 0.9981     \n",
      "Epoch 298/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0007 - acc: 0.9990     \n",
      "Epoch 299/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0007 - acc: 0.9995     \n",
      "Epoch 300/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9970 - acc: 0.9990     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 3s\n",
      "accuracy: 88.24742269270199\n",
      "precision: 89.22413793103449\n",
      "recall: 86.61087866108787\n",
      "f1_score: 87.89808917197452\n",
      "Training fold 5/10\n",
      "Epoch 1/300\n",
      "2064/2064 [==============================] - 1s - loss: 14.0422 - acc: 0.8421     \n",
      "Epoch 2/300\n",
      "2064/2064 [==============================] - 0s - loss: 11.4851 - acc: 0.9055     \n",
      "Epoch 3/300\n",
      "2064/2064 [==============================] - 0s - loss: 9.8246 - acc: 0.9152     \n",
      "Epoch 4/300\n",
      "2064/2064 [==============================] - 0s - loss: 8.6492 - acc: 0.9331     \n",
      "Epoch 5/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.7665 - acc: 0.9327     \n",
      "Epoch 6/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.0748 - acc: 0.9457     \n",
      "Epoch 7/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.5154 - acc: 0.9569     \n",
      "Epoch 8/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.0711 - acc: 0.9569     \n",
      "Epoch 9/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.6873 - acc: 0.9656     \n",
      "Epoch 10/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.3638 - acc: 0.9641     \n",
      "Epoch 11/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.0956 - acc: 0.9588     \n",
      "Epoch 12/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.8539 - acc: 0.9646     \n",
      "Epoch 13/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.6406 - acc: 0.9661     \n",
      "Epoch 14/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.4492 - acc: 0.9685     \n",
      "Epoch 15/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.2914 - acc: 0.9719     \n",
      "Epoch 16/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.1307 - acc: 0.9734     \n",
      "Epoch 17/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.0000 - acc: 0.9753     \n",
      "Epoch 18/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.8745 - acc: 0.9714     \n",
      "Epoch 19/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.7669 - acc: 0.9758     \n",
      "Epoch 20/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.6526 - acc: 0.9782     \n",
      "Epoch 21/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.5574 - acc: 0.9816     \n",
      "Epoch 22/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.4712 - acc: 0.9772     \n",
      "Epoch 23/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.3838 - acc: 0.9792     \n",
      "Epoch 24/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.3079 - acc: 0.9840     \n",
      "Epoch 25/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2382 - acc: 0.9811     \n",
      "Epoch 26/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1687 - acc: 0.9830     \n",
      "Epoch 27/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1077 - acc: 0.9821     \n",
      "Epoch 28/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0436 - acc: 0.9821     \n",
      "Epoch 29/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9938 - acc: 0.9835     \n",
      "Epoch 30/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9370 - acc: 0.9826     \n",
      "Epoch 31/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8838 - acc: 0.9850     \n",
      "Epoch 32/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8437 - acc: 0.9816     \n",
      "Epoch 33/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7932 - acc: 0.9864     \n",
      "Epoch 34/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7516 - acc: 0.9835     \n",
      "Epoch 35/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7103 - acc: 0.9845     \n",
      "Epoch 36/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6682 - acc: 0.9874     \n",
      "Epoch 37/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6335 - acc: 0.9874     \n",
      "Epoch 38/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5947 - acc: 0.9898     \n",
      "Epoch 39/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5651 - acc: 0.9826     \n",
      "Epoch 40/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5286 - acc: 0.9898     \n",
      "Epoch 41/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4999 - acc: 0.9889     \n",
      "Epoch 42/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4728 - acc: 0.9850     \n",
      "Epoch 43/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4413 - acc: 0.9884     \n",
      "Epoch 44/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4126 - acc: 0.9874     \n",
      "Epoch 45/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3865 - acc: 0.9864     \n",
      "Epoch 46/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3603 - acc: 0.9874     \n",
      "Epoch 47/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3317 - acc: 0.9922     \n",
      "Epoch 48/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3113 - acc: 0.9908     \n",
      "Epoch 49/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2846 - acc: 0.9908     \n",
      "Epoch 50/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2672 - acc: 0.9859     \n",
      "Epoch 51/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2390 - acc: 0.9932     \n",
      "Epoch 52/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2165 - acc: 0.9942     \n",
      "Epoch 53/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1976 - acc: 0.9913     \n",
      "Epoch 54/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1828 - acc: 0.9898     \n",
      "Epoch 55/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1623 - acc: 0.9884     \n",
      "Epoch 56/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1440 - acc: 0.9884     \n",
      "Epoch 57/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1160 - acc: 0.9927     \n",
      "Epoch 58/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1046 - acc: 0.9913     \n",
      "Epoch 59/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0842 - acc: 0.9947     \n",
      "Epoch 60/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0703 - acc: 0.9918     \n",
      "Epoch 61/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0595 - acc: 0.9898     \n",
      "Epoch 62/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0376 - acc: 0.9927     \n",
      "Epoch 63/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0218 - acc: 0.9922     \n",
      "Epoch 64/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0056 - acc: 0.9913     \n",
      "Epoch 65/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9883 - acc: 0.9947     \n",
      "Epoch 66/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9783 - acc: 0.9927     \n",
      "Epoch 67/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9603 - acc: 0.9952     \n",
      "Epoch 68/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9487 - acc: 0.9932     \n",
      "Epoch 69/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9328 - acc: 0.9947     \n",
      "Epoch 70/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9222 - acc: 0.9922     \n",
      "Epoch 71/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 1.9196 - acc: 0.9864     \n",
      "Epoch 72/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8953 - acc: 0.9942     \n",
      "Epoch 73/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8838 - acc: 0.9952     \n",
      "Epoch 74/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8688 - acc: 0.9937     \n",
      "Epoch 75/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8578 - acc: 0.9952     \n",
      "Epoch 76/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8452 - acc: 0.9947     \n",
      "Epoch 77/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8401 - acc: 0.9918     \n",
      "Epoch 78/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8234 - acc: 0.9937     \n",
      "Epoch 79/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8170 - acc: 0.9942     \n",
      "Epoch 80/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8012 - acc: 0.9947     \n",
      "Epoch 81/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7911 - acc: 0.9947     \n",
      "Epoch 82/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7841 - acc: 0.9922     \n",
      "Epoch 83/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7708 - acc: 0.9961     \n",
      "Epoch 84/300\n",
      "2064/2064 [==============================] - ETA: 0s - loss: 1.7610 - acc: 0.996 - 0s - loss: 1.7628 - acc: 0.9952     \n",
      "Epoch 85/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7534 - acc: 0.9932     \n",
      "Epoch 86/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7454 - acc: 0.9947     \n",
      "Epoch 87/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7364 - acc: 0.9952     \n",
      "Epoch 88/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7223 - acc: 0.9961     \n",
      "Epoch 89/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7118 - acc: 0.9956     \n",
      "Epoch 90/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7096 - acc: 0.9918     \n",
      "Epoch 91/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7001 - acc: 0.9937     \n",
      "Epoch 92/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6894 - acc: 0.9932     \n",
      "Epoch 93/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6801 - acc: 0.9971     \n",
      "Epoch 94/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6715 - acc: 0.9947     \n",
      "Epoch 95/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6651 - acc: 0.9942     \n",
      "Epoch 96/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6533 - acc: 0.9966     \n",
      "Epoch 97/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6472 - acc: 0.9952     \n",
      "Epoch 98/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6379 - acc: 0.9952     \n",
      "Epoch 99/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6298 - acc: 0.9966     \n",
      "Epoch 100/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6293 - acc: 0.9932     \n",
      "Epoch 101/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6194 - acc: 0.9961     \n",
      "Epoch 102/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6126 - acc: 0.9942     \n",
      "Epoch 103/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5974 - acc: 0.9971     \n",
      "Epoch 104/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5928 - acc: 0.9971     \n",
      "Epoch 105/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5872 - acc: 0.9966     \n",
      "Epoch 106/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5759 - acc: 0.9971     \n",
      "Epoch 107/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5746 - acc: 0.9956     \n",
      "Epoch 108/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5651 - acc: 0.9966     \n",
      "Epoch 109/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5562 - acc: 0.9981     \n",
      "Epoch 110/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5527 - acc: 0.9956     \n",
      "Epoch 111/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5441 - acc: 0.9971     \n",
      "Epoch 112/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5388 - acc: 0.9961     \n",
      "Epoch 113/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5344 - acc: 0.9942     \n",
      "Epoch 114/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5289 - acc: 0.9971     \n",
      "Epoch 115/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5200 - acc: 0.9956     \n",
      "Epoch 116/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5145 - acc: 0.9976     \n",
      "Epoch 117/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5093 - acc: 0.9952     \n",
      "Epoch 118/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5007 - acc: 0.9976     \n",
      "Epoch 119/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4977 - acc: 0.9947     \n",
      "Epoch 120/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4924 - acc: 0.9966     \n",
      "Epoch 121/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4894 - acc: 0.9942     \n",
      "Epoch 122/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4832 - acc: 0.9932     \n",
      "Epoch 123/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4737 - acc: 0.9966     \n",
      "Epoch 124/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4684 - acc: 0.9961     \n",
      "Epoch 125/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4655 - acc: 0.9961     \n",
      "Epoch 126/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4566 - acc: 0.9985     \n",
      "Epoch 127/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4543 - acc: 0.9961     \n",
      "Epoch 128/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4445 - acc: 0.9966     \n",
      "Epoch 129/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4433 - acc: 0.9952     \n",
      "Epoch 130/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4371 - acc: 0.9971     \n",
      "Epoch 131/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4294 - acc: 0.9985     \n",
      "Epoch 132/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4259 - acc: 0.9976     \n",
      "Epoch 133/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4176 - acc: 0.9990     \n",
      "Epoch 134/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4149 - acc: 0.9981     \n",
      "Epoch 135/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4138 - acc: 0.9971     \n",
      "Epoch 136/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4062 - acc: 0.9966     \n",
      "Epoch 137/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3988 - acc: 0.9976     \n",
      "Epoch 138/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3974 - acc: 0.9976     \n",
      "Epoch 139/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3948 - acc: 0.9947     \n",
      "Epoch 140/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3877 - acc: 0.9966     \n",
      "Epoch 141/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3818 - acc: 0.9981     \n",
      "Epoch 142/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3779 - acc: 0.9966     \n",
      "Epoch 143/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3739 - acc: 0.9961     \n",
      "Epoch 144/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3654 - acc: 0.9985     \n",
      "Epoch 145/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3623 - acc: 0.9976     \n",
      "Epoch 146/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3595 - acc: 0.9956     \n",
      "Epoch 147/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3553 - acc: 0.9971     \n",
      "Epoch 148/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3488 - acc: 0.9985     \n",
      "Epoch 149/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3441 - acc: 0.9985     \n",
      "Epoch 150/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3442 - acc: 0.9961     \n",
      "Epoch 151/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3427 - acc: 0.9942     \n",
      "Epoch 152/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3342 - acc: 0.9981     \n",
      "Epoch 153/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3302 - acc: 0.9966     \n",
      "Epoch 154/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3263 - acc: 0.9976     \n",
      "Epoch 155/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3230 - acc: 0.9971     \n",
      "Epoch 156/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3187 - acc: 0.9966     \n",
      "Epoch 157/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3130 - acc: 0.9985     \n",
      "Epoch 158/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3080 - acc: 0.9976     \n",
      "Epoch 159/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3067 - acc: 0.9966     \n",
      "Epoch 160/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3035 - acc: 0.9966     \n",
      "Epoch 161/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2980 - acc: 0.9976     \n",
      "Epoch 162/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2920 - acc: 0.9990     \n",
      "Epoch 163/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2940 - acc: 0.9961     \n",
      "Epoch 164/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2872 - acc: 0.9961     \n",
      "Epoch 165/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2835 - acc: 0.9981     \n",
      "Epoch 166/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2785 - acc: 0.9971     \n",
      "Epoch 167/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2812 - acc: 0.9966     \n",
      "Epoch 168/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2735 - acc: 0.9971     \n",
      "Epoch 169/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2704 - acc: 0.9985     \n",
      "Epoch 170/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2695 - acc: 0.9971     \n",
      "Epoch 171/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2626 - acc: 0.9971     \n",
      "Epoch 172/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2602 - acc: 0.9981     \n",
      "Epoch 173/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2578 - acc: 0.9966     \n",
      "Epoch 174/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2542 - acc: 0.9981     \n",
      "Epoch 175/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2481 - acc: 0.9976     \n",
      "Epoch 176/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2450 - acc: 0.9976     \n",
      "Epoch 177/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2438 - acc: 0.9976     \n",
      "Epoch 178/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2415 - acc: 0.9976     \n",
      "Epoch 179/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2361 - acc: 0.9981     \n",
      "Epoch 180/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2327 - acc: 0.9976     \n",
      "Epoch 181/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2294 - acc: 0.9985     \n",
      "Epoch 182/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2295 - acc: 0.9971     \n",
      "Epoch 183/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2236 - acc: 0.9971     \n",
      "Epoch 184/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2211 - acc: 0.9976     \n",
      "Epoch 185/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2184 - acc: 0.9976     \n",
      "Epoch 186/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2166 - acc: 0.9971     \n",
      "Epoch 187/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2091 - acc: 0.9981     \n",
      "Epoch 188/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2074 - acc: 0.9981     \n",
      "Epoch 189/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2056 - acc: 0.9981     \n",
      "Epoch 190/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2039 - acc: 0.9990     \n",
      "Epoch 191/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1985 - acc: 0.9985     \n",
      "Epoch 192/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2022 - acc: 0.9947     \n",
      "Epoch 193/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1939 - acc: 0.9985     \n",
      "Epoch 194/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1941 - acc: 0.9961     \n",
      "Epoch 195/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1885 - acc: 0.9971     \n",
      "Epoch 196/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1900 - acc: 0.9961     \n",
      "Epoch 197/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1818 - acc: 0.9985     \n",
      "Epoch 198/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1802 - acc: 0.9990     \n",
      "Epoch 199/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1772 - acc: 0.9981     \n",
      "Epoch 200/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1748 - acc: 0.9985     \n",
      "Epoch 201/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1733 - acc: 0.9976     \n",
      "Epoch 202/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1722 - acc: 0.9956     \n",
      "Epoch 203/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1676 - acc: 0.9966     \n",
      "Epoch 204/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1609 - acc: 0.9990     \n",
      "Epoch 205/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1627 - acc: 0.9976     \n",
      "Epoch 206/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1624 - acc: 0.9981     \n",
      "Epoch 207/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1567 - acc: 0.9971     \n",
      "Epoch 208/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1533 - acc: 0.9985     \n",
      "Epoch 209/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1535 - acc: 0.9961     \n",
      "Epoch 210/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1514 - acc: 0.9961     \n",
      "Epoch 211/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1472 - acc: 0.9981     \n",
      "Epoch 212/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1421 - acc: 0.9990     \n",
      "Epoch 213/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1440 - acc: 0.9971     \n",
      "Epoch 214/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1392 - acc: 0.9985     \n",
      "Epoch 215/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1347 - acc: 0.9981     \n",
      "Epoch 216/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1366 - acc: 0.9971     \n",
      "Epoch 217/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1350 - acc: 0.9961     \n",
      "Epoch 218/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1332 - acc: 0.9976     \n",
      "Epoch 219/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1285 - acc: 0.9971     \n",
      "Epoch 220/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1249 - acc: 0.9985     \n",
      "Epoch 221/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1242 - acc: 0.9976     \n",
      "Epoch 222/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1195 - acc: 0.9981     \n",
      "Epoch 223/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1168 - acc: 0.9985     \n",
      "Epoch 224/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1175 - acc: 0.9985     \n",
      "Epoch 225/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1152 - acc: 0.9966     \n",
      "Epoch 226/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1100 - acc: 0.9990     \n",
      "Epoch 227/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1116 - acc: 0.9981     \n",
      "Epoch 228/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1101 - acc: 0.9981     \n",
      "Epoch 229/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1053 - acc: 0.9981     \n",
      "Epoch 230/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1047 - acc: 0.9976     \n",
      "Epoch 231/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0982 - acc: 0.9985     \n",
      "Epoch 232/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0988 - acc: 0.9985     \n",
      "Epoch 233/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0961 - acc: 0.9985     \n",
      "Epoch 234/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0941 - acc: 0.9981     \n",
      "Epoch 235/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0912 - acc: 0.9985     \n",
      "Epoch 236/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0903 - acc: 0.9966     \n",
      "Epoch 237/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0848 - acc: 0.9990     \n",
      "Epoch 238/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0853 - acc: 0.9981     \n",
      "Epoch 239/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0812 - acc: 0.9976     \n",
      "Epoch 240/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0823 - acc: 0.9976     \n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 1.0787 - acc: 0.9981     \n",
      "Epoch 242/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0756 - acc: 0.9985     \n",
      "Epoch 243/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0739 - acc: 0.9985     \n",
      "Epoch 244/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0719 - acc: 0.9981     \n",
      "Epoch 245/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0735 - acc: 0.9981     \n",
      "Epoch 246/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0686 - acc: 0.9990     \n",
      "Epoch 247/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0657 - acc: 0.9985     \n",
      "Epoch 248/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0638 - acc: 0.9985     \n",
      "Epoch 249/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0639 - acc: 0.9985     \n",
      "Epoch 250/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0612 - acc: 0.9985     \n",
      "Epoch 251/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0572 - acc: 0.9990     \n",
      "Epoch 252/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0570 - acc: 0.9981     \n",
      "Epoch 253/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0556 - acc: 0.9976     \n",
      "Epoch 254/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0549 - acc: 0.9981     \n",
      "Epoch 255/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0490 - acc: 0.9985     \n",
      "Epoch 256/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0502 - acc: 0.9976     \n",
      "Epoch 257/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0473 - acc: 0.9976     \n",
      "Epoch 258/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0466 - acc: 0.9990     \n",
      "Epoch 259/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0430 - acc: 0.9976     \n",
      "Epoch 260/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0419 - acc: 0.9990     \n",
      "Epoch 261/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0412 - acc: 0.9985     \n",
      "Epoch 262/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0389 - acc: 0.9985     \n",
      "Epoch 263/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0372 - acc: 0.9990     \n",
      "Epoch 264/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0341 - acc: 0.9990     \n",
      "Epoch 265/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0340 - acc: 0.9981     \n",
      "Epoch 266/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0295 - acc: 0.9985     \n",
      "Epoch 267/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0317 - acc: 0.9990     \n",
      "Epoch 268/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0277 - acc: 0.9985     \n",
      "Epoch 269/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0277 - acc: 0.9971     \n",
      "Epoch 270/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0231 - acc: 0.9990     \n",
      "Epoch 271/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0228 - acc: 0.9985     \n",
      "Epoch 272/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0210 - acc: 0.9976     \n",
      "Epoch 273/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0210 - acc: 0.9981     \n",
      "Epoch 274/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0192 - acc: 0.9981     \n",
      "Epoch 275/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0160 - acc: 0.9981     \n",
      "Epoch 276/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0163 - acc: 0.9985     \n",
      "Epoch 277/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0126 - acc: 0.9981     \n",
      "Epoch 278/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0105 - acc: 0.9990     \n",
      "Epoch 279/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0104 - acc: 0.9971     \n",
      "Epoch 280/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0082 - acc: 0.9985     \n",
      "Epoch 281/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0063 - acc: 0.9985     \n",
      "Epoch 282/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0045 - acc: 0.9985     \n",
      "Epoch 283/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0024 - acc: 0.9990     \n",
      "Epoch 284/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0006 - acc: 0.9981     \n",
      "Epoch 285/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9989 - acc: 0.9981     \n",
      "Epoch 286/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0025 - acc: 0.9966     \n",
      "Epoch 287/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9977 - acc: 0.9981     \n",
      "Epoch 288/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9948 - acc: 0.9985     \n",
      "Epoch 289/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9924 - acc: 0.9990     \n",
      "Epoch 290/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9935 - acc: 0.9976     \n",
      "Epoch 291/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9880 - acc: 0.9990     \n",
      "Epoch 292/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9901 - acc: 0.9990     \n",
      "Epoch 293/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9878 - acc: 0.9981     \n",
      "Epoch 294/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9845 - acc: 0.9990     \n",
      "Epoch 295/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9853 - acc: 0.9985     \n",
      "Epoch 296/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9852 - acc: 0.9976     \n",
      "Epoch 297/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9804 - acc: 0.9985     \n",
      "Epoch 298/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9798 - acc: 0.9981     \n",
      "Epoch 299/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9803 - acc: 0.9981     \n",
      "Epoch 300/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9760 - acc: 0.9985     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 5s\n",
      "accuracy: 88.24742269270199\n",
      "precision: 89.91228070175438\n",
      "recall: 85.77405857740585\n",
      "f1_score: 87.79443254817988\n",
      "Training fold 6/10\n",
      "Epoch 1/300\n",
      "2064/2064 [==============================] - 1s - loss: 14.0827 - acc: 0.8484     \n",
      "Epoch 2/300\n",
      "2064/2064 [==============================] - 0s - loss: 11.5836 - acc: 0.9094     \n",
      "Epoch 3/300\n",
      "2064/2064 [==============================] - 0s - loss: 9.9626 - acc: 0.9220     \n",
      "Epoch 4/300\n",
      "2064/2064 [==============================] - 0s - loss: 8.7848 - acc: 0.9360     \n",
      "Epoch 5/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.9074 - acc: 0.9433     \n",
      "Epoch 6/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.2084 - acc: 0.9520     \n",
      "Epoch 7/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.6661 - acc: 0.9559     \n",
      "Epoch 8/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.2047 - acc: 0.9588     \n",
      "Epoch 9/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.8180 - acc: 0.9675     \n",
      "Epoch 10/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.4979 - acc: 0.9646     \n",
      "Epoch 11/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.2191 - acc: 0.9646     \n",
      "Epoch 12/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.9753 - acc: 0.9675     \n",
      "Epoch 13/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.7594 - acc: 0.9666     \n",
      "Epoch 14/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.5640 - acc: 0.9743     \n",
      "Epoch 15/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.3923 - acc: 0.9743     \n",
      "Epoch 16/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.2468 - acc: 0.9734     \n",
      "Epoch 17/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.0935 - acc: 0.9801     \n",
      "Epoch 18/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.9774 - acc: 0.9738     \n",
      "Epoch 19/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.8557 - acc: 0.9782     \n",
      "Epoch 20/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.7481 - acc: 0.9763     \n",
      "Epoch 21/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.6516 - acc: 0.9816     \n",
      "Epoch 22/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.5577 - acc: 0.9801     \n",
      "Epoch 23/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.4748 - acc: 0.9816     \n",
      "Epoch 24/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.3941 - acc: 0.9811     \n",
      "Epoch 25/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.3262 - acc: 0.9821     \n",
      "Epoch 26/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2536 - acc: 0.9835     \n",
      "Epoch 27/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1924 - acc: 0.9826     \n",
      "Epoch 28/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1345 - acc: 0.9797     \n",
      "Epoch 29/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0699 - acc: 0.9845     \n",
      "Epoch 30/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0151 - acc: 0.9864     \n",
      "Epoch 31/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9696 - acc: 0.9811     \n",
      "Epoch 32/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9168 - acc: 0.9850     \n",
      "Epoch 33/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8676 - acc: 0.9869     \n",
      "Epoch 34/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8235 - acc: 0.9869     \n",
      "Epoch 35/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7851 - acc: 0.9826     \n",
      "Epoch 36/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7383 - acc: 0.9893     \n",
      "Epoch 37/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7086 - acc: 0.9874     \n",
      "Epoch 38/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6677 - acc: 0.9864     \n",
      "Epoch 39/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6303 - acc: 0.9918     - ETA: 0s - loss: 2.6442 - ac\n",
      "Epoch 40/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5990 - acc: 0.9903     \n",
      "Epoch 41/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5664 - acc: 0.9918     \n",
      "Epoch 42/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5352 - acc: 0.9908     \n",
      "Epoch 43/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5044 - acc: 0.9903     \n",
      "Epoch 44/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4780 - acc: 0.9874     \n",
      "Epoch 45/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4516 - acc: 0.9903     \n",
      "Epoch 46/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4207 - acc: 0.9898     \n",
      "Epoch 47/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3967 - acc: 0.9913     \n",
      "Epoch 48/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3685 - acc: 0.9884     \n",
      "Epoch 49/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3408 - acc: 0.9918     \n",
      "Epoch 50/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3199 - acc: 0.9932     \n",
      "Epoch 51/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2919 - acc: 0.9966     \n",
      "Epoch 52/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2784 - acc: 0.9908     \n",
      "Epoch 53/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2526 - acc: 0.9918     \n",
      "Epoch 54/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2364 - acc: 0.9893     \n",
      "Epoch 55/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2108 - acc: 0.9942     \n",
      "Epoch 56/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1939 - acc: 0.9913     \n",
      "Epoch 57/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1704 - acc: 0.9927     \n",
      "Epoch 58/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1587 - acc: 0.9918     \n",
      "Epoch 59/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1357 - acc: 0.9918     \n",
      "Epoch 60/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1203 - acc: 0.9937     \n",
      "Epoch 61/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0988 - acc: 0.9918     \n",
      "Epoch 62/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0848 - acc: 0.9922     \n",
      "Epoch 63/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0667 - acc: 0.9932     \n",
      "Epoch 64/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0523 - acc: 0.9932     \n",
      "Epoch 65/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0332 - acc: 0.9961     \n",
      "Epoch 66/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0204 - acc: 0.9927     \n",
      "Epoch 67/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0084 - acc: 0.9942     \n",
      "Epoch 68/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9850 - acc: 0.9952     \n",
      "Epoch 69/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9758 - acc: 0.9932     \n",
      "Epoch 70/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9667 - acc: 0.9932     \n",
      "Epoch 71/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9505 - acc: 0.9961     \n",
      "Epoch 72/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9356 - acc: 0.9942     \n",
      "Epoch 73/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9224 - acc: 0.9956     \n",
      "Epoch 74/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9114 - acc: 0.9922     \n",
      "Epoch 75/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8947 - acc: 0.9952     \n",
      "Epoch 76/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8843 - acc: 0.9952     \n",
      "Epoch 77/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8698 - acc: 0.9932     \n",
      "Epoch 78/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8595 - acc: 0.9961     \n",
      "Epoch 79/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8441 - acc: 0.9952     \n",
      "Epoch 80/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8394 - acc: 0.9937     \n",
      "Epoch 81/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8273 - acc: 0.9942     \n",
      "Epoch 82/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8185 - acc: 0.9956     \n",
      "Epoch 83/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8040 - acc: 0.9956     \n",
      "Epoch 84/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7948 - acc: 0.9942     \n",
      "Epoch 85/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7826 - acc: 0.9956     \n",
      "Epoch 86/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7712 - acc: 0.9952     \n",
      "Epoch 87/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7695 - acc: 0.9922     \n",
      "Epoch 88/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7528 - acc: 0.9971     \n",
      "Epoch 89/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7450 - acc: 0.9952     \n",
      "Epoch 90/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7344 - acc: 0.9976     \n",
      "Epoch 91/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7256 - acc: 0.9961     \n",
      "Epoch 92/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7171 - acc: 0.9971     \n",
      "Epoch 93/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7043 - acc: 0.9971     \n",
      "Epoch 94/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6984 - acc: 0.9981     \n",
      "Epoch 95/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6883 - acc: 0.9961     \n",
      "Epoch 96/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6810 - acc: 0.9966     \n",
      "Epoch 97/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6757 - acc: 0.9947     \n",
      "Epoch 98/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6663 - acc: 0.9966     \n",
      "Epoch 99/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6536 - acc: 0.9966     \n",
      "Epoch 100/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6464 - acc: 0.9985     \n",
      "Epoch 101/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6420 - acc: 0.9961     \n",
      "Epoch 102/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6347 - acc: 0.9956     \n",
      "Epoch 103/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6261 - acc: 0.9961     \n",
      "Epoch 104/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6240 - acc: 0.9942     \n",
      "Epoch 105/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6092 - acc: 0.9961     \n",
      "Epoch 106/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6014 - acc: 0.9961     \n",
      "Epoch 107/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5981 - acc: 0.9942     \n",
      "Epoch 108/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5886 - acc: 0.9966     \n",
      "Epoch 109/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 1.5788 - acc: 0.9976     \n",
      "Epoch 110/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5769 - acc: 0.9937     \n",
      "Epoch 111/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5671 - acc: 0.9956     \n",
      "Epoch 112/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5600 - acc: 0.9976     \n",
      "Epoch 113/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5520 - acc: 0.9990     \n",
      "Epoch 114/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5520 - acc: 0.9956     \n",
      "Epoch 115/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5406 - acc: 0.9981     \n",
      "Epoch 116/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5376 - acc: 0.9952     \n",
      "Epoch 117/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5269 - acc: 0.9966     \n",
      "Epoch 118/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5235 - acc: 0.9952     \n",
      "Epoch 119/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5204 - acc: 0.9985     \n",
      "Epoch 120/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5098 - acc: 0.9971     \n",
      "Epoch 121/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5048 - acc: 0.9971     \n",
      "Epoch 122/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5001 - acc: 0.9971     \n",
      "Epoch 123/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4910 - acc: 0.9981     \n",
      "Epoch 124/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4861 - acc: 0.9961     \n",
      "Epoch 125/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4806 - acc: 0.9976     \n",
      "Epoch 126/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4742 - acc: 0.9976     \n",
      "Epoch 127/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4667 - acc: 0.9985     \n",
      "Epoch 128/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4650 - acc: 0.9961     \n",
      "Epoch 129/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4588 - acc: 0.9981     \n",
      "Epoch 130/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4527 - acc: 0.9966     \n",
      "Epoch 131/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4494 - acc: 0.9966     \n",
      "Epoch 132/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4443 - acc: 0.9971     \n",
      "Epoch 133/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4368 - acc: 0.9971     \n",
      "Epoch 134/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4327 - acc: 0.9947     \n",
      "Epoch 135/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4271 - acc: 0.9966     \n",
      "Epoch 136/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4195 - acc: 0.9985     \n",
      "Epoch 137/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4153 - acc: 0.9985     \n",
      "Epoch 138/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4109 - acc: 0.9976     \n",
      "Epoch 139/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4094 - acc: 0.9961     \n",
      "Epoch 140/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4012 - acc: 0.9966     \n",
      "Epoch 141/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3961 - acc: 0.9985     \n",
      "Epoch 142/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3953 - acc: 0.9971     \n",
      "Epoch 143/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3885 - acc: 0.9971     \n",
      "Epoch 144/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3826 - acc: 0.9971     \n",
      "Epoch 145/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3760 - acc: 0.9981     \n",
      "Epoch 146/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3756 - acc: 0.9971     \n",
      "Epoch 147/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3683 - acc: 0.9985     - ETA: 0s - loss: 1.3796 - \n",
      "Epoch 148/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3633 - acc: 0.9981     \n",
      "Epoch 149/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3624 - acc: 0.9966     \n",
      "Epoch 150/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3566 - acc: 0.9971     \n",
      "Epoch 151/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3528 - acc: 0.9976     \n",
      "Epoch 152/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3510 - acc: 0.9981     \n",
      "Epoch 153/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3436 - acc: 0.9976     \n",
      "Epoch 154/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3413 - acc: 0.9971     \n",
      "Epoch 155/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3369 - acc: 0.9971     \n",
      "Epoch 156/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3333 - acc: 0.9971     \n",
      "Epoch 157/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3271 - acc: 0.9971     \n",
      "Epoch 158/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3251 - acc: 0.9961     \n",
      "Epoch 159/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3173 - acc: 0.9985     \n",
      "Epoch 160/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3165 - acc: 0.9981     \n",
      "Epoch 161/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3115 - acc: 0.9976     \n",
      "Epoch 162/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3084 - acc: 0.9956     \n",
      "Epoch 163/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3023 - acc: 0.9981     \n",
      "Epoch 164/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2990 - acc: 0.9981     \n",
      "Epoch 165/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2965 - acc: 0.9981     \n",
      "Epoch 166/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2888 - acc: 0.9990     \n",
      "Epoch 167/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2921 - acc: 0.9976     \n",
      "Epoch 168/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2856 - acc: 0.9961     \n",
      "Epoch 169/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2799 - acc: 0.9990     \n",
      "Epoch 170/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2764 - acc: 0.9985     \n",
      "Epoch 171/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2714 - acc: 0.9981     \n",
      "Epoch 172/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2692 - acc: 0.9985     \n",
      "Epoch 173/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2661 - acc: 0.9981     \n",
      "Epoch 174/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2630 - acc: 0.9976     \n",
      "Epoch 175/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2582 - acc: 0.9985     \n",
      "Epoch 176/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2560 - acc: 0.9985     \n",
      "Epoch 177/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2521 - acc: 0.9985     \n",
      "Epoch 178/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2509 - acc: 0.9976     \n",
      "Epoch 179/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2463 - acc: 0.9981     \n",
      "Epoch 180/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2418 - acc: 0.9981     \n",
      "Epoch 181/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2380 - acc: 0.9985     \n",
      "Epoch 182/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2347 - acc: 0.9990     \n",
      "Epoch 183/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2306 - acc: 0.9981     \n",
      "Epoch 184/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2278 - acc: 0.9971     \n",
      "Epoch 185/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2264 - acc: 0.9976     \n",
      "Epoch 186/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2213 - acc: 0.9981     \n",
      "Epoch 187/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2189 - acc: 0.9976     \n",
      "Epoch 188/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2156 - acc: 0.9976     \n",
      "Epoch 189/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2089 - acc: 0.9985     \n",
      "Epoch 190/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2119 - acc: 0.9961     \n",
      "Epoch 191/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2076 - acc: 0.9966     \n",
      "Epoch 192/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2068 - acc: 0.9971     \n",
      "Epoch 193/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2029 - acc: 0.9981     \n",
      "Epoch 194/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1954 - acc: 0.9990     \n",
      "Epoch 195/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1935 - acc: 0.9971     \n",
      "Epoch 196/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1919 - acc: 0.9971     \n",
      "Epoch 197/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1877 - acc: 0.9981     \n",
      "Epoch 198/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1856 - acc: 0.9976     \n",
      "Epoch 199/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1841 - acc: 0.9976     \n",
      "Epoch 200/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1801 - acc: 0.9985     \n",
      "Epoch 201/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1777 - acc: 0.9981     \n",
      "Epoch 202/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1767 - acc: 0.9966     \n",
      "Epoch 203/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1705 - acc: 0.9990     \n",
      "Epoch 204/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1712 - acc: 0.9985     \n",
      "Epoch 205/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1676 - acc: 0.9985     \n",
      "Epoch 206/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1665 - acc: 0.9966     \n",
      "Epoch 207/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1646 - acc: 0.9976     \n",
      "Epoch 208/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1574 - acc: 0.9981     \n",
      "Epoch 209/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1537 - acc: 0.9981     \n",
      "Epoch 210/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1538 - acc: 0.9981     \n",
      "Epoch 211/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1491 - acc: 0.9990     \n",
      "Epoch 212/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1462 - acc: 0.9981     \n",
      "Epoch 213/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1461 - acc: 0.9985     \n",
      "Epoch 214/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1418 - acc: 0.9985     \n",
      "Epoch 215/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1390 - acc: 0.9981     \n",
      "Epoch 216/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1385 - acc: 0.9981     \n",
      "Epoch 217/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1347 - acc: 0.9990     \n",
      "Epoch 218/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1318 - acc: 0.9990     \n",
      "Epoch 219/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1274 - acc: 0.9990     \n",
      "Epoch 220/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1286 - acc: 0.9985     \n",
      "Epoch 221/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1243 - acc: 0.9990     \n",
      "Epoch 222/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1234 - acc: 0.9981     \n",
      "Epoch 223/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1169 - acc: 0.9990     \n",
      "Epoch 224/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1167 - acc: 0.9985     \n",
      "Epoch 225/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1155 - acc: 0.9990     \n",
      "Epoch 226/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1140 - acc: 0.9976     \n",
      "Epoch 227/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1109 - acc: 0.9981     \n",
      "Epoch 228/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1077 - acc: 0.9990     \n",
      "Epoch 229/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1050 - acc: 0.9985     \n",
      "Epoch 230/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1032 - acc: 0.9990     \n",
      "Epoch 231/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1008 - acc: 0.9966     \n",
      "Epoch 232/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0990 - acc: 0.9985     \n",
      "Epoch 233/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0970 - acc: 0.9985     \n",
      "Epoch 234/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0928 - acc: 0.9985     \n",
      "Epoch 235/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0918 - acc: 0.9981     \n",
      "Epoch 236/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0896 - acc: 0.9985     \n",
      "Epoch 237/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0849 - acc: 0.9990     \n",
      "Epoch 238/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0857 - acc: 0.9976     \n",
      "Epoch 239/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0820 - acc: 0.9985     \n",
      "Epoch 240/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0799 - acc: 0.9981     \n",
      "Epoch 241/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0780 - acc: 0.9981     - ETA: 0s - loss: 1.0766 - acc:\n",
      "Epoch 242/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0752 - acc: 0.9981     \n",
      "Epoch 243/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0754 - acc: 0.9985     \n",
      "Epoch 244/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0705 - acc: 0.9985     \n",
      "Epoch 245/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0704 - acc: 0.9985     \n",
      "Epoch 246/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0677 - acc: 0.9976     \n",
      "Epoch 247/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0637 - acc: 0.9990     \n",
      "Epoch 248/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0621 - acc: 0.9981     \n",
      "Epoch 249/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0612 - acc: 0.9981     \n",
      "Epoch 250/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0568 - acc: 0.9981     \n",
      "Epoch 251/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0573 - acc: 0.9990     \n",
      "Epoch 252/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0546 - acc: 0.9985     \n",
      "Epoch 253/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0544 - acc: 0.9981     \n",
      "Epoch 254/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0530 - acc: 0.9971     \n",
      "Epoch 255/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0481 - acc: 0.9990     \n",
      "Epoch 256/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0429 - acc: 0.9990     \n",
      "Epoch 257/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0442 - acc: 0.9981     \n",
      "Epoch 258/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0412 - acc: 0.9985     \n",
      "Epoch 259/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0414 - acc: 0.9981     \n",
      "Epoch 260/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0367 - acc: 0.9990     \n",
      "Epoch 261/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0349 - acc: 0.9985     \n",
      "Epoch 262/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0328 - acc: 0.9985     \n",
      "Epoch 263/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0306 - acc: 0.9985     \n",
      "Epoch 264/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0317 - acc: 0.9976     \n",
      "Epoch 265/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0307 - acc: 0.9976     \n",
      "Epoch 266/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0260 - acc: 0.9990     \n",
      "Epoch 267/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0239 - acc: 0.9985     \n",
      "Epoch 268/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0229 - acc: 0.9981     \n",
      "Epoch 269/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0204 - acc: 0.9981     \n",
      "Epoch 270/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0198 - acc: 0.9985     \n",
      "Epoch 271/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0171 - acc: 0.9981     \n",
      "Epoch 272/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0132 - acc: 0.9985     \n",
      "Epoch 273/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0136 - acc: 0.9981     \n",
      "Epoch 274/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0119 - acc: 0.9976     \n",
      "Epoch 275/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0090 - acc: 0.9985     \n",
      "Epoch 276/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0057 - acc: 0.9990     \n",
      "Epoch 277/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0048 - acc: 0.9995     \n",
      "Epoch 278/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0037 - acc: 0.9990     \n",
      "Epoch 279/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 1.0005 - acc: 0.9985     \n",
      "Epoch 280/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0018 - acc: 0.9985     \n",
      "Epoch 281/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9978 - acc: 0.9985     \n",
      "Epoch 282/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9979 - acc: 0.9985     \n",
      "Epoch 283/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9945 - acc: 0.9990     \n",
      "Epoch 284/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9909 - acc: 0.9995     \n",
      "Epoch 285/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9898 - acc: 0.9990     \n",
      "Epoch 286/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9902 - acc: 0.9985     \n",
      "Epoch 287/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9874 - acc: 0.9990     \n",
      "Epoch 288/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9873 - acc: 0.9985     \n",
      "Epoch 289/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9826 - acc: 0.9990     \n",
      "Epoch 290/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9819 - acc: 0.9990     \n",
      "Epoch 291/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9803 - acc: 0.9990     \n",
      "Epoch 292/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9799 - acc: 0.9976     \n",
      "Epoch 293/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9787 - acc: 0.9981     \n",
      "Epoch 294/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9781 - acc: 0.9985     \n",
      "Epoch 295/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9741 - acc: 0.9990     \n",
      "Epoch 296/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9713 - acc: 0.9990     \n",
      "Epoch 297/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9735 - acc: 0.9985     \n",
      "Epoch 298/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9716 - acc: 0.9976     \n",
      "Epoch 299/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9682 - acc: 0.9990     \n",
      "Epoch 300/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9676 - acc: 0.9985     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 4s\n",
      "accuracy: 87.83505155868137\n",
      "precision: 89.13043478260869\n",
      "recall: 85.77405857740585\n",
      "f1_score: 87.42004264392324\n",
      "Training fold 7/10\n",
      "Epoch 1/300\n",
      "2064/2064 [==============================] - 1s - loss: 14.1333 - acc: 0.8469     \n",
      "Epoch 2/300\n",
      "2064/2064 [==============================] - 0s - loss: 11.7198 - acc: 0.9070     \n",
      "Epoch 3/300\n",
      "2064/2064 [==============================] - 0s - loss: 10.1108 - acc: 0.9293     \n",
      "Epoch 4/300\n",
      "2064/2064 [==============================] - 0s - loss: 8.9534 - acc: 0.9385     \n",
      "Epoch 5/300\n",
      "2064/2064 [==============================] - 0s - loss: 8.0863 - acc: 0.9438     \n",
      "Epoch 6/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.3949 - acc: 0.9501     \n",
      "Epoch 7/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.8454 - acc: 0.9578     \n",
      "Epoch 8/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.3893 - acc: 0.9612     \n",
      "Epoch 9/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.0166 - acc: 0.9593     \n",
      "Epoch 10/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.6730 - acc: 0.9695     \n",
      "Epoch 11/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.4031 - acc: 0.9637     \n",
      "Epoch 12/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.1498 - acc: 0.9709     \n",
      "Epoch 13/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.9360 - acc: 0.9719     \n",
      "Epoch 14/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.7388 - acc: 0.9729     \n",
      "Epoch 15/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.5647 - acc: 0.9753     \n",
      "Epoch 16/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.4044 - acc: 0.9767     \n",
      "Epoch 17/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.2610 - acc: 0.9782     \n",
      "Epoch 18/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.1337 - acc: 0.9806     \n",
      "Epoch 19/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.0171 - acc: 0.9767     \n",
      "Epoch 20/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.9072 - acc: 0.9767     \n",
      "Epoch 21/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.8010 - acc: 0.9830     \n",
      "Epoch 22/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.7085 - acc: 0.9821     \n",
      "Epoch 23/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.6198 - acc: 0.9845     \n",
      "Epoch 24/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.5466 - acc: 0.9806     \n",
      "Epoch 25/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.4669 - acc: 0.9797     \n",
      "Epoch 26/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.3856 - acc: 0.9855     \n",
      "Epoch 27/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.3248 - acc: 0.9859     \n",
      "Epoch 28/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2536 - acc: 0.9879     \n",
      "Epoch 29/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2016 - acc: 0.9850     \n",
      "Epoch 30/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1471 - acc: 0.9835     \n",
      "Epoch 31/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0951 - acc: 0.9826     \n",
      "Epoch 32/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0371 - acc: 0.9884     \n",
      "Epoch 33/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9890 - acc: 0.9884     \n",
      "Epoch 34/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9447 - acc: 0.9879     \n",
      "Epoch 35/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9027 - acc: 0.9884     \n",
      "Epoch 36/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8543 - acc: 0.9898     \n",
      "Epoch 37/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8170 - acc: 0.9908     \n",
      "Epoch 38/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7847 - acc: 0.9879     \n",
      "Epoch 39/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7437 - acc: 0.9884     \n",
      "Epoch 40/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7035 - acc: 0.9898     \n",
      "Epoch 41/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6692 - acc: 0.9908     \n",
      "Epoch 42/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6447 - acc: 0.9864     \n",
      "Epoch 43/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6077 - acc: 0.9922     \n",
      "Epoch 44/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5788 - acc: 0.9889     \n",
      "Epoch 45/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5483 - acc: 0.9893     \n",
      "Epoch 46/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5135 - acc: 0.9942     \n",
      "Epoch 47/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4920 - acc: 0.9908     \n",
      "Epoch 48/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4664 - acc: 0.9893     \n",
      "Epoch 49/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4398 - acc: 0.9913     \n",
      "Epoch 50/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4150 - acc: 0.9927     \n",
      "Epoch 51/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3909 - acc: 0.9927     \n",
      "Epoch 52/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3670 - acc: 0.9927     \n",
      "Epoch 53/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3432 - acc: 0.9898     \n",
      "Epoch 54/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3193 - acc: 0.9918     \n",
      "Epoch 55/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3028 - acc: 0.9922     \n",
      "Epoch 56/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2814 - acc: 0.9922     \n",
      "Epoch 57/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2647 - acc: 0.9913     \n",
      "Epoch 58/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2393 - acc: 0.9922     \n",
      "Epoch 59/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2188 - acc: 0.9927     \n",
      "Epoch 60/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1996 - acc: 0.9932     \n",
      "Epoch 61/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1793 - acc: 0.9952     \n",
      "Epoch 62/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1658 - acc: 0.9922     - ETA: 0s - loss: 2.1762 - a\n",
      "Epoch 63/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1506 - acc: 0.9927     \n",
      "Epoch 64/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1328 - acc: 0.9913     \n",
      "Epoch 65/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1127 - acc: 0.9961     \n",
      "Epoch 66/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0975 - acc: 0.9922     \n",
      "Epoch 67/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0800 - acc: 0.9942     \n",
      "Epoch 68/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0645 - acc: 0.9952     \n",
      "Epoch 69/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0511 - acc: 0.9932     \n",
      "Epoch 70/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0376 - acc: 0.9942     \n",
      "Epoch 71/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0186 - acc: 0.9942     \n",
      "Epoch 72/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0086 - acc: 0.9927     \n",
      "Epoch 73/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9960 - acc: 0.9922     \n",
      "Epoch 74/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9812 - acc: 0.9947     \n",
      "Epoch 75/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9701 - acc: 0.9927     \n",
      "Epoch 76/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9543 - acc: 0.9961     \n",
      "Epoch 77/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9422 - acc: 0.9952     \n",
      "Epoch 78/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9247 - acc: 0.9971     \n",
      "Epoch 79/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9148 - acc: 0.9952     \n",
      "Epoch 80/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9030 - acc: 0.9961     \n",
      "Epoch 81/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8948 - acc: 0.9942     \n",
      "Epoch 82/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8841 - acc: 0.9922     \n",
      "Epoch 83/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8769 - acc: 0.9903     \n",
      "Epoch 84/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8575 - acc: 0.9956     \n",
      "Epoch 85/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8518 - acc: 0.9932     \n",
      "Epoch 86/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8381 - acc: 0.9971     \n",
      "Epoch 87/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8297 - acc: 0.9961     \n",
      "Epoch 88/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8182 - acc: 0.9956     \n",
      "Epoch 89/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8110 - acc: 0.9942     \n",
      "Epoch 90/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7985 - acc: 0.9952     \n",
      "Epoch 91/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7856 - acc: 0.9966     \n",
      "Epoch 92/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7786 - acc: 0.9956     \n",
      "Epoch 93/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7688 - acc: 0.9952     \n",
      "Epoch 94/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7592 - acc: 0.9956     \n",
      "Epoch 95/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7506 - acc: 0.9971     \n",
      "Epoch 96/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7401 - acc: 0.9956     \n",
      "Epoch 97/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7330 - acc: 0.9961     \n",
      "Epoch 98/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7221 - acc: 0.9966     \n",
      "Epoch 99/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7162 - acc: 0.9942     \n",
      "Epoch 100/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7090 - acc: 0.9927     \n",
      "Epoch 101/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6999 - acc: 0.9947     \n",
      "Epoch 102/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6903 - acc: 0.9971     \n",
      "Epoch 103/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6795 - acc: 0.9971     \n",
      "Epoch 104/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6706 - acc: 0.9976     \n",
      "Epoch 105/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6642 - acc: 0.9952     \n",
      "Epoch 106/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6590 - acc: 0.9971     \n",
      "Epoch 107/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6495 - acc: 0.9971     \n",
      "Epoch 108/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6389 - acc: 0.9981     \n",
      "Epoch 109/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6364 - acc: 0.9952     \n",
      "Epoch 110/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6259 - acc: 0.9976     \n",
      "Epoch 111/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6214 - acc: 0.9961     \n",
      "Epoch 112/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6133 - acc: 0.9956     \n",
      "Epoch 113/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6043 - acc: 0.9966     \n",
      "Epoch 114/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5955 - acc: 0.9976     \n",
      "Epoch 115/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5930 - acc: 0.9971     \n",
      "Epoch 116/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5879 - acc: 0.9952     \n",
      "Epoch 117/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5796 - acc: 0.9961     \n",
      "Epoch 118/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5716 - acc: 0.9971     \n",
      "Epoch 119/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5686 - acc: 0.9947     \n",
      "Epoch 120/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5601 - acc: 0.9971     \n",
      "Epoch 121/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5502 - acc: 0.9971     \n",
      "Epoch 122/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5444 - acc: 0.9971     \n",
      "Epoch 123/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5377 - acc: 0.9981     \n",
      "Epoch 124/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5339 - acc: 0.9961     \n",
      "Epoch 125/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5277 - acc: 0.9976     \n",
      "Epoch 126/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5228 - acc: 0.9971     \n",
      "Epoch 127/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5139 - acc: 0.9971     \n",
      "Epoch 128/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5096 - acc: 0.9966     \n",
      "Epoch 129/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5014 - acc: 0.9981     \n",
      "Epoch 130/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4987 - acc: 0.9956     \n",
      "Epoch 131/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4871 - acc: 0.9976     \n",
      "Epoch 132/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4898 - acc: 0.9947     \n",
      "Epoch 133/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4804 - acc: 0.9981     \n",
      "Epoch 134/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4759 - acc: 0.9961     \n",
      "Epoch 135/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4696 - acc: 0.9981     \n",
      "Epoch 136/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4620 - acc: 0.9971     \n",
      "Epoch 137/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4607 - acc: 0.9966     \n",
      "Epoch 138/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4554 - acc: 0.9966     \n",
      "Epoch 139/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4476 - acc: 0.9966     \n",
      "Epoch 140/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4465 - acc: 0.9961     \n",
      "Epoch 141/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4352 - acc: 0.9981     \n",
      "Epoch 142/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4336 - acc: 0.9971     \n",
      "Epoch 143/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4264 - acc: 0.9981     \n",
      "Epoch 144/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4226 - acc: 0.9981     \n",
      "Epoch 145/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4170 - acc: 0.9990     - ETA: 0s - loss: 1.4235 - a\n",
      "Epoch 146/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4125 - acc: 0.9971     \n",
      "Epoch 147/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 1.4061 - acc: 0.9985     \n",
      "Epoch 148/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4030 - acc: 0.9971     \n",
      "Epoch 149/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3987 - acc: 0.9981     \n",
      "Epoch 150/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3926 - acc: 0.9971     \n",
      "Epoch 151/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3887 - acc: 0.9976     \n",
      "Epoch 152/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3841 - acc: 0.9966     - ETA: 0s - loss: 1.3822 - \n",
      "Epoch 153/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3799 - acc: 0.9981     \n",
      "Epoch 154/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3771 - acc: 0.9971     \n",
      "Epoch 155/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3702 - acc: 0.9990     \n",
      "Epoch 156/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3637 - acc: 0.9981     \n",
      "Epoch 157/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3620 - acc: 0.9966     \n",
      "Epoch 158/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3568 - acc: 0.9971     \n",
      "Epoch 159/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3541 - acc: 0.9981     \n",
      "Epoch 160/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3520 - acc: 0.9966     \n",
      "Epoch 161/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3461 - acc: 0.9971     \n",
      "Epoch 162/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3398 - acc: 0.9985     \n",
      "Epoch 163/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3364 - acc: 0.9981     \n",
      "Epoch 164/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3313 - acc: 0.9976     \n",
      "Epoch 165/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3288 - acc: 0.9971     \n",
      "Epoch 166/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3263 - acc: 0.9976     \n",
      "Epoch 167/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3200 - acc: 0.9985     \n",
      "Epoch 168/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3159 - acc: 0.9971     \n",
      "Epoch 169/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3116 - acc: 0.9971     \n",
      "Epoch 170/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3092 - acc: 0.9985     \n",
      "Epoch 171/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3045 - acc: 0.9985     \n",
      "Epoch 172/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2983 - acc: 0.9985     \n",
      "Epoch 173/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2986 - acc: 0.9966     \n",
      "Epoch 174/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2934 - acc: 0.9981     \n",
      "Epoch 175/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2895 - acc: 0.9981     \n",
      "Epoch 176/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2846 - acc: 0.9981     \n",
      "Epoch 177/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2811 - acc: 0.9985     \n",
      "Epoch 178/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2793 - acc: 0.9985     \n",
      "Epoch 179/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2754 - acc: 0.9981     \n",
      "Epoch 180/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2715 - acc: 0.9985     \n",
      "Epoch 181/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2689 - acc: 0.9981     \n",
      "Epoch 182/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2658 - acc: 0.9976     \n",
      "Epoch 183/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2608 - acc: 0.9981     \n",
      "Epoch 184/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2596 - acc: 0.9976     \n",
      "Epoch 185/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2560 - acc: 0.9985     \n",
      "Epoch 186/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2512 - acc: 0.9976     \n",
      "Epoch 187/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2482 - acc: 0.9976     \n",
      "Epoch 188/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2438 - acc: 0.9976     \n",
      "Epoch 189/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2415 - acc: 0.9985     \n",
      "Epoch 190/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2376 - acc: 0.9981     \n",
      "Epoch 191/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2354 - acc: 0.9966     \n",
      "Epoch 192/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2335 - acc: 0.9966     \n",
      "Epoch 193/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2294 - acc: 0.9981     \n",
      "Epoch 194/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2247 - acc: 0.9985     \n",
      "Epoch 195/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2215 - acc: 0.9981     \n",
      "Epoch 196/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2209 - acc: 0.9976     \n",
      "Epoch 197/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2164 - acc: 0.9981     \n",
      "Epoch 198/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2140 - acc: 0.9981     \n",
      "Epoch 199/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2145 - acc: 0.9981     \n",
      "Epoch 200/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2088 - acc: 0.9971     \n",
      "Epoch 201/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2061 - acc: 0.9985     \n",
      "Epoch 202/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2038 - acc: 0.9976     \n",
      "Epoch 203/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2001 - acc: 0.9981     \n",
      "Epoch 204/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1989 - acc: 0.9981     \n",
      "Epoch 205/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1939 - acc: 0.9976     \n",
      "Epoch 206/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1917 - acc: 0.9966     \n",
      "Epoch 207/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1865 - acc: 0.9990     \n",
      "Epoch 208/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1838 - acc: 0.9981     \n",
      "Epoch 209/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1839 - acc: 0.9966     \n",
      "Epoch 210/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1799 - acc: 0.9985     \n",
      "Epoch 211/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1774 - acc: 0.9971     \n",
      "Epoch 212/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1750 - acc: 0.9990     \n",
      "Epoch 213/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1749 - acc: 0.9961     \n",
      "Epoch 214/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1698 - acc: 0.9981     \n",
      "Epoch 215/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1641 - acc: 0.9981     \n",
      "Epoch 216/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1633 - acc: 0.9976     \n",
      "Epoch 217/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1610 - acc: 0.9976     \n",
      "Epoch 218/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1596 - acc: 0.9981     \n",
      "Epoch 219/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1547 - acc: 0.9990     \n",
      "Epoch 220/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1542 - acc: 0.9976     \n",
      "Epoch 221/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1513 - acc: 0.9981     \n",
      "Epoch 222/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1513 - acc: 0.9981     \n",
      "Epoch 223/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1475 - acc: 0.9985     - ETA: 0s - loss: 1.1473 - acc:\n",
      "Epoch 224/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1426 - acc: 0.9985     \n",
      "Epoch 225/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1419 - acc: 0.9981     \n",
      "Epoch 226/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1378 - acc: 0.9990     \n",
      "Epoch 227/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1369 - acc: 0.9985     \n",
      "Epoch 228/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1349 - acc: 0.9985     \n",
      "Epoch 229/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1343 - acc: 0.9976     \n",
      "Epoch 230/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1262 - acc: 0.9990     \n",
      "Epoch 231/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1249 - acc: 0.9985     \n",
      "Epoch 232/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1247 - acc: 0.9976     \n",
      "Epoch 233/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1208 - acc: 0.9971     \n",
      "Epoch 234/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1201 - acc: 0.9985     \n",
      "Epoch 235/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1187 - acc: 0.9985     \n",
      "Epoch 236/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1144 - acc: 0.9985     \n",
      "Epoch 237/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1137 - acc: 0.9990     \n",
      "Epoch 238/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1117 - acc: 0.9981     \n",
      "Epoch 239/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1081 - acc: 0.9985     \n",
      "Epoch 240/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1060 - acc: 0.9985     \n",
      "Epoch 241/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1020 - acc: 0.9990     \n",
      "Epoch 242/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1010 - acc: 0.9976     \n",
      "Epoch 243/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0972 - acc: 0.9981     \n",
      "Epoch 244/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0967 - acc: 0.9985     \n",
      "Epoch 245/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0930 - acc: 0.9990     \n",
      "Epoch 246/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0922 - acc: 0.9985     \n",
      "Epoch 247/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0910 - acc: 0.9976     \n",
      "Epoch 248/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0857 - acc: 0.9990     \n",
      "Epoch 249/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0863 - acc: 0.9990     \n",
      "Epoch 250/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0856 - acc: 0.9981     \n",
      "Epoch 251/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0837 - acc: 0.9976     \n",
      "Epoch 252/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0783 - acc: 0.9990     \n",
      "Epoch 253/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0770 - acc: 0.9990     \n",
      "Epoch 254/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0814 - acc: 0.9971     \n",
      "Epoch 255/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0717 - acc: 0.9990     \n",
      "Epoch 256/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0713 - acc: 0.9995     \n",
      "Epoch 257/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0716 - acc: 0.9966     \n",
      "Epoch 258/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0667 - acc: 0.9981     \n",
      "Epoch 259/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0674 - acc: 0.9985     \n",
      "Epoch 260/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0622 - acc: 0.9990     \n",
      "Epoch 261/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0636 - acc: 0.9976     \n",
      "Epoch 262/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0605 - acc: 0.9976     \n",
      "Epoch 263/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0557 - acc: 0.9985     \n",
      "Epoch 264/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0554 - acc: 0.9985     \n",
      "Epoch 265/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0531 - acc: 0.9990     \n",
      "Epoch 266/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0510 - acc: 0.9985     \n",
      "Epoch 267/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0486 - acc: 0.9985     \n",
      "Epoch 268/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0468 - acc: 0.9985     \n",
      "Epoch 269/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0448 - acc: 0.9981     \n",
      "Epoch 270/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0446 - acc: 0.9985     \n",
      "Epoch 271/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0416 - acc: 0.9990     \n",
      "Epoch 272/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0403 - acc: 0.9990     \n",
      "Epoch 273/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0376 - acc: 0.9990     \n",
      "Epoch 274/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0365 - acc: 0.9990     \n",
      "Epoch 275/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0344 - acc: 0.9985     \n",
      "Epoch 276/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0332 - acc: 0.9990     \n",
      "Epoch 277/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0313 - acc: 0.9990     \n",
      "Epoch 278/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0295 - acc: 0.9981     \n",
      "Epoch 279/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0270 - acc: 0.9985     \n",
      "Epoch 280/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0243 - acc: 0.9985     \n",
      "Epoch 281/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0224 - acc: 0.9990     \n",
      "Epoch 282/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0203 - acc: 0.9985     \n",
      "Epoch 283/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0201 - acc: 0.9985     \n",
      "Epoch 284/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0190 - acc: 0.9985     \n",
      "Epoch 285/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0156 - acc: 0.9990     \n",
      "Epoch 286/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0145 - acc: 0.9990     \n",
      "Epoch 287/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0113 - acc: 0.9995     \n",
      "Epoch 288/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0123 - acc: 0.9981     \n",
      "Epoch 289/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0062 - acc: 0.9995     \n",
      "Epoch 290/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0086 - acc: 0.9990     \n",
      "Epoch 291/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0061 - acc: 0.9985     \n",
      "Epoch 292/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0064 - acc: 0.9981     \n",
      "Epoch 293/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0006 - acc: 0.9985     \n",
      "Epoch 294/300\n",
      "2064/2064 [==============================] - ETA: 0s - loss: 0.9996 - acc: 0.999 - 0s - loss: 0.9995 - acc: 0.9990     \n",
      "Epoch 295/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9983 - acc: 0.9981     \n",
      "Epoch 296/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9969 - acc: 0.9985     \n",
      "Epoch 297/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9927 - acc: 0.9995     \n",
      "Epoch 298/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9926 - acc: 0.9990     \n",
      "Epoch 299/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9908 - acc: 0.9985     \n",
      "Epoch 300/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9902 - acc: 0.9981     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 5s\n",
      "accuracy: 88.4536082597123\n",
      "precision: 88.93617021276596\n",
      "recall: 87.44769874476988\n",
      "f1_score: 88.1856540084388\n",
      "Training fold 8/10\n",
      "Epoch 1/300\n",
      "2064/2064 [==============================] - 1s - loss: 14.1283 - acc: 0.8362     \n",
      "Epoch 2/300\n",
      "2064/2064 [==============================] - 0s - loss: 11.6100 - acc: 0.8997     \n",
      "Epoch 3/300\n",
      "2064/2064 [==============================] - 0s - loss: 9.9634 - acc: 0.9244     \n",
      "Epoch 4/300\n",
      "2064/2064 [==============================] - 0s - loss: 8.7940 - acc: 0.9234     \n",
      "Epoch 5/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.9031 - acc: 0.9419     \n",
      "Epoch 6/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.2217 - acc: 0.9433     \n",
      "Epoch 7/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.6667 - acc: 0.9506     \n",
      "Epoch 8/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.2056 - acc: 0.9637     \n",
      "Epoch 9/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.8232 - acc: 0.9622     \n",
      "Epoch 10/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.5053 - acc: 0.9578     \n",
      "Epoch 11/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.2257 - acc: 0.9641     \n",
      "Epoch 12/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.9771 - acc: 0.9675     \n",
      "Epoch 13/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.7669 - acc: 0.9675     \n",
      "Epoch 14/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 4.5712 - acc: 0.9738     \n",
      "Epoch 15/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.4109 - acc: 0.9690     \n",
      "Epoch 16/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.2462 - acc: 0.9729     \n",
      "Epoch 17/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.1148 - acc: 0.9729     \n",
      "Epoch 18/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.9892 - acc: 0.9738     \n",
      "Epoch 19/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.8735 - acc: 0.9714     \n",
      "Epoch 20/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.7674 - acc: 0.9758     \n",
      "Epoch 21/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.6740 - acc: 0.9734     \n",
      "Epoch 22/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.5806 - acc: 0.9797     \n",
      "Epoch 23/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.4942 - acc: 0.9806     \n",
      "Epoch 24/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.4130 - acc: 0.9835     \n",
      "Epoch 25/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.3403 - acc: 0.9840     \n",
      "Epoch 26/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2768 - acc: 0.9811     \n",
      "Epoch 27/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2127 - acc: 0.9811     \n",
      "Epoch 28/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1538 - acc: 0.9806     \n",
      "Epoch 29/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0977 - acc: 0.9806     \n",
      "Epoch 30/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0386 - acc: 0.9864     \n",
      "Epoch 31/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9907 - acc: 0.9845     \n",
      "Epoch 32/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9432 - acc: 0.9850     \n",
      "Epoch 33/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8974 - acc: 0.9821     \n",
      "Epoch 34/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8557 - acc: 0.9850     \n",
      "Epoch 35/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8162 - acc: 0.9850     \n",
      "Epoch 36/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7727 - acc: 0.9889     \n",
      "Epoch 37/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7307 - acc: 0.9922     \n",
      "Epoch 38/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6946 - acc: 0.9889     \n",
      "Epoch 39/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6693 - acc: 0.9830     \n",
      "Epoch 40/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6307 - acc: 0.9850     \n",
      "Epoch 41/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6014 - acc: 0.9855     \n",
      "Epoch 42/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5644 - acc: 0.9918     \n",
      "Epoch 43/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5371 - acc: 0.9893     \n",
      "Epoch 44/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5152 - acc: 0.9840     \n",
      "Epoch 45/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4810 - acc: 0.9903     \n",
      "Epoch 46/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4548 - acc: 0.9898     \n",
      "Epoch 47/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4310 - acc: 0.9889     \n",
      "Epoch 48/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4065 - acc: 0.9879     \n",
      "Epoch 49/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3809 - acc: 0.9879     \n",
      "Epoch 50/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3595 - acc: 0.9898     \n",
      "Epoch 51/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3337 - acc: 0.9889     \n",
      "Epoch 52/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3084 - acc: 0.9927     \n",
      "Epoch 53/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2906 - acc: 0.9927     \n",
      "Epoch 54/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2737 - acc: 0.9893     \n",
      "Epoch 55/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2465 - acc: 0.9932     \n",
      "Epoch 56/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2332 - acc: 0.9898     \n",
      "Epoch 57/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2154 - acc: 0.9898     \n",
      "Epoch 58/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1946 - acc: 0.9903     \n",
      "Epoch 59/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1718 - acc: 0.9942     \n",
      "Epoch 60/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1546 - acc: 0.9927     \n",
      "Epoch 61/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1394 - acc: 0.9932     \n",
      "Epoch 62/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1216 - acc: 0.9932     \n",
      "Epoch 63/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1045 - acc: 0.9947     \n",
      "Epoch 64/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0883 - acc: 0.9922     \n",
      "Epoch 65/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0708 - acc: 0.9942     \n",
      "Epoch 66/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0611 - acc: 0.9898     \n",
      "Epoch 67/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0421 - acc: 0.9937     \n",
      "Epoch 68/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0308 - acc: 0.9952     \n",
      "Epoch 69/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0146 - acc: 0.9922     \n",
      "Epoch 70/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9989 - acc: 0.9947     \n",
      "Epoch 71/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9868 - acc: 0.9922     \n",
      "Epoch 72/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9707 - acc: 0.9952     \n",
      "Epoch 73/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9676 - acc: 0.9898     \n",
      "Epoch 74/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9462 - acc: 0.9937     \n",
      "Epoch 75/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9352 - acc: 0.9937     \n",
      "Epoch 76/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9240 - acc: 0.9966     \n",
      "Epoch 77/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9109 - acc: 0.9913     \n",
      "Epoch 78/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9004 - acc: 0.9932     \n",
      "Epoch 79/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8902 - acc: 0.9942     \n",
      "Epoch 80/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8752 - acc: 0.9961     \n",
      "Epoch 81/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8658 - acc: 0.9942     \n",
      "Epoch 82/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8519 - acc: 0.9932     \n",
      "Epoch 83/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8420 - acc: 0.9956     \n",
      "Epoch 84/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8341 - acc: 0.9927     \n",
      "Epoch 85/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8198 - acc: 0.9952     \n",
      "Epoch 86/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8122 - acc: 0.9937     \n",
      "Epoch 87/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8038 - acc: 0.9942     \n",
      "Epoch 88/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7907 - acc: 0.9952     \n",
      "Epoch 89/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7840 - acc: 0.9913     \n",
      "Epoch 90/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7731 - acc: 0.9956     \n",
      "Epoch 91/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7644 - acc: 0.9956     \n",
      "Epoch 92/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7543 - acc: 0.9942     \n",
      "Epoch 93/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7436 - acc: 0.9966     \n",
      "Epoch 94/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7324 - acc: 0.9976     \n",
      "Epoch 95/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7262 - acc: 0.9942     \n",
      "Epoch 96/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7238 - acc: 0.9942     \n",
      "Epoch 97/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7108 - acc: 0.9922     \n",
      "Epoch 98/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7026 - acc: 0.9952     \n",
      "Epoch 99/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6903 - acc: 0.9966     \n",
      "Epoch 100/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6892 - acc: 0.9942     \n",
      "Epoch 101/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6761 - acc: 0.9971     \n",
      "Epoch 102/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6678 - acc: 0.9961     \n",
      "Epoch 103/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6650 - acc: 0.9942     \n",
      "Epoch 104/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6545 - acc: 0.9961     \n",
      "Epoch 105/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6469 - acc: 0.9942     \n",
      "Epoch 106/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6401 - acc: 0.9966     \n",
      "Epoch 107/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6314 - acc: 0.9976     \n",
      "Epoch 108/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6252 - acc: 0.9966     \n",
      "Epoch 109/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6168 - acc: 0.9961     \n",
      "Epoch 110/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6081 - acc: 0.9971     \n",
      "Epoch 111/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6011 - acc: 0.9971     \n",
      "Epoch 112/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5977 - acc: 0.9937     \n",
      "Epoch 113/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5891 - acc: 0.9976     \n",
      "Epoch 114/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5895 - acc: 0.9942     \n",
      "Epoch 115/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5768 - acc: 0.9966     \n",
      "Epoch 116/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5688 - acc: 0.9976     \n",
      "Epoch 117/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5655 - acc: 0.9961     \n",
      "Epoch 118/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5595 - acc: 0.9961     \n",
      "Epoch 119/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5508 - acc: 0.9971     \n",
      "Epoch 120/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5453 - acc: 0.9947     \n",
      "Epoch 121/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5358 - acc: 0.9966     \n",
      "Epoch 122/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5311 - acc: 0.9976     \n",
      "Epoch 123/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5231 - acc: 0.9981     \n",
      "Epoch 124/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5289 - acc: 0.9942     \n",
      "Epoch 125/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5159 - acc: 0.9966     \n",
      "Epoch 126/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5115 - acc: 0.9961     \n",
      "Epoch 127/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5035 - acc: 0.9971     \n",
      "Epoch 128/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4973 - acc: 0.9966     \n",
      "Epoch 129/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4924 - acc: 0.9966     \n",
      "Epoch 130/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4870 - acc: 0.9981     \n",
      "Epoch 131/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4851 - acc: 0.9956     \n",
      "Epoch 132/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4762 - acc: 0.9976     \n",
      "Epoch 133/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4711 - acc: 0.9971     \n",
      "Epoch 134/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4687 - acc: 0.9956     \n",
      "Epoch 135/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4610 - acc: 0.9981     \n",
      "Epoch 136/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4552 - acc: 0.9971     \n",
      "Epoch 137/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4512 - acc: 0.9976     \n",
      "Epoch 138/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4489 - acc: 0.9952     \n",
      "Epoch 139/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4409 - acc: 0.9981     \n",
      "Epoch 140/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4348 - acc: 0.9981     \n",
      "Epoch 141/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4291 - acc: 0.9966     \n",
      "Epoch 142/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4334 - acc: 0.9937     \n",
      "Epoch 143/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4233 - acc: 0.9976     \n",
      "Epoch 144/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4163 - acc: 0.9985     \n",
      "Epoch 145/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4123 - acc: 0.9971     \n",
      "Epoch 146/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4082 - acc: 0.9966     \n",
      "Epoch 147/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4012 - acc: 0.9976     \n",
      "Epoch 148/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4025 - acc: 0.9966     \n",
      "Epoch 149/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3969 - acc: 0.9956     \n",
      "Epoch 150/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3912 - acc: 0.9981     \n",
      "Epoch 151/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3861 - acc: 0.9971     \n",
      "Epoch 152/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3830 - acc: 0.9971     \n",
      "Epoch 153/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3792 - acc: 0.9985     \n",
      "Epoch 154/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3705 - acc: 0.9985     \n",
      "Epoch 155/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3707 - acc: 0.9981     \n",
      "Epoch 156/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3656 - acc: 0.9966     \n",
      "Epoch 157/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3611 - acc: 0.9971     \n",
      "Epoch 158/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3607 - acc: 0.9971     \n",
      "Epoch 159/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3530 - acc: 0.9985     \n",
      "Epoch 160/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3559 - acc: 0.9942     \n",
      "Epoch 161/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3465 - acc: 0.9961     \n",
      "Epoch 162/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3420 - acc: 0.9981     \n",
      "Epoch 163/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3407 - acc: 0.9961     \n",
      "Epoch 164/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3352 - acc: 0.9981     \n",
      "Epoch 165/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3289 - acc: 0.9971     \n",
      "Epoch 166/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3285 - acc: 0.9966     \n",
      "Epoch 167/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3223 - acc: 0.9990     \n",
      "Epoch 168/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3226 - acc: 0.9952     \n",
      "Epoch 169/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3198 - acc: 0.9966     \n",
      "Epoch 170/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3137 - acc: 0.9976     \n",
      "Epoch 171/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3101 - acc: 0.9971     \n",
      "Epoch 172/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3063 - acc: 0.9985     \n",
      "Epoch 173/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3052 - acc: 0.9971     \n",
      "Epoch 174/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3015 - acc: 0.9976     \n",
      "Epoch 175/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2942 - acc: 0.9981     \n",
      "Epoch 176/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2933 - acc: 0.9981     \n",
      "Epoch 177/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2896 - acc: 0.9966     \n",
      "Epoch 178/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2873 - acc: 0.9981     \n",
      "Epoch 179/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2828 - acc: 0.9981     \n",
      "Epoch 180/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2809 - acc: 0.9981     \n",
      "Epoch 181/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2760 - acc: 0.9981     \n",
      "Epoch 182/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2756 - acc: 0.9985     \n",
      "Epoch 183/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2718 - acc: 0.9971     \n",
      "Epoch 184/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2662 - acc: 0.9976     \n",
      "Epoch 185/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 1.2632 - acc: 0.9976     \n",
      "Epoch 186/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2606 - acc: 0.9976     \n",
      "Epoch 187/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2566 - acc: 0.9976     \n",
      "Epoch 188/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2549 - acc: 0.9976     \n",
      "Epoch 189/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2503 - acc: 0.9981     \n",
      "Epoch 190/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2466 - acc: 0.9985     \n",
      "Epoch 191/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2464 - acc: 0.9985     \n",
      "Epoch 192/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2420 - acc: 0.9981     \n",
      "Epoch 193/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2392 - acc: 0.9976     \n",
      "Epoch 194/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2361 - acc: 0.9971     \n",
      "Epoch 195/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2348 - acc: 0.9981     \n",
      "Epoch 196/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2284 - acc: 0.9976     \n",
      "Epoch 197/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2281 - acc: 0.9981     \n",
      "Epoch 198/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2235 - acc: 0.9985     \n",
      "Epoch 199/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2240 - acc: 0.9976     \n",
      "Epoch 200/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2180 - acc: 0.9985     \n",
      "Epoch 201/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2162 - acc: 0.9976     \n",
      "Epoch 202/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2139 - acc: 0.9981     \n",
      "Epoch 203/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2111 - acc: 0.9971     \n",
      "Epoch 204/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2076 - acc: 0.9990     \n",
      "Epoch 205/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2035 - acc: 0.9985     \n",
      "Epoch 206/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1999 - acc: 0.9976     \n",
      "Epoch 207/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2016 - acc: 0.9952     \n",
      "Epoch 208/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1976 - acc: 0.9976     \n",
      "Epoch 209/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1936 - acc: 0.9985     \n",
      "Epoch 210/300\n",
      "2064/2064 [==============================] - ETA: 0s - loss: 1.1911 - acc: 0.998 - 0s - loss: 1.1910 - acc: 0.9981     \n",
      "Epoch 211/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1880 - acc: 0.9985     \n",
      "Epoch 212/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1866 - acc: 0.9985     \n",
      "Epoch 213/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1829 - acc: 0.9981     \n",
      "Epoch 214/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1835 - acc: 0.9981     \n",
      "Epoch 215/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1802 - acc: 0.9981     \n",
      "Epoch 216/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1758 - acc: 0.9985     \n",
      "Epoch 217/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1741 - acc: 0.9985     \n",
      "Epoch 218/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1709 - acc: 0.9976     \n",
      "Epoch 219/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1675 - acc: 0.9985     \n",
      "Epoch 220/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1640 - acc: 0.9990     \n",
      "Epoch 221/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1632 - acc: 0.9985     - ETA: 0s - loss: 1.1661 - a\n",
      "Epoch 222/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1609 - acc: 0.9981     \n",
      "Epoch 223/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1615 - acc: 0.9966     \n",
      "Epoch 224/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1574 - acc: 0.9985     \n",
      "Epoch 225/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1554 - acc: 0.9981     \n",
      "Epoch 226/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1510 - acc: 0.9985     \n",
      "Epoch 227/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1499 - acc: 0.9985     \n",
      "Epoch 228/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1461 - acc: 0.9981     \n",
      "Epoch 229/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1438 - acc: 0.9981     \n",
      "Epoch 230/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1442 - acc: 0.9966     \n",
      "Epoch 231/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1420 - acc: 0.9981     \n",
      "Epoch 232/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1369 - acc: 0.9976     \n",
      "Epoch 233/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1381 - acc: 0.9976     \n",
      "Epoch 234/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1338 - acc: 0.9981     \n",
      "Epoch 235/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1359 - acc: 0.9952     \n",
      "Epoch 236/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1299 - acc: 0.9981     \n",
      "Epoch 237/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1276 - acc: 0.9981     \n",
      "Epoch 238/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1236 - acc: 0.9976     \n",
      "Epoch 239/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1240 - acc: 0.9971     \n",
      "Epoch 240/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1198 - acc: 0.9981     \n",
      "Epoch 241/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1195 - acc: 0.9976     \n",
      "Epoch 242/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1156 - acc: 0.9981     \n",
      "Epoch 243/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1133 - acc: 0.9985     \n",
      "Epoch 244/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1106 - acc: 0.9990     \n",
      "Epoch 245/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1100 - acc: 0.9990     \n",
      "Epoch 246/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1078 - acc: 0.9990     \n",
      "Epoch 247/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1039 - acc: 0.9985     \n",
      "Epoch 248/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1032 - acc: 0.9990     \n",
      "Epoch 249/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1028 - acc: 0.9985     \n",
      "Epoch 250/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0993 - acc: 0.9981     \n",
      "Epoch 251/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0962 - acc: 0.9985     \n",
      "Epoch 252/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0979 - acc: 0.9971     \n",
      "Epoch 253/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0925 - acc: 0.9990     \n",
      "Epoch 254/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0919 - acc: 0.9985     \n",
      "Epoch 255/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0907 - acc: 0.9971     \n",
      "Epoch 256/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0885 - acc: 0.9985     \n",
      "Epoch 257/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0866 - acc: 0.9976     \n",
      "Epoch 258/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0843 - acc: 0.9981     \n",
      "Epoch 259/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0834 - acc: 0.9985     \n",
      "Epoch 260/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0794 - acc: 0.9971     \n",
      "Epoch 261/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0783 - acc: 0.9981     \n",
      "Epoch 262/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0765 - acc: 0.9976     \n",
      "Epoch 263/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0742 - acc: 0.9976     \n",
      "Epoch 264/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0735 - acc: 0.9981     \n",
      "Epoch 265/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0743 - acc: 0.9971     \n",
      "Epoch 266/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0692 - acc: 0.9985     \n",
      "Epoch 267/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0680 - acc: 0.9990     \n",
      "Epoch 268/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0644 - acc: 0.9981     \n",
      "Epoch 269/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0624 - acc: 0.9990     \n",
      "Epoch 270/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0614 - acc: 0.9985     \n",
      "Epoch 271/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0580 - acc: 0.9981     \n",
      "Epoch 272/300\n",
      "2064/2064 [==============================] - ETA: 0s - loss: 1.0569 - acc: 0.998 - 0s - loss: 1.0569 - acc: 0.9985     \n",
      "Epoch 273/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0582 - acc: 0.9971     \n",
      "Epoch 274/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0553 - acc: 0.9981     \n",
      "Epoch 275/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0506 - acc: 0.9985     \n",
      "Epoch 276/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0515 - acc: 0.9990     \n",
      "Epoch 277/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0483 - acc: 0.9985     \n",
      "Epoch 278/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0465 - acc: 0.9990     \n",
      "Epoch 279/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0463 - acc: 0.9985     \n",
      "Epoch 280/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0443 - acc: 0.9981     \n",
      "Epoch 281/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0404 - acc: 0.9990     \n",
      "Epoch 282/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0418 - acc: 0.9981     \n",
      "Epoch 283/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0370 - acc: 0.9976     \n",
      "Epoch 284/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0352 - acc: 0.9985     \n",
      "Epoch 285/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0339 - acc: 0.9985     \n",
      "Epoch 286/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0327 - acc: 0.9981     \n",
      "Epoch 287/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0316 - acc: 0.9990     \n",
      "Epoch 288/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0311 - acc: 0.9981     \n",
      "Epoch 289/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0291 - acc: 0.9976     \n",
      "Epoch 290/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0275 - acc: 0.9976     \n",
      "Epoch 291/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0243 - acc: 0.9990     \n",
      "Epoch 292/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0225 - acc: 0.9985     \n",
      "Epoch 293/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0207 - acc: 0.9985     \n",
      "Epoch 294/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0237 - acc: 0.9976     \n",
      "Epoch 295/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0185 - acc: 0.9981     \n",
      "Epoch 296/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0156 - acc: 0.9995     \n",
      "Epoch 297/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0197 - acc: 0.9971     \n",
      "Epoch 298/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0138 - acc: 0.9976     \n",
      "Epoch 299/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0132 - acc: 0.9981     \n",
      "Epoch 300/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0117 - acc: 0.9985     \n",
      "# # # Evaluating cv-fold...\n",
      "416/485 [========================>.....] - ETA: 0s\n",
      "accuracy: 88.24742269270199\n",
      "precision: 89.56521739130436\n",
      "recall: 86.19246861924687\n",
      "f1_score: 87.84648187633262\n",
      "Training fold 9/10\n",
      "Epoch 1/300\n",
      "2064/2064 [==============================] - 1s - loss: 14.0968 - acc: 0.8391     \n",
      "Epoch 2/300\n",
      "2064/2064 [==============================] - 0s - loss: 11.6034 - acc: 0.9118     \n",
      "Epoch 3/300\n",
      "2064/2064 [==============================] - 0s - loss: 9.9909 - acc: 0.9191      \n",
      "Epoch 4/300\n",
      "2064/2064 [==============================] - 0s - loss: 8.8187 - acc: 0.9390     \n",
      "Epoch 5/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.9496 - acc: 0.9385     \n",
      "Epoch 6/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.2540 - acc: 0.9530     \n",
      "Epoch 7/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.7040 - acc: 0.9564     \n",
      "Epoch 8/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.2352 - acc: 0.9617     \n",
      "Epoch 9/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.8607 - acc: 0.9588     \n",
      "Epoch 10/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.5331 - acc: 0.9617     \n",
      "Epoch 11/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.2465 - acc: 0.9671     \n",
      "Epoch 12/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.0063 - acc: 0.9622     \n",
      "Epoch 13/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.7825 - acc: 0.9690     \n",
      "Epoch 14/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.5913 - acc: 0.9738     \n",
      "Epoch 15/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.4171 - acc: 0.9738     \n",
      "Epoch 16/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.2636 - acc: 0.9772     \n",
      "Epoch 17/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.1224 - acc: 0.9758     \n",
      "Epoch 18/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.9948 - acc: 0.9792     \n",
      "Epoch 19/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.8774 - acc: 0.9748     \n",
      "Epoch 20/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.7668 - acc: 0.9792     \n",
      "Epoch 21/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.6679 - acc: 0.9767     \n",
      "Epoch 22/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.5715 - acc: 0.9801     \n",
      "Epoch 23/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.4887 - acc: 0.9806     \n",
      "Epoch 24/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.4166 - acc: 0.9811     \n",
      "Epoch 25/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.3353 - acc: 0.9830     \n",
      "Epoch 26/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2611 - acc: 0.9830     \n",
      "Epoch 27/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2017 - acc: 0.9855     \n",
      "Epoch 28/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1384 - acc: 0.9811     \n",
      "Epoch 29/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0797 - acc: 0.9830     \n",
      "Epoch 30/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0244 - acc: 0.9864     \n",
      "Epoch 31/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9716 - acc: 0.9869     \n",
      "Epoch 32/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9231 - acc: 0.9884     \n",
      "Epoch 33/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8817 - acc: 0.9864     \n",
      "Epoch 34/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8347 - acc: 0.9874     \n",
      "Epoch 35/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7896 - acc: 0.9845     \n",
      "Epoch 36/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7565 - acc: 0.9850     \n",
      "Epoch 37/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7194 - acc: 0.9859     \n",
      "Epoch 38/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6771 - acc: 0.9884     \n",
      "Epoch 39/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6452 - acc: 0.9893     \n",
      "Epoch 40/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6081 - acc: 0.9859     \n",
      "Epoch 41/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5726 - acc: 0.9913     \n",
      "Epoch 42/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5490 - acc: 0.9889     \n",
      "Epoch 43/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5136 - acc: 0.9884     \n",
      "Epoch 44/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4842 - acc: 0.9908     \n",
      "Epoch 45/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4563 - acc: 0.9922     \n",
      "Epoch 46/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4329 - acc: 0.9864     \n",
      "Epoch 47/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4036 - acc: 0.9922     \n",
      "Epoch 48/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3886 - acc: 0.9845     \n",
      "Epoch 49/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3550 - acc: 0.9947     \n",
      "Epoch 50/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3357 - acc: 0.9869     \n",
      "Epoch 51/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3083 - acc: 0.9927     \n",
      "Epoch 52/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 2.2867 - acc: 0.9908     \n",
      "Epoch 53/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2642 - acc: 0.9947     \n",
      "Epoch 54/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2500 - acc: 0.9893     \n",
      "Epoch 55/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2285 - acc: 0.9927     \n",
      "Epoch 56/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2047 - acc: 0.9913     \n",
      "Epoch 57/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1864 - acc: 0.9932     \n",
      "Epoch 58/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1681 - acc: 0.9922     \n",
      "Epoch 59/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1532 - acc: 0.9908     \n",
      "Epoch 60/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1373 - acc: 0.9908     \n",
      "Epoch 61/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1145 - acc: 0.9937     \n",
      "Epoch 62/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0991 - acc: 0.9927     \n",
      "Epoch 63/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0873 - acc: 0.9918     \n",
      "Epoch 64/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0637 - acc: 0.9947     \n",
      "Epoch 65/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0526 - acc: 0.9927     \n",
      "Epoch 66/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0361 - acc: 0.9937     \n",
      "Epoch 67/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0214 - acc: 0.9932     \n",
      "Epoch 68/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0032 - acc: 0.9966     \n",
      "Epoch 69/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9942 - acc: 0.9918     \n",
      "Epoch 70/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9755 - acc: 0.9956     \n",
      "Epoch 71/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9647 - acc: 0.9956     \n",
      "Epoch 72/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9536 - acc: 0.9932     \n",
      "Epoch 73/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9400 - acc: 0.9942     \n",
      "Epoch 74/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9290 - acc: 0.9932     \n",
      "Epoch 75/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9134 - acc: 0.9942     \n",
      "Epoch 76/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9016 - acc: 0.9942     \n",
      "Epoch 77/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8902 - acc: 0.9942     \n",
      "Epoch 78/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8780 - acc: 0.9947     \n",
      "Epoch 79/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8645 - acc: 0.9942     \n",
      "Epoch 80/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8539 - acc: 0.9947     \n",
      "Epoch 81/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8426 - acc: 0.9937     \n",
      "Epoch 82/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8311 - acc: 0.9942     \n",
      "Epoch 83/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8205 - acc: 0.9952     \n",
      "Epoch 84/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8149 - acc: 0.9937     \n",
      "Epoch 85/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8001 - acc: 0.9956     \n",
      "Epoch 86/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7889 - acc: 0.9966     \n",
      "Epoch 87/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7809 - acc: 0.9956     \n",
      "Epoch 88/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7687 - acc: 0.9952     \n",
      "Epoch 89/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7614 - acc: 0.9952     \n",
      "Epoch 90/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7576 - acc: 0.9918     \n",
      "Epoch 91/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7451 - acc: 0.9937     \n",
      "Epoch 92/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7318 - acc: 0.9952     \n",
      "Epoch 93/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7277 - acc: 0.9922     \n",
      "Epoch 94/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7174 - acc: 0.9942     \n",
      "Epoch 95/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7071 - acc: 0.9952     \n",
      "Epoch 96/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6948 - acc: 0.9956     \n",
      "Epoch 97/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6914 - acc: 0.9971     \n",
      "Epoch 98/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6811 - acc: 0.9956     \n",
      "Epoch 99/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6756 - acc: 0.9942     \n",
      "Epoch 100/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6635 - acc: 0.9971     \n",
      "Epoch 101/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6563 - acc: 0.9947     \n",
      "Epoch 102/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6499 - acc: 0.9976     \n",
      "Epoch 103/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6439 - acc: 0.9966     \n",
      "Epoch 104/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6319 - acc: 0.9971     \n",
      "Epoch 105/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6244 - acc: 0.9981     \n",
      "Epoch 106/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6199 - acc: 0.9966     \n",
      "Epoch 107/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6132 - acc: 0.9947     \n",
      "Epoch 108/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6067 - acc: 0.9971     \n",
      "Epoch 109/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5957 - acc: 0.9981     \n",
      "Epoch 110/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5883 - acc: 0.9966     \n",
      "Epoch 111/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5865 - acc: 0.9927     \n",
      "Epoch 112/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5758 - acc: 0.9961     \n",
      "Epoch 113/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5693 - acc: 0.9971     \n",
      "Epoch 114/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5632 - acc: 0.9966     \n",
      "Epoch 115/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5582 - acc: 0.9966     \n",
      "Epoch 116/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5516 - acc: 0.9971     \n",
      "Epoch 117/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5433 - acc: 0.9976     \n",
      "Epoch 118/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5355 - acc: 0.9971     \n",
      "Epoch 119/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5339 - acc: 0.9947     \n",
      "Epoch 120/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5232 - acc: 0.9971     \n",
      "Epoch 121/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5210 - acc: 0.9961     \n",
      "Epoch 122/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5128 - acc: 0.9966     \n",
      "Epoch 123/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5075 - acc: 0.9971     \n",
      "Epoch 124/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5000 - acc: 0.9971     \n",
      "Epoch 125/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4990 - acc: 0.9952     \n",
      "Epoch 126/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4951 - acc: 0.9956     \n",
      "Epoch 127/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4839 - acc: 0.9985     \n",
      "Epoch 128/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4822 - acc: 0.9947     \n",
      "Epoch 129/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4721 - acc: 0.9976     \n",
      "Epoch 130/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4680 - acc: 0.9971     \n",
      "Epoch 131/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4630 - acc: 0.9971     \n",
      "Epoch 132/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4606 - acc: 0.9932     \n",
      "Epoch 133/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4550 - acc: 0.9966     \n",
      "Epoch 134/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4494 - acc: 0.9947     \n",
      "Epoch 135/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4404 - acc: 0.9971     \n",
      "Epoch 136/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4329 - acc: 0.9981     \n",
      "Epoch 137/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4338 - acc: 0.9961     \n",
      "Epoch 138/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4268 - acc: 0.9976     \n",
      "Epoch 139/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4212 - acc: 0.9981     \n",
      "Epoch 140/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4174 - acc: 0.9966     \n",
      "Epoch 141/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4127 - acc: 0.9990     \n",
      "Epoch 142/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4064 - acc: 0.9976     \n",
      "Epoch 143/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4037 - acc: 0.9971     \n",
      "Epoch 144/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3990 - acc: 0.9981     \n",
      "Epoch 145/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3933 - acc: 0.9976     \n",
      "Epoch 146/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3922 - acc: 0.9961     \n",
      "Epoch 147/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3857 - acc: 0.9976     \n",
      "Epoch 148/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3795 - acc: 0.9981     \n",
      "Epoch 149/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3752 - acc: 0.9976     \n",
      "Epoch 150/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3734 - acc: 0.9976     \n",
      "Epoch 151/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3638 - acc: 0.9985     \n",
      "Epoch 152/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3624 - acc: 0.9981     \n",
      "Epoch 153/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3574 - acc: 0.9976     \n",
      "Epoch 154/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3542 - acc: 0.9966     \n",
      "Epoch 155/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3556 - acc: 0.9956     \n",
      "Epoch 156/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3462 - acc: 0.9966     \n",
      "Epoch 157/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3419 - acc: 0.9981     \n",
      "Epoch 158/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3389 - acc: 0.9976     \n",
      "Epoch 159/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3363 - acc: 0.9961     \n",
      "Epoch 160/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3299 - acc: 0.9981     \n",
      "Epoch 161/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3266 - acc: 0.9971     \n",
      "Epoch 162/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3263 - acc: 0.9961     \n",
      "Epoch 163/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3194 - acc: 0.9976     \n",
      "Epoch 164/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3154 - acc: 0.9971     \n",
      "Epoch 165/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3130 - acc: 0.9981     \n",
      "Epoch 166/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3090 - acc: 0.9981     \n",
      "Epoch 167/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3039 - acc: 0.9961     \n",
      "Epoch 168/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3001 - acc: 0.9971     \n",
      "Epoch 169/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2958 - acc: 0.9976     \n",
      "Epoch 170/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2932 - acc: 0.9966     \n",
      "Epoch 171/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2868 - acc: 0.9976     \n",
      "Epoch 172/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2894 - acc: 0.9971     \n",
      "Epoch 173/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2814 - acc: 0.9985     \n",
      "Epoch 174/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2816 - acc: 0.9971     \n",
      "Epoch 175/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2749 - acc: 0.9976     \n",
      "Epoch 176/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2729 - acc: 0.9976     \n",
      "Epoch 177/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2688 - acc: 0.9966     \n",
      "Epoch 178/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2679 - acc: 0.9966     \n",
      "Epoch 179/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2598 - acc: 0.9985     \n",
      "Epoch 180/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2587 - acc: 0.9976     \n",
      "Epoch 181/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2542 - acc: 0.9976     \n",
      "Epoch 182/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2529 - acc: 0.9976     \n",
      "Epoch 183/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2490 - acc: 0.9971     \n",
      "Epoch 184/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2467 - acc: 0.9981     \n",
      "Epoch 185/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2446 - acc: 0.9976     \n",
      "Epoch 186/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2383 - acc: 0.9985     \n",
      "Epoch 187/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2364 - acc: 0.9985     \n",
      "Epoch 188/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2322 - acc: 0.9981     \n",
      "Epoch 189/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2301 - acc: 0.9976     \n",
      "Epoch 190/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2242 - acc: 0.9976     \n",
      "Epoch 191/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2254 - acc: 0.9976     \n",
      "Epoch 192/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2225 - acc: 0.9985     \n",
      "Epoch 193/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2198 - acc: 0.9981     \n",
      "Epoch 194/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2130 - acc: 0.9985     \n",
      "Epoch 195/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2112 - acc: 0.9981     \n",
      "Epoch 196/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2072 - acc: 0.9976     \n",
      "Epoch 197/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2058 - acc: 0.9981     \n",
      "Epoch 198/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2017 - acc: 0.9985     \n",
      "Epoch 199/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2004 - acc: 0.9985     \n",
      "Epoch 200/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1979 - acc: 0.9985     \n",
      "Epoch 201/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1959 - acc: 0.9976     \n",
      "Epoch 202/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1899 - acc: 0.9985     \n",
      "Epoch 203/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1883 - acc: 0.9985     \n",
      "Epoch 204/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1861 - acc: 0.9990     \n",
      "Epoch 205/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1844 - acc: 0.9976     \n",
      "Epoch 206/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1807 - acc: 0.9976     \n",
      "Epoch 207/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1763 - acc: 0.9990     \n",
      "Epoch 208/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1777 - acc: 0.9976     \n",
      "Epoch 209/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1746 - acc: 0.9971     \n",
      "Epoch 210/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1711 - acc: 0.9990     \n",
      "Epoch 211/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1666 - acc: 0.9981     \n",
      "Epoch 212/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1668 - acc: 0.9971     \n",
      "Epoch 213/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1620 - acc: 0.9976     \n",
      "Epoch 214/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1601 - acc: 0.9981     \n",
      "Epoch 215/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1555 - acc: 0.9985     \n",
      "Epoch 216/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1578 - acc: 0.9971     \n",
      "Epoch 217/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1505 - acc: 0.9985     \n",
      "Epoch 218/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1499 - acc: 0.9981     \n",
      "Epoch 219/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1466 - acc: 0.9985     \n",
      "Epoch 220/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1433 - acc: 0.9985     \n",
      "Epoch 221/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1428 - acc: 0.9976     \n",
      "Epoch 222/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 1.1382 - acc: 0.9990     \n",
      "Epoch 223/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1376 - acc: 0.9985     \n",
      "Epoch 224/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1346 - acc: 0.9985     \n",
      "Epoch 225/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1335 - acc: 0.9981     \n",
      "Epoch 226/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1274 - acc: 0.9985     \n",
      "Epoch 227/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1264 - acc: 0.9990     \n",
      "Epoch 228/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1246 - acc: 0.9985     \n",
      "Epoch 229/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1229 - acc: 0.9990     \n",
      "Epoch 230/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1200 - acc: 0.9985     \n",
      "Epoch 231/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1213 - acc: 0.9985     \n",
      "Epoch 232/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1137 - acc: 0.9990     \n",
      "Epoch 233/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1129 - acc: 0.9985     \n",
      "Epoch 234/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1103 - acc: 0.9985     \n",
      "Epoch 235/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1098 - acc: 0.9981     \n",
      "Epoch 236/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1096 - acc: 0.9971     \n",
      "Epoch 237/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1050 - acc: 0.9985     \n",
      "Epoch 238/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1015 - acc: 0.9990     \n",
      "Epoch 239/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0999 - acc: 0.9976     \n",
      "Epoch 240/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1034 - acc: 0.9966     \n",
      "Epoch 241/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0943 - acc: 0.9981     \n",
      "Epoch 242/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0942 - acc: 0.9971     \n",
      "Epoch 243/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0923 - acc: 0.9981     \n",
      "Epoch 244/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0910 - acc: 0.9976     \n",
      "Epoch 245/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0876 - acc: 0.9990     \n",
      "Epoch 246/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0847 - acc: 0.9985     \n",
      "Epoch 247/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0859 - acc: 0.9971     \n",
      "Epoch 248/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0807 - acc: 0.9990     \n",
      "Epoch 249/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0804 - acc: 0.9976     \n",
      "Epoch 250/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0792 - acc: 0.9976     \n",
      "Epoch 251/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0762 - acc: 0.9985     \n",
      "Epoch 252/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0745 - acc: 0.9985     \n",
      "Epoch 253/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0719 - acc: 0.9990     \n",
      "Epoch 254/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0706 - acc: 0.9976     \n",
      "Epoch 255/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0677 - acc: 0.9985     \n",
      "Epoch 256/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0683 - acc: 0.9985     \n",
      "Epoch 257/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0667 - acc: 0.9990     \n",
      "Epoch 258/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0615 - acc: 0.9985     \n",
      "Epoch 259/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0605 - acc: 0.9976     \n",
      "Epoch 260/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0582 - acc: 0.9985     \n",
      "Epoch 261/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0562 - acc: 0.9985     \n",
      "Epoch 262/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0561 - acc: 0.9971     \n",
      "Epoch 263/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0516 - acc: 0.9990     \n",
      "Epoch 264/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0501 - acc: 0.9985     \n",
      "Epoch 265/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0489 - acc: 0.9985     \n",
      "Epoch 266/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0498 - acc: 0.9981     \n",
      "Epoch 267/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0475 - acc: 0.9971     \n",
      "Epoch 268/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0449 - acc: 0.9990     \n",
      "Epoch 269/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0456 - acc: 0.9981     \n",
      "Epoch 270/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0430 - acc: 0.9985     \n",
      "Epoch 271/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0385 - acc: 0.9981     \n",
      "Epoch 272/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0409 - acc: 0.9981     \n",
      "Epoch 273/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0363 - acc: 0.9981     \n",
      "Epoch 274/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0366 - acc: 0.9976     \n",
      "Epoch 275/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0331 - acc: 0.9990     \n",
      "Epoch 276/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0303 - acc: 0.9976     \n",
      "Epoch 277/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0282 - acc: 0.9985     \n",
      "Epoch 278/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0279 - acc: 0.9985     \n",
      "Epoch 279/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0259 - acc: 0.9981     \n",
      "Epoch 280/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0239 - acc: 0.9985     \n",
      "Epoch 281/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0223 - acc: 0.9990     \n",
      "Epoch 282/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0205 - acc: 0.9990     \n",
      "Epoch 283/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0188 - acc: 0.9990     \n",
      "Epoch 284/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0193 - acc: 0.9985     \n",
      "Epoch 285/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0136 - acc: 0.9990     \n",
      "Epoch 286/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0170 - acc: 0.9985     \n",
      "Epoch 287/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0117 - acc: 0.9990     \n",
      "Epoch 288/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0098 - acc: 0.9985     \n",
      "Epoch 289/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0082 - acc: 0.9985     \n",
      "Epoch 290/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0075 - acc: 0.9985     \n",
      "Epoch 291/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0064 - acc: 0.9981     \n",
      "Epoch 292/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0084 - acc: 0.9966     \n",
      "Epoch 293/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0035 - acc: 0.9981     \n",
      "Epoch 294/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0035 - acc: 0.9981     \n",
      "Epoch 295/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0000 - acc: 0.9985     \n",
      "Epoch 296/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0027 - acc: 0.9971     \n",
      "Epoch 297/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9955 - acc: 0.9981     \n",
      "Epoch 298/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9954 - acc: 0.9985     \n",
      "Epoch 299/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9940 - acc: 0.9990     \n",
      "Epoch 300/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9906 - acc: 0.9990     \n",
      "# # # Evaluating cv-fold...\n",
      "384/485 [======================>.......] - ETA: 0s\n",
      "accuracy: 87.42268042466075\n",
      "precision: 89.03508771929825\n",
      "recall: 84.93723849372385\n",
      "f1_score: 86.93790149892934\n",
      "Training fold 10/10\n",
      "Epoch 1/300\n",
      "2064/2064 [==============================] - 1s - loss: 14.1912 - acc: 0.8324     \n",
      "Epoch 2/300\n",
      "2064/2064 [==============================] - 0s - loss: 11.7790 - acc: 0.9152     \n",
      "Epoch 3/300\n",
      "2064/2064 [==============================] - 0s - loss: 10.1873 - acc: 0.9215     \n",
      "Epoch 4/300\n",
      "2064/2064 [==============================] - 0s - loss: 9.0304 - acc: 0.9351     \n",
      "Epoch 5/300\n",
      "2064/2064 [==============================] - 0s - loss: 8.1389 - acc: 0.9457     \n",
      "Epoch 6/300\n",
      "2064/2064 [==============================] - 0s - loss: 7.4484 - acc: 0.9520     \n",
      "Epoch 7/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.8868 - acc: 0.9559     \n",
      "Epoch 8/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.4183 - acc: 0.9612     \n",
      "Epoch 9/300\n",
      "2064/2064 [==============================] - 0s - loss: 6.0267 - acc: 0.9695     \n",
      "Epoch 10/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.6921 - acc: 0.9666     \n",
      "Epoch 11/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.4026 - acc: 0.9695     \n",
      "Epoch 12/300\n",
      "2064/2064 [==============================] - 0s - loss: 5.1517 - acc: 0.9700     \n",
      "Epoch 13/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.9311 - acc: 0.9709     \n",
      "Epoch 14/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.7315 - acc: 0.9758     \n",
      "Epoch 15/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.5475 - acc: 0.9792     \n",
      "Epoch 16/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.3865 - acc: 0.9767     \n",
      "Epoch 17/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.2395 - acc: 0.9787     \n",
      "Epoch 18/300\n",
      "2064/2064 [==============================] - 0s - loss: 4.1069 - acc: 0.9758     \n",
      "Epoch 19/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.9831 - acc: 0.9835     \n",
      "Epoch 20/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.8715 - acc: 0.9806     \n",
      "Epoch 21/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.7676 - acc: 0.9855     \n",
      "Epoch 22/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.6743 - acc: 0.9806     \n",
      "Epoch 23/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.5808 - acc: 0.9840     \n",
      "Epoch 24/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.4994 - acc: 0.9840     \n",
      "Epoch 25/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.4189 - acc: 0.9850     \n",
      "Epoch 26/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.3444 - acc: 0.9850     \n",
      "Epoch 27/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2761 - acc: 0.9835     \n",
      "Epoch 28/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.2117 - acc: 0.9869     \n",
      "Epoch 29/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.1474 - acc: 0.9859     \n",
      "Epoch 30/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0942 - acc: 0.9835     \n",
      "Epoch 31/300\n",
      "2064/2064 [==============================] - 0s - loss: 3.0356 - acc: 0.9864     \n",
      "Epoch 32/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9840 - acc: 0.9850     \n",
      "Epoch 33/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.9400 - acc: 0.9850     \n",
      "Epoch 34/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8887 - acc: 0.9889     \n",
      "Epoch 35/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8417 - acc: 0.9889     \n",
      "Epoch 36/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.8054 - acc: 0.9903     \n",
      "Epoch 37/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7612 - acc: 0.9903     \n",
      "Epoch 38/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.7256 - acc: 0.9918     \n",
      "Epoch 39/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6848 - acc: 0.9893     \n",
      "Epoch 40/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6496 - acc: 0.9889     \n",
      "Epoch 41/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.6079 - acc: 0.9942     \n",
      "Epoch 42/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5771 - acc: 0.9908     \n",
      "Epoch 43/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5497 - acc: 0.9893     \n",
      "Epoch 44/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.5174 - acc: 0.9903     \n",
      "Epoch 45/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4869 - acc: 0.9927     \n",
      "Epoch 46/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4611 - acc: 0.9903     \n",
      "Epoch 47/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4359 - acc: 0.9908     \n",
      "Epoch 48/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.4035 - acc: 0.9918     \n",
      "Epoch 49/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3866 - acc: 0.9879     \n",
      "Epoch 50/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3461 - acc: 0.9947     \n",
      "Epoch 51/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3304 - acc: 0.9927     \n",
      "Epoch 52/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.3117 - acc: 0.9884     \n",
      "Epoch 53/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2825 - acc: 0.9932     \n",
      "Epoch 54/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2565 - acc: 0.9942     \n",
      "Epoch 55/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2358 - acc: 0.9937     \n",
      "Epoch 56/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.2214 - acc: 0.9918     \n",
      "Epoch 57/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1982 - acc: 0.9927     \n",
      "Epoch 58/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1816 - acc: 0.9908     \n",
      "Epoch 59/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1591 - acc: 0.9932     \n",
      "Epoch 60/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1386 - acc: 0.9966     \n",
      "Epoch 61/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1228 - acc: 0.9942     \n",
      "Epoch 62/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.1047 - acc: 0.9952     \n",
      "Epoch 63/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0825 - acc: 0.9937     \n",
      "Epoch 64/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0695 - acc: 0.9952     \n",
      "Epoch 65/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0520 - acc: 0.9947     \n",
      "Epoch 66/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0349 - acc: 0.9952     \n",
      "Epoch 67/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0200 - acc: 0.9956     \n",
      "Epoch 68/300\n",
      "2064/2064 [==============================] - 0s - loss: 2.0054 - acc: 0.9961     \n",
      "Epoch 69/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9893 - acc: 0.9947     \n",
      "Epoch 70/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9724 - acc: 0.9952     \n",
      "Epoch 71/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9630 - acc: 0.9918     \n",
      "Epoch 72/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9491 - acc: 0.9956     \n",
      "Epoch 73/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9355 - acc: 0.9913     \n",
      "Epoch 74/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9169 - acc: 0.9956     \n",
      "Epoch 75/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.9133 - acc: 0.9918     \n",
      "Epoch 76/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8900 - acc: 0.9971     \n",
      "Epoch 77/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8808 - acc: 0.9937     \n",
      "Epoch 78/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8704 - acc: 0.9942     \n",
      "Epoch 79/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8529 - acc: 0.9966     \n",
      "Epoch 80/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8409 - acc: 0.9966     \n",
      "Epoch 81/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8317 - acc: 0.9961     \n",
      "Epoch 82/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8184 - acc: 0.9966     \n",
      "Epoch 83/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.8074 - acc: 0.9966     \n",
      "Epoch 84/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7958 - acc: 0.9956     \n",
      "Epoch 85/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7886 - acc: 0.9956     \n",
      "Epoch 86/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7748 - acc: 0.9956     \n",
      "Epoch 87/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7646 - acc: 0.9961     \n",
      "Epoch 88/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7567 - acc: 0.9956     \n",
      "Epoch 89/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7429 - acc: 0.9985     \n",
      "Epoch 90/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7319 - acc: 0.9966     \n",
      "Epoch 91/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 1.7231 - acc: 0.9971     \n",
      "Epoch 92/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7150 - acc: 0.9942     \n",
      "Epoch 93/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.7069 - acc: 0.9942     \n",
      "Epoch 94/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6950 - acc: 0.9976     \n",
      "Epoch 95/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6862 - acc: 0.9966     \n",
      "Epoch 96/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6801 - acc: 0.9937     \n",
      "Epoch 97/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6686 - acc: 0.9971     \n",
      "Epoch 98/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6615 - acc: 0.9952     \n",
      "Epoch 99/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6519 - acc: 0.9956     \n",
      "Epoch 100/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6428 - acc: 0.9971     \n",
      "Epoch 101/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6358 - acc: 0.9966     \n",
      "Epoch 102/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6251 - acc: 0.9971     \n",
      "Epoch 103/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6209 - acc: 0.9952     \n",
      "Epoch 104/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6097 - acc: 0.9976     \n",
      "Epoch 105/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.6027 - acc: 0.9981     \n",
      "Epoch 106/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5926 - acc: 0.9971     \n",
      "Epoch 107/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5882 - acc: 0.9976     \n",
      "Epoch 108/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5789 - acc: 0.9966     \n",
      "Epoch 109/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5707 - acc: 0.9976     \n",
      "Epoch 110/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5623 - acc: 0.9976     \n",
      "Epoch 111/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5576 - acc: 0.9961     \n",
      "Epoch 112/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5509 - acc: 0.9956     \n",
      "Epoch 113/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5410 - acc: 0.9981     \n",
      "Epoch 114/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5348 - acc: 0.9981     \n",
      "Epoch 115/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5294 - acc: 0.9971     \n",
      "Epoch 116/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5202 - acc: 0.9976     \n",
      "Epoch 117/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5134 - acc: 0.9976     \n",
      "Epoch 118/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5047 - acc: 0.9981     \n",
      "Epoch 119/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.5000 - acc: 0.9971     \n",
      "Epoch 120/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4945 - acc: 0.9976     \n",
      "Epoch 121/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4909 - acc: 0.9976     \n",
      "Epoch 122/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4848 - acc: 0.9961     \n",
      "Epoch 123/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4764 - acc: 0.9976     \n",
      "Epoch 124/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4672 - acc: 0.9981     \n",
      "Epoch 125/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4613 - acc: 0.9981     \n",
      "Epoch 126/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4545 - acc: 0.9976     \n",
      "Epoch 127/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4528 - acc: 0.9985     \n",
      "Epoch 128/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4418 - acc: 0.9981     \n",
      "Epoch 129/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4443 - acc: 0.9947     \n",
      "Epoch 130/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4330 - acc: 0.9976     \n",
      "Epoch 131/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4245 - acc: 0.9985     \n",
      "Epoch 132/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4181 - acc: 0.9976     \n",
      "Epoch 133/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4163 - acc: 0.9976     \n",
      "Epoch 134/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4083 - acc: 0.9976     \n",
      "Epoch 135/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.4043 - acc: 0.9981     \n",
      "Epoch 136/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3987 - acc: 0.9985     \n",
      "Epoch 137/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3926 - acc: 0.9971     \n",
      "Epoch 138/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3880 - acc: 0.9981     \n",
      "Epoch 139/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3796 - acc: 0.9981     \n",
      "Epoch 140/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3765 - acc: 0.9981     \n",
      "Epoch 141/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3719 - acc: 0.9976     \n",
      "Epoch 142/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3660 - acc: 0.9981     \n",
      "Epoch 143/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3609 - acc: 0.9976     \n",
      "Epoch 144/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3566 - acc: 0.9990     \n",
      "Epoch 145/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3524 - acc: 0.9985     \n",
      "Epoch 146/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3463 - acc: 0.9966     \n",
      "Epoch 147/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3417 - acc: 0.9981     \n",
      "Epoch 148/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3355 - acc: 0.9981     - ETA: 0s - loss: 1.3364 - acc\n",
      "Epoch 149/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3307 - acc: 0.9985     \n",
      "Epoch 150/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3267 - acc: 0.9981     \n",
      "Epoch 151/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3208 - acc: 0.9985     \n",
      "Epoch 152/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3182 - acc: 0.9976     \n",
      "Epoch 153/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3097 - acc: 0.9990     \n",
      "Epoch 154/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3089 - acc: 0.9976     \n",
      "Epoch 155/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3055 - acc: 0.9976     \n",
      "Epoch 156/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.3010 - acc: 0.9976     \n",
      "Epoch 157/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2959 - acc: 0.9971     \n",
      "Epoch 158/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2943 - acc: 0.9981     \n",
      "Epoch 159/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2854 - acc: 0.9990     \n",
      "Epoch 160/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2828 - acc: 0.9981     \n",
      "Epoch 161/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2778 - acc: 0.9985     \n",
      "Epoch 162/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2748 - acc: 0.9981     \n",
      "Epoch 163/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2709 - acc: 0.9981     \n",
      "Epoch 164/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2675 - acc: 0.9981     \n",
      "Epoch 165/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2602 - acc: 0.9990     \n",
      "Epoch 166/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2580 - acc: 0.9985     \n",
      "Epoch 167/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2544 - acc: 0.9976     \n",
      "Epoch 168/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2508 - acc: 0.9985     \n",
      "Epoch 169/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2479 - acc: 0.9971     \n",
      "Epoch 170/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2420 - acc: 0.9990     \n",
      "Epoch 171/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2396 - acc: 0.9976     \n",
      "Epoch 172/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2342 - acc: 0.9990     \n",
      "Epoch 173/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2315 - acc: 0.9971     \n",
      "Epoch 174/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2281 - acc: 0.9990     \n",
      "Epoch 175/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2240 - acc: 0.9985     \n",
      "Epoch 176/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2193 - acc: 0.9990     \n",
      "Epoch 177/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2144 - acc: 0.9990     \n",
      "Epoch 178/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2139 - acc: 0.9985     \n",
      "Epoch 179/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2069 - acc: 0.9985     \n",
      "Epoch 180/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2085 - acc: 0.9976     \n",
      "Epoch 181/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.2024 - acc: 0.9981     \n",
      "Epoch 182/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1967 - acc: 0.9990     \n",
      "Epoch 183/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1958 - acc: 0.9971     \n",
      "Epoch 184/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1907 - acc: 0.9990     \n",
      "Epoch 185/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1885 - acc: 0.9985     \n",
      "Epoch 186/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1866 - acc: 0.9976     \n",
      "Epoch 187/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1820 - acc: 0.9981     \n",
      "Epoch 188/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1802 - acc: 0.9961     \n",
      "Epoch 189/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1789 - acc: 0.9966     \n",
      "Epoch 190/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1748 - acc: 0.9976     \n",
      "Epoch 191/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1689 - acc: 0.9990     \n",
      "Epoch 192/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1692 - acc: 0.9966     \n",
      "Epoch 193/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1648 - acc: 0.9981     \n",
      "Epoch 194/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1609 - acc: 0.9985     \n",
      "Epoch 195/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1566 - acc: 0.9981     \n",
      "Epoch 196/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1529 - acc: 0.9990     \n",
      "Epoch 197/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1533 - acc: 0.9976     \n",
      "Epoch 198/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1479 - acc: 0.9990     \n",
      "Epoch 199/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1448 - acc: 0.9981     \n",
      "Epoch 200/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1428 - acc: 0.9985     \n",
      "Epoch 201/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1391 - acc: 0.9985     \n",
      "Epoch 202/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1366 - acc: 0.9990     \n",
      "Epoch 203/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1370 - acc: 0.9976     \n",
      "Epoch 204/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1311 - acc: 0.9985     \n",
      "Epoch 205/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1296 - acc: 0.9985     \n",
      "Epoch 206/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1282 - acc: 0.9971     \n",
      "Epoch 207/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1221 - acc: 0.9981     \n",
      "Epoch 208/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1196 - acc: 0.9985     \n",
      "Epoch 209/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1165 - acc: 0.9981     \n",
      "Epoch 210/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1139 - acc: 0.9985     \n",
      "Epoch 211/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1139 - acc: 0.9985     \n",
      "Epoch 212/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1094 - acc: 0.9985     \n",
      "Epoch 213/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1071 - acc: 0.9976     \n",
      "Epoch 214/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1041 - acc: 0.9990     \n",
      "Epoch 215/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.1001 - acc: 0.9990     \n",
      "Epoch 216/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0968 - acc: 0.9985     \n",
      "Epoch 217/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0943 - acc: 0.9990     \n",
      "Epoch 218/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0941 - acc: 0.9990     \n",
      "Epoch 219/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0904 - acc: 0.9971     \n",
      "Epoch 220/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0862 - acc: 0.9985     \n",
      "Epoch 221/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0874 - acc: 0.9985     - ETA: 0s - loss: 1.0917 - a\n",
      "Epoch 222/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0816 - acc: 0.9990     \n",
      "Epoch 223/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0807 - acc: 0.9985     \n",
      "Epoch 224/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0794 - acc: 0.9976     \n",
      "Epoch 225/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0792 - acc: 0.9976     \n",
      "Epoch 226/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0727 - acc: 0.9990     \n",
      "Epoch 227/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0707 - acc: 0.9990     \n",
      "Epoch 228/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0668 - acc: 0.9990     \n",
      "Epoch 229/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0677 - acc: 0.9981     \n",
      "Epoch 230/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0663 - acc: 0.9990     \n",
      "Epoch 231/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0603 - acc: 0.9995     \n",
      "Epoch 232/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0596 - acc: 0.9985     \n",
      "Epoch 233/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0558 - acc: 0.9990     \n",
      "Epoch 234/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0535 - acc: 0.9985     \n",
      "Epoch 235/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0517 - acc: 0.9990     \n",
      "Epoch 236/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0529 - acc: 0.9981     \n",
      "Epoch 237/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0483 - acc: 0.9985     \n",
      "Epoch 238/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0429 - acc: 0.9990     \n",
      "Epoch 239/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0439 - acc: 0.9990     \n",
      "Epoch 240/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0408 - acc: 0.9985     \n",
      "Epoch 241/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0386 - acc: 0.9985     \n",
      "Epoch 242/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0373 - acc: 0.9995     \n",
      "Epoch 243/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0335 - acc: 0.9981     \n",
      "Epoch 244/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0321 - acc: 0.9990     \n",
      "Epoch 245/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0306 - acc: 0.9990     \n",
      "Epoch 246/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0275 - acc: 0.9990     \n",
      "Epoch 247/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0251 - acc: 0.9985     \n",
      "Epoch 248/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0236 - acc: 0.9995     \n",
      "Epoch 249/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0228 - acc: 0.9985     \n",
      "Epoch 250/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0188 - acc: 0.9985     \n",
      "Epoch 251/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0174 - acc: 0.9990     \n",
      "Epoch 252/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0172 - acc: 0.9985     \n",
      "Epoch 253/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0132 - acc: 0.9990     \n",
      "Epoch 254/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0102 - acc: 0.9985     \n",
      "Epoch 255/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0086 - acc: 0.9981     \n",
      "Epoch 256/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0067 - acc: 0.9990     \n",
      "Epoch 257/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0051 - acc: 0.9990     \n",
      "Epoch 258/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0023 - acc: 0.9985     \n",
      "Epoch 259/300\n",
      "2064/2064 [==============================] - 0s - loss: 1.0002 - acc: 0.9990     \n",
      "Epoch 260/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9990 - acc: 0.9985     \n",
      "Epoch 261/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 0s - loss: 0.9958 - acc: 0.9990     \n",
      "Epoch 262/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9934 - acc: 0.9985     \n",
      "Epoch 263/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9909 - acc: 0.9990     \n",
      "Epoch 264/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9911 - acc: 0.9995     \n",
      "Epoch 265/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9883 - acc: 0.9995     \n",
      "Epoch 266/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9852 - acc: 0.9990     \n",
      "Epoch 267/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9848 - acc: 0.9990     \n",
      "Epoch 268/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9820 - acc: 0.9995     \n",
      "Epoch 269/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9802 - acc: 0.9981     \n",
      "Epoch 270/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9771 - acc: 0.9990     \n",
      "Epoch 271/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9788 - acc: 0.9976     \n",
      "Epoch 272/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9739 - acc: 0.9990     \n",
      "Epoch 273/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9710 - acc: 0.9990     \n",
      "Epoch 274/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9711 - acc: 0.9990     \n",
      "Epoch 275/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9698 - acc: 0.9985     \n",
      "Epoch 276/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9671 - acc: 0.9990     \n",
      "Epoch 277/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9654 - acc: 0.9995     \n",
      "Epoch 278/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9613 - acc: 0.9981     \n",
      "Epoch 279/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9596 - acc: 0.9990     \n",
      "Epoch 280/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9616 - acc: 0.9985     \n",
      "Epoch 281/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9582 - acc: 0.9985     \n",
      "Epoch 282/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9548 - acc: 0.9990     \n",
      "Epoch 283/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9522 - acc: 0.9990     \n",
      "Epoch 284/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9512 - acc: 0.9990     \n",
      "Epoch 285/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9476 - acc: 0.9995     \n",
      "Epoch 286/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9481 - acc: 0.9995     \n",
      "Epoch 287/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9473 - acc: 0.9981     \n",
      "Epoch 288/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9449 - acc: 0.9990     \n",
      "Epoch 289/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9429 - acc: 0.9990     \n",
      "Epoch 290/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9404 - acc: 0.9990     \n",
      "Epoch 291/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9385 - acc: 0.9990     \n",
      "Epoch 292/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9375 - acc: 0.9990     \n",
      "Epoch 293/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9354 - acc: 0.9985     \n",
      "Epoch 294/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9339 - acc: 0.9990     \n",
      "Epoch 295/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9329 - acc: 0.9985     \n",
      "Epoch 296/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9312 - acc: 0.9990     \n",
      "Epoch 297/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9289 - acc: 0.9990     \n",
      "Epoch 298/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9272 - acc: 0.9985     \n",
      "Epoch 299/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9271 - acc: 0.9985     \n",
      "Epoch 300/300\n",
      "2064/2064 [==============================] - 0s - loss: 0.9235 - acc: 0.9995     \n",
      "# # # Evaluating cv-fold...\n",
      "448/485 [==========================>...] - ETA: 0s\n",
      "accuracy: 87.83505155868137\n",
      "precision: 87.81512605042016\n",
      "recall: 87.44769874476988\n",
      "f1_score: 87.63102725366878\n",
      "\n",
      "Final cross-validation score:\n",
      "88.02061856899064 +/- 0.2980790163876476\n",
      "88.98019091146551 +/- 0.6375797608682774\n",
      "86.40167364016737 +/- 0.9945493158162945\n",
      "87.66534655151375 +/- 0.3578161556560656\n"
     ]
    }
   ],
   "source": [
    "# ON THE PLAIN DATASET\n",
    "\n",
    "folds = 10\n",
    "cv_accuracies = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1_score = []\n",
    "\n",
    "for fold in range(folds):\n",
    "    print(\"Training fold \" + str(fold + 1) + \"/\" + str(folds))\n",
    "    \n",
    "    shuffle(train_tactile_images, train_labels_cat)\n",
    "    shuffle(test_tactile_images, test_labels_cat) \n",
    "    \n",
    "    # build model\n",
    "    epochs = 300\n",
    "    batch = 32\n",
    "    \n",
    "    learning_rate = 0.0001\n",
    "    epsilon = 1e-08\n",
    "    decay_rate = 0.005\n",
    "    \n",
    "    l2_reg = 0.01\n",
    "    drop_prob = 0.0\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(FINGERS, TACTILE_IMAGE_ROWS, TACTILE_IMAGE_COLS), \n",
    "                     data_format='channels_first',\n",
    "                     use_bias=False, kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1024, kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(drop_prob))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    # compile and train\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.Adam(lr=learning_rate, epsilon=epsilon, decay=decay_rate), \n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(train_tactile_images, train_labels_cat, epochs=epochs, batch_size=batch, verbose=1)\n",
    "    \n",
    "    # evaluate\n",
    "    print(\"# # # Evaluating cv-fold...\")\n",
    "    scores = model.evaluate(test_tactile_images, test_labels_cat, verbose=1)\n",
    "    cv_accuracies.append(scores[1] * 100)\n",
    "    \n",
    "    predictions = model.predict(test_tactile_images)\n",
    "    [precision, recall, f1_score, _] = precision_recall_fscore_support(np.argmax(test_labels_cat, axis=1), \n",
    "                                                                          np.argmax(predictions, axis=1), \n",
    "                                                                          average='binary', pos_label=1)\n",
    "    \n",
    "    cv_precision.append(precision * 100)\n",
    "    cv_recall.append(recall * 100)\n",
    "    cv_f1_score.append(f1_score * 100)\n",
    "    \n",
    "    print(\"\\naccuracy:\", scores[1] * 100)\n",
    "    print(\"precision:\", precision * 100)\n",
    "    print(\"recall:\", recall * 100)\n",
    "    print(\"f1_score:\", f1_score * 100)\n",
    "    \n",
    "print(\"\\nFinal cross-validation score:\")\n",
    "print(np.mean(cv_accuracies), \"+/-\", np.std(cv_accuracies))\n",
    "print(np.mean(cv_precision), \"+/-\", np.std(cv_precision))\n",
    "print(np.mean(cv_recall), \"+/-\", np.std(cv_recall))\n",
    "print(np.mean(cv_f1_score), \"+/-\", np.std(cv_f1_score))\n",
    "\n",
    "# IROS\n",
    "#86.0355987113 +/- 0.383259524026\n",
    "#86.47674489 +/- 0.501892412426\n",
    "#83.8644067797 +/- 0.775967670662\n",
    "#85.1477152443 +/- 0.441251814143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/10\n",
      "Epoch 1/30\n",
      "4128/4128 [==============================] - 3s - loss: 19.2793 - acc: 0.8266     \n",
      "Epoch 2/30\n",
      "4128/4128 [==============================] - 1s - loss: 14.1680 - acc: 0.8861     \n",
      "Epoch 3/30\n",
      "4128/4128 [==============================] - 1s - loss: 11.5231 - acc: 0.8878     \n",
      "Epoch 4/30\n",
      "4128/4128 [==============================] - 1s - loss: 9.8751 - acc: 0.8937     \n",
      "Epoch 5/30\n",
      "4128/4128 [==============================] - 1s - loss: 8.7448 - acc: 0.9050     \n",
      "Epoch 6/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.9292 - acc: 0.9109     \n",
      "Epoch 7/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.2951 - acc: 0.9155     \n",
      "Epoch 8/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.8030 - acc: 0.9184     \n",
      "Epoch 9/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.3947 - acc: 0.9271     \n",
      "Epoch 10/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.0653 - acc: 0.9259     \n",
      "Epoch 11/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.7820 - acc: 0.9288     \n",
      "Epoch 12/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.5425 - acc: 0.9339     \n",
      "Epoch 13/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.3182 - acc: 0.9419     \n",
      "Epoch 14/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.1463 - acc: 0.9358     \n",
      "Epoch 15/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.9832 - acc: 0.9380     \n",
      "Epoch 16/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.8334 - acc: 0.9426     \n",
      "Epoch 17/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.7077 - acc: 0.9394     \n",
      "Epoch 18/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.5883 - acc: 0.9411     \n",
      "Epoch 19/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.4780 - acc: 0.9445     \n",
      "Epoch 20/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.3850 - acc: 0.9421     \n",
      "Epoch 21/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.2857 - acc: 0.9474     \n",
      "Epoch 22/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.2113 - acc: 0.9416     \n",
      "Epoch 23/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.1254 - acc: 0.9482     \n",
      "Epoch 24/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.0481 - acc: 0.9518     \n",
      "Epoch 25/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9939 - acc: 0.9474     \n",
      "Epoch 26/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9275 - acc: 0.9542     \n",
      "Epoch 27/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8735 - acc: 0.9469     \n",
      "Epoch 28/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8029 - acc: 0.9598     \n",
      "Epoch 29/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.7606 - acc: 0.9499     \n",
      "Epoch 30/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.7119 - acc: 0.9503     \n",
      "# # # Evaluating cv-fold...\n",
      "485/485 [==============================] - 1s      \n",
      "\n",
      "accuracy: 89.48453609476384\n",
      "precision: 89.49579831932773\n",
      "recall: 89.1213389121339\n",
      "f1_score: 89.30817610062893\n",
      "Training fold 2/10\n",
      "Epoch 1/30\n",
      "4128/4128 [==============================] - 2s - loss: 19.1812 - acc: 0.8425     \n",
      "Epoch 2/30\n",
      "4128/4128 [==============================] - 1s - loss: 14.1587 - acc: 0.8779     \n",
      "Epoch 3/30\n",
      "4128/4128 [==============================] - 1s - loss: 11.5416 - acc: 0.8912     \n",
      "Epoch 4/30\n",
      "4128/4128 [==============================] - 1s - loss: 9.9243 - acc: 0.8966     \n",
      "Epoch 5/30\n",
      "4128/4128 [==============================] - 1s - loss: 8.8129 - acc: 0.9125     \n",
      "Epoch 6/30\n",
      "4128/4128 [==============================] - 1s - loss: 8.0113 - acc: 0.9133     \n",
      "Epoch 7/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.4000 - acc: 0.9184     \n",
      "Epoch 8/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.9051 - acc: 0.9220     \n",
      "Epoch 9/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.5106 - acc: 0.9230     \n",
      "Epoch 10/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.1680 - acc: 0.9312     \n",
      "Epoch 11/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.8942 - acc: 0.9312     \n",
      "Epoch 12/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.6497 - acc: 0.9363     \n",
      "Epoch 13/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.4474 - acc: 0.9375     \n",
      "Epoch 14/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.2624 - acc: 0.9404     \n",
      "Epoch 15/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.0968 - acc: 0.9423     \n",
      "Epoch 16/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.9486 - acc: 0.9431     \n",
      "Epoch 17/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.8302 - acc: 0.9382     \n",
      "Epoch 18/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.7033 - acc: 0.9443     \n",
      "Epoch 19/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.5968 - acc: 0.9465     \n",
      "Epoch 20/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.4907 - acc: 0.9494     \n",
      "Epoch 21/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.4002 - acc: 0.9465     \n",
      "Epoch 22/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.3112 - acc: 0.9501     \n",
      "Epoch 23/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.2389 - acc: 0.9528     \n",
      "Epoch 24/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.1616 - acc: 0.9528     \n",
      "Epoch 25/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.0934 - acc: 0.9564     \n",
      "Epoch 26/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.0241 - acc: 0.9562     \n",
      "Epoch 27/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9699 - acc: 0.9542     \n",
      "Epoch 28/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9117 - acc: 0.9545     \n",
      "Epoch 29/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8523 - acc: 0.9600     \n",
      "Epoch 30/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8062 - acc: 0.9574     \n",
      "# # # Evaluating cv-fold...\n",
      "480/485 [============================>.] - ETA: 0s \n",
      "accuracy: 90.72164949682569\n",
      "precision: 92.17391304347827\n",
      "recall: 88.70292887029288\n",
      "f1_score: 90.40511727078892\n",
      "Training fold 3/10\n",
      "Epoch 1/30\n",
      "4128/4128 [==============================] - 3s - loss: 19.4215 - acc: 0.8270     \n",
      "Epoch 2/30\n",
      "4128/4128 [==============================] - 1s - loss: 14.4827 - acc: 0.8728     \n",
      "Epoch 3/30\n",
      "4128/4128 [==============================] - 1s - loss: 11.8579 - acc: 0.8903     \n",
      "Epoch 4/30\n",
      "4128/4128 [==============================] - 1s - loss: 10.2280 - acc: 0.8966     \n",
      "Epoch 5/30\n",
      "4128/4128 [==============================] - 1s - loss: 9.0877 - acc: 0.9079     \n",
      "Epoch 6/30\n",
      "4128/4128 [==============================] - 1s - loss: 8.2691 - acc: 0.9169     \n",
      "Epoch 7/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.6390 - acc: 0.9130     \n",
      "Epoch 8/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.1278 - acc: 0.9179     \n",
      "Epoch 9/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.7173 - acc: 0.9218     \n",
      "Epoch 10/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.3784 - acc: 0.9256     \n",
      "Epoch 11/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.0851 - acc: 0.9297     \n",
      "Epoch 12/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.8319 - acc: 0.9382     \n",
      "Epoch 13/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.6076 - acc: 0.9370     \n",
      "Epoch 14/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.4280 - acc: 0.9380     \n",
      "Epoch 15/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.2633 - acc: 0.9334     \n",
      "Epoch 16/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.0956 - acc: 0.9477     \n",
      "Epoch 17/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.9603 - acc: 0.9455     \n",
      "Epoch 18/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.8391 - acc: 0.9457     \n",
      "Epoch 19/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.7355 - acc: 0.9397     \n",
      "Epoch 20/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.6230 - acc: 0.9445     \n",
      "Epoch 21/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.5306 - acc: 0.9465     \n",
      "Epoch 22/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.4439 - acc: 0.9438     \n",
      "Epoch 23/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.3583 - acc: 0.9484     \n",
      "Epoch 24/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.2818 - acc: 0.9528     \n",
      "Epoch 25/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.2096 - acc: 0.9516     \n",
      "Epoch 26/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.1413 - acc: 0.9540     \n",
      "Epoch 27/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.0803 - acc: 0.9540     \n",
      "Epoch 28/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.0217 - acc: 0.9552     \n",
      "Epoch 29/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9687 - acc: 0.9513     \n",
      "Epoch 30/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9176 - acc: 0.9578     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 15s\n",
      "accuracy: 90.30927836280507\n",
      "precision: 91.73913043478261\n",
      "recall: 88.28451882845188\n",
      "f1_score: 89.97867803837953\n",
      "Training fold 4/10\n",
      "Epoch 1/30\n",
      "4128/4128 [==============================] - 2s - loss: 19.2180 - acc: 0.8246     \n",
      "Epoch 2/30\n",
      "4128/4128 [==============================] - 1s - loss: 14.1521 - acc: 0.8694     \n",
      "Epoch 3/30\n",
      "4128/4128 [==============================] - 1s - loss: 11.5057 - acc: 0.8941     \n",
      "Epoch 4/30\n",
      "4128/4128 [==============================] - 1s - loss: 9.8741 - acc: 0.8978     \n",
      "Epoch 5/30\n",
      "4128/4128 [==============================] - 1s - loss: 8.7498 - acc: 0.9026     \n",
      "Epoch 6/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.9282 - acc: 0.9140     \n",
      "Epoch 7/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.2967 - acc: 0.9218     \n",
      "Epoch 8/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.8118 - acc: 0.9167     \n",
      "Epoch 9/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.4052 - acc: 0.9220     \n",
      "Epoch 10/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.0628 - acc: 0.9285     \n",
      "Epoch 11/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.7786 - acc: 0.9331     \n",
      "Epoch 12/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.5345 - acc: 0.9322     \n",
      "Epoch 13/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.3252 - acc: 0.9358     \n",
      "Epoch 14/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.1439 - acc: 0.9341     \n",
      "Epoch 15/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.9769 - acc: 0.9375     \n",
      "Epoch 16/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.8287 - acc: 0.9423     \n",
      "Epoch 17/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.6950 - acc: 0.9414     \n",
      "Epoch 18/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.5767 - acc: 0.9457     \n",
      "Epoch 19/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.4754 - acc: 0.9394     \n",
      "Epoch 20/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.3659 - acc: 0.9516     \n",
      "Epoch 21/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.2749 - acc: 0.9494     \n",
      "Epoch 22/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.1951 - acc: 0.9511     \n",
      "Epoch 23/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.1156 - acc: 0.9489     \n",
      "Epoch 24/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.0506 - acc: 0.9433     \n",
      "Epoch 25/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9709 - acc: 0.9482     \n",
      "Epoch 26/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9104 - acc: 0.9516     \n",
      "Epoch 27/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8546 - acc: 0.9513     \n",
      "Epoch 28/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.7874 - acc: 0.9586     \n",
      "Epoch 29/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.7361 - acc: 0.9552     \n",
      "Epoch 30/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.6930 - acc: 0.9571     \n",
      "# # # Evaluating cv-fold...\n",
      "480/485 [============================>.] - ETA: 0s \n",
      "accuracy: 89.48453609476384\n",
      "precision: 91.5929203539823\n",
      "recall: 86.61087866108787\n",
      "f1_score: 89.03225806451613\n",
      "Training fold 5/10\n",
      "Epoch 1/30\n",
      "4128/4128 [==============================] - 2s - loss: 19.2212 - acc: 0.8350     \n",
      "Epoch 2/30\n",
      "4128/4128 [==============================] - 1s - loss: 14.2002 - acc: 0.8808     \n",
      "Epoch 3/30\n",
      "4128/4128 [==============================] - 1s - loss: 11.5673 - acc: 0.8864     \n",
      "Epoch 4/30\n",
      "4128/4128 [==============================] - 1s - loss: 9.9385 - acc: 0.8997     \n",
      "Epoch 5/30\n",
      "4128/4128 [==============================] - 1s - loss: 8.8137 - acc: 0.9087     \n",
      "Epoch 6/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.9963 - acc: 0.9099     \n",
      "Epoch 7/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.3727 - acc: 0.9164     \n",
      "Epoch 8/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.8739 - acc: 0.9227     \n",
      "Epoch 9/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.4662 - acc: 0.9266     \n",
      "Epoch 10/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.1335 - acc: 0.9317     \n",
      "Epoch 11/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.8497 - acc: 0.9317     \n",
      "Epoch 12/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.6006 - acc: 0.9334     \n",
      "Epoch 13/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.3883 - acc: 0.9329     \n",
      "Epoch 14/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.2140 - acc: 0.9327     \n",
      "Epoch 15/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.0408 - acc: 0.9423     \n",
      "Epoch 16/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.8879 - acc: 0.9445     \n",
      "Epoch 17/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.7633 - acc: 0.9423     \n",
      "Epoch 18/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.6440 - acc: 0.9462     \n",
      "Epoch 19/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.5259 - acc: 0.9511     \n",
      "Epoch 20/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.4337 - acc: 0.9450     \n",
      "Epoch 21/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.3340 - acc: 0.9545     \n",
      "Epoch 22/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.2547 - acc: 0.9484     \n",
      "Epoch 23/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.1727 - acc: 0.9499     \n",
      "Epoch 24/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.1006 - acc: 0.9508     \n",
      "Epoch 25/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.0321 - acc: 0.9528     \n",
      "Epoch 26/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9634 - acc: 0.9559     \n",
      "Epoch 27/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9079 - acc: 0.9535     \n",
      "Epoch 28/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8478 - acc: 0.9552     \n",
      "Epoch 29/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.7990 - acc: 0.9569     \n",
      "Epoch 30/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.7499 - acc: 0.9528     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 15s\n",
      "accuracy: 89.89690722878446\n",
      "precision: 92.03539823008849\n",
      "recall: 87.02928870292888\n",
      "f1_score: 89.46236559139784\n",
      "Training fold 6/10\n",
      "Epoch 1/30\n",
      "4128/4128 [==============================] - 3s - loss: 19.0694 - acc: 0.8411     \n",
      "Epoch 2/30\n",
      "4128/4128 [==============================] - 1s - loss: 13.9895 - acc: 0.8830     \n",
      "Epoch 3/30\n",
      "4128/4128 [==============================] - 1s - loss: 11.3811 - acc: 0.8866     \n",
      "Epoch 4/30\n",
      "4128/4128 [==============================] - 1s - loss: 9.7732 - acc: 0.8956     \n",
      "Epoch 5/30\n",
      "4128/4128 [==============================] - 1s - loss: 8.6719 - acc: 0.9082     \n",
      "Epoch 6/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.8730 - acc: 0.9099     \n",
      "Epoch 7/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.2591 - acc: 0.9225     \n",
      "Epoch 8/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.7737 - acc: 0.9191     \n",
      "Epoch 9/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.3845 - acc: 0.9234     \n",
      "Epoch 10/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.0482 - acc: 0.9314     \n",
      "Epoch 11/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.7771 - acc: 0.9314     \n",
      "Epoch 12/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.5362 - acc: 0.9365     \n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4128/4128 [==============================] - 1s - loss: 5.3290 - acc: 0.9351     \n",
      "Epoch 14/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.1492 - acc: 0.9356     \n",
      "Epoch 15/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.9870 - acc: 0.9387     \n",
      "Epoch 16/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.8378 - acc: 0.9450     \n",
      "Epoch 17/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.7207 - acc: 0.9419     \n",
      "Epoch 18/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.6019 - acc: 0.9392     \n",
      "Epoch 19/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.4895 - acc: 0.9479     \n",
      "Epoch 20/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.3881 - acc: 0.9462     \n",
      "Epoch 21/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.2965 - acc: 0.9491     \n",
      "Epoch 22/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.2181 - acc: 0.9489     \n",
      "Epoch 23/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.1306 - acc: 0.9557     \n",
      "Epoch 24/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.0669 - acc: 0.9528     \n",
      "Epoch 25/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.0000 - acc: 0.9528     \n",
      "Epoch 26/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9325 - acc: 0.9545     - ETA: 1s - loss: 3.9\n",
      "Epoch 27/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8777 - acc: 0.9484     \n",
      "Epoch 28/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8174 - acc: 0.9552     \n",
      "Epoch 29/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.7686 - acc: 0.9540     \n",
      "Epoch 30/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.7146 - acc: 0.9571     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 16s\n",
      "accuracy: 90.72164949682569\n",
      "precision: 92.54385964912281\n",
      "recall: 88.28451882845188\n",
      "f1_score: 90.36402569593149\n",
      "Training fold 7/10\n",
      "Epoch 1/30\n",
      "4128/4128 [==============================] - 3s - loss: 19.2612 - acc: 0.8229     \n",
      "Epoch 2/30\n",
      "4128/4128 [==============================] - 1s - loss: 14.2256 - acc: 0.8738     \n",
      "Epoch 3/30\n",
      "4128/4128 [==============================] - 1s - loss: 11.5807 - acc: 0.8915     \n",
      "Epoch 4/30\n",
      "4128/4128 [==============================] - 1s - loss: 9.9351 - acc: 0.9026     \n",
      "Epoch 5/30\n",
      "4128/4128 [==============================] - 1s - loss: 8.8073 - acc: 0.9128     \n",
      "Epoch 6/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.9803 - acc: 0.9198     \n",
      "Epoch 7/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.3473 - acc: 0.9203     \n",
      "Epoch 8/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.8547 - acc: 0.9218     \n",
      "Epoch 9/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.4434 - acc: 0.9278     \n",
      "Epoch 10/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.1138 - acc: 0.9273     \n",
      "Epoch 11/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.8154 - acc: 0.9358     \n",
      "Epoch 12/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.5707 - acc: 0.9387     \n",
      "Epoch 13/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.3638 - acc: 0.9404     \n",
      "Epoch 14/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.1753 - acc: 0.9431     \n",
      "Epoch 15/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.0232 - acc: 0.9329     \n",
      "Epoch 16/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.8594 - acc: 0.9423     \n",
      "Epoch 17/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.7400 - acc: 0.9462     \n",
      "Epoch 18/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.6075 - acc: 0.9443     \n",
      "Epoch 19/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.4983 - acc: 0.9482     \n",
      "Epoch 20/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.4020 - acc: 0.9489     \n",
      "Epoch 21/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.3081 - acc: 0.9455     \n",
      "Epoch 22/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.2233 - acc: 0.9496     \n",
      "Epoch 23/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.1278 - acc: 0.9617     \n",
      "Epoch 24/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.0633 - acc: 0.9554     \n",
      "Epoch 25/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9991 - acc: 0.9552     \n",
      "Epoch 26/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9303 - acc: 0.9537     \n",
      "Epoch 27/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8722 - acc: 0.9562     \n",
      "Epoch 28/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8156 - acc: 0.9545     \n",
      "Epoch 29/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.7627 - acc: 0.9545     \n",
      "Epoch 30/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.7068 - acc: 0.9591     \n",
      "# # # Evaluating cv-fold...\n",
      "485/485 [==============================] - 1s      \n",
      "\n",
      "accuracy: 90.72164949682569\n",
      "precision: 89.11290322580645\n",
      "recall: 92.46861924686193\n",
      "f1_score: 90.75975359342917\n",
      "Training fold 8/10\n",
      "Epoch 1/30\n",
      "4128/4128 [==============================] - 3s - loss: 19.1938 - acc: 0.8358     \n",
      "Epoch 2/30\n",
      "4128/4128 [==============================] - 1s - loss: 14.1284 - acc: 0.8755     \n",
      "Epoch 3/30\n",
      "4128/4128 [==============================] - 1s - loss: 11.4678 - acc: 0.8937     \n",
      "Epoch 4/30\n",
      "4128/4128 [==============================] - 1s - loss: 9.8296 - acc: 0.9046     \n",
      "Epoch 5/30\n",
      "4128/4128 [==============================] - 1s - loss: 8.7040 - acc: 0.9106     - ETA: 0s - loss: 9.\n",
      "Epoch 6/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.8876 - acc: 0.9186     \n",
      "Epoch 7/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.2588 - acc: 0.9230     \n",
      "Epoch 8/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.7674 - acc: 0.9237     \n",
      "Epoch 9/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.3631 - acc: 0.9251     \n",
      "Epoch 10/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.0387 - acc: 0.9285     \n",
      "Epoch 11/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.7491 - acc: 0.9314     \n",
      "Epoch 12/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.5026 - acc: 0.9421     \n",
      "Epoch 13/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.2971 - acc: 0.9394     - ETA: 0s - loss: 5.2979 - acc: 0.939\n",
      "Epoch 14/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.1127 - acc: 0.9411     \n",
      "Epoch 15/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.9524 - acc: 0.9450     \n",
      "Epoch 16/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.7976 - acc: 0.9453     \n",
      "Epoch 17/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.6714 - acc: 0.9399     \n",
      "Epoch 18/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.5558 - acc: 0.9460     \n",
      "Epoch 19/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.4449 - acc: 0.9443     \n",
      "Epoch 20/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.3517 - acc: 0.9462     \n",
      "Epoch 21/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.2553 - acc: 0.9499     \n",
      "Epoch 22/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.1672 - acc: 0.9547     \n",
      "Epoch 23/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.0885 - acc: 0.9540     \n",
      "Epoch 24/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.0197 - acc: 0.9486     \n",
      "Epoch 25/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9479 - acc: 0.9564     \n",
      "Epoch 26/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8848 - acc: 0.9557     \n",
      "Epoch 27/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8279 - acc: 0.9549     \n",
      "Epoch 28/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.7715 - acc: 0.9554     \n",
      "Epoch 29/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.7194 - acc: 0.9566     \n",
      "Epoch 30/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.6646 - acc: 0.9615     \n",
      "# # # Evaluating cv-fold...\n",
      "480/485 [============================>.] - ETA: 0s \n",
      "accuracy: 91.13402063084631\n",
      "precision: 92.98245614035088\n",
      "recall: 88.70292887029288\n",
      "f1_score: 90.79229122055675\n",
      "Training fold 9/10\n",
      "Epoch 1/30\n",
      "4128/4128 [==============================] - 3s - loss: 19.3055 - acc: 0.8312     \n",
      "Epoch 2/30\n",
      "4128/4128 [==============================] - 1s - loss: 14.2750 - acc: 0.8716     \n",
      "Epoch 3/30\n",
      "4128/4128 [==============================] - 1s - loss: 11.6240 - acc: 0.8910     \n",
      "Epoch 4/30\n",
      "4128/4128 [==============================] - 1s - loss: 9.9850 - acc: 0.8985     \n",
      "Epoch 5/30\n",
      "4128/4128 [==============================] - 1s - loss: 8.8553 - acc: 0.9084     \n",
      "Epoch 6/30\n",
      "4128/4128 [==============================] - 1s - loss: 8.0366 - acc: 0.9130     \n",
      "Epoch 7/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.4027 - acc: 0.9230     \n",
      "Epoch 8/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.9054 - acc: 0.9215     \n",
      "Epoch 9/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.5114 - acc: 0.9215     \n",
      "Epoch 10/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.1770 - acc: 0.9249     \n",
      "Epoch 11/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.8891 - acc: 0.9317     \n",
      "Epoch 12/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.6513 - acc: 0.9331     \n",
      "Epoch 13/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.4379 - acc: 0.9373     \n",
      "Epoch 14/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.2469 - acc: 0.9397     \n",
      "Epoch 15/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.0856 - acc: 0.9421     \n",
      "Epoch 16/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.9402 - acc: 0.9457     \n",
      "Epoch 17/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.8114 - acc: 0.9411     \n",
      "Epoch 18/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.6803 - acc: 0.9486     \n",
      "Epoch 19/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.5779 - acc: 0.9440     \n",
      "Epoch 20/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.4779 - acc: 0.9453     \n",
      "Epoch 21/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.3906 - acc: 0.9465     \n",
      "Epoch 22/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.3006 - acc: 0.9460     \n",
      "Epoch 23/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.2182 - acc: 0.9532     \n",
      "Epoch 24/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.1456 - acc: 0.9535     \n",
      "Epoch 25/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.0790 - acc: 0.9549     \n",
      "Epoch 26/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.0216 - acc: 0.9484     \n",
      "Epoch 27/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9617 - acc: 0.9499     \n",
      "Epoch 28/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8996 - acc: 0.9569     \n",
      "Epoch 29/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8482 - acc: 0.9547     \n",
      "Epoch 30/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.7897 - acc: 0.9625     \n",
      "# # # Evaluating cv-fold...\n",
      "480/485 [============================>.] - ETA: 0s \n",
      "accuracy: 89.27835054004315\n",
      "precision: 90.47619047619048\n",
      "recall: 87.44769874476988\n",
      "f1_score: 88.93617021276596\n",
      "Training fold 10/10\n",
      "Epoch 1/30\n",
      "4128/4128 [==============================] - 3s - loss: 19.1616 - acc: 0.8299     \n",
      "Epoch 2/30\n",
      "4128/4128 [==============================] - 1s - loss: 14.0906 - acc: 0.8767     \n",
      "Epoch 3/30\n",
      "4128/4128 [==============================] - 1s - loss: 11.4454 - acc: 0.8953     \n",
      "Epoch 4/30\n",
      "4128/4128 [==============================] - 1s - loss: 9.8234 - acc: 0.8987     \n",
      "Epoch 5/30\n",
      "4128/4128 [==============================] - 1s - loss: 8.7106 - acc: 0.9046     \n",
      "Epoch 6/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.9000 - acc: 0.9065     \n",
      "Epoch 7/30\n",
      "4128/4128 [==============================] - 1s - loss: 7.2826 - acc: 0.9176     \n",
      "Epoch 8/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.7915 - acc: 0.9184     \n",
      "Epoch 9/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.4009 - acc: 0.9179     \n",
      "Epoch 10/30\n",
      "4128/4128 [==============================] - 1s - loss: 6.0592 - acc: 0.9278     \n",
      "Epoch 11/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.7862 - acc: 0.9288     \n",
      "Epoch 12/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.5458 - acc: 0.9344     \n",
      "Epoch 13/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.3363 - acc: 0.9341     \n",
      "Epoch 14/30\n",
      "4128/4128 [==============================] - 1s - loss: 5.1536 - acc: 0.9351     \n",
      "Epoch 15/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.9924 - acc: 0.9375     \n",
      "Epoch 16/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.8411 - acc: 0.9419     \n",
      "Epoch 17/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.7136 - acc: 0.9416     \n",
      "Epoch 18/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.6000 - acc: 0.9414     \n",
      "Epoch 19/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.4880 - acc: 0.9474     \n",
      "Epoch 20/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.3895 - acc: 0.9482     \n",
      "Epoch 21/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.2971 - acc: 0.9469     \n",
      "Epoch 22/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.2143 - acc: 0.9513     \n",
      "Epoch 23/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.1362 - acc: 0.9511     \n",
      "Epoch 24/30\n",
      "4128/4128 [==============================] - 1s - loss: 4.0720 - acc: 0.9484     \n",
      "Epoch 25/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9991 - acc: 0.9530     \n",
      "Epoch 26/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.9449 - acc: 0.9462     \n",
      "Epoch 27/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8772 - acc: 0.9545     \n",
      "Epoch 28/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.8198 - acc: 0.9535     \n",
      "Epoch 29/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.7639 - acc: 0.9578     \n",
      "Epoch 30/30\n",
      "4128/4128 [==============================] - 1s - loss: 3.7158 - acc: 0.9578     \n",
      "# # # Evaluating cv-fold...\n",
      "480/485 [============================>.] - ETA: 0s \n",
      "accuracy: 90.72164949682569\n",
      "precision: 90.75630252100841\n",
      "recall: 90.3765690376569\n",
      "f1_score: 90.56603773584906\n",
      "\n",
      "Final cross-validation score:\n",
      "90.24742269393093 +/- 0.6257315818283928\n",
      "91.29088723941383 +/- 1.2236418016798474\n",
      "88.70292887029288 +/- 1.620495123936159\n",
      "89.96048735242437 +/- 0.681377707113486\n"
     ]
    }
   ],
   "source": [
    "# ON THE AUGMENTED DATASET WITH FLIPLR\n",
    "\n",
    "folds = 10\n",
    "cv_accuracies = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1_score = []\n",
    "\n",
    "for fold in range(folds):\n",
    "    print(\"Training fold \" + str(fold + 1) + \"/\" + str(folds))\n",
    "    \n",
    "    shuffle(train_tactile_images, train_labels_cat)\n",
    "    shuffle(test_tactile_images, test_labels_cat) \n",
    "    \n",
    "    # build model\n",
    "    epochs = 30\n",
    "    batch = 32\n",
    "    \n",
    "    learning_rate = 0.0001\n",
    "    epsilon = 1e-08\n",
    "    decay_rate = 0.005\n",
    "    \n",
    "    l2_reg = 0.015\n",
    "    drop_prob = 0.25\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(FINGERS, TACTILE_IMAGE_ROWS, TACTILE_IMAGE_COLS), \n",
    "                     data_format='channels_first',\n",
    "                     use_bias=False, kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1024, kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(drop_prob))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # compile and train\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.Adam(lr=learning_rate, epsilon=epsilon, decay=decay_rate), \n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(train_tactile_images, train_labels_cat, epochs=epochs, batch_size=batch, verbose=1)\n",
    "    \n",
    "    # evaluate\n",
    "    print(\"# # # Evaluating cv-fold...\")\n",
    "    scores = model.evaluate(test_tactile_images, test_labels_cat, verbose=1)\n",
    "    cv_accuracies.append(scores[1] * 100)\n",
    "    \n",
    "    predictions = model.predict(test_tactile_images)\n",
    "    [precision, recall, f1_score, _] = precision_recall_fscore_support(np.argmax(test_labels_cat, axis=1), \n",
    "                                                                          np.argmax(predictions, axis=1), \n",
    "                                                                          average='binary', pos_label=1)\n",
    "    \n",
    "    cv_precision.append(precision * 100)\n",
    "    cv_recall.append(recall * 100)\n",
    "    cv_f1_score.append(f1_score * 100)\n",
    "    \n",
    "    print(\"\\naccuracy:\", scores[1] * 100)\n",
    "    print(\"precision:\", precision * 100)\n",
    "    print(\"recall:\", recall * 100)\n",
    "    print(\"f1_score:\", f1_score * 100)\n",
    "    \n",
    "print(\"\\nFinal cross-validation score:\")\n",
    "print(np.mean(cv_accuracies), \"+/-\", np.std(cv_accuracies))\n",
    "print(np.mean(cv_precision), \"+/-\", np.std(cv_precision))\n",
    "print(np.mean(cv_recall), \"+/-\", np.std(cv_recall))\n",
    "print(np.mean(cv_f1_score), \"+/-\", np.std(cv_f1_score))\n",
    "\n",
    "# IROS\n",
    "#86.0355987113 +/- 0.383259524026\n",
    "#86.47674489 +/- 0.501892412426\n",
    "#83.8644067797 +/- 0.775967670662\n",
    "#85.1477152443 +/- 0.441251814143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/10\n",
      "Epoch 1/30\n",
      "6192/6192 [==============================] - 4s - loss: 18.0447 - acc: 0.8280     \n",
      "Epoch 2/30\n",
      "6192/6192 [==============================] - 2s - loss: 12.4967 - acc: 0.8742     \n",
      "Epoch 3/30\n",
      "6192/6192 [==============================] - 2s - loss: 10.0204 - acc: 0.8849     \n",
      "Epoch 4/30\n",
      "6192/6192 [==============================] - 2s - loss: 8.5823 - acc: 0.8947     \n",
      "Epoch 5/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.6355 - acc: 0.9026     \n",
      "Epoch 6/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.9625 - acc: 0.9042     \n",
      "Epoch 7/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.4504 - acc: 0.9133     \n",
      "Epoch 8/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.0520 - acc: 0.9155     \n",
      "Epoch 9/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.7305 - acc: 0.9172     \n",
      "Epoch 10/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.4671 - acc: 0.9173     \n",
      "Epoch 11/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.2385 - acc: 0.9238     \n",
      "Epoch 12/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.0527 - acc: 0.9226     \n",
      "Epoch 13/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.8859 - acc: 0.9233     \n",
      "Epoch 14/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.7443 - acc: 0.9254     \n",
      "Epoch 15/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.6108 - acc: 0.9304     \n",
      "Epoch 16/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.4943 - acc: 0.9288     \n",
      "Epoch 17/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.3974 - acc: 0.9285     \n",
      "Epoch 18/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.2937 - acc: 0.9365     \n",
      "Epoch 19/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.2102 - acc: 0.9351     \n",
      "Epoch 20/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.1370 - acc: 0.9328     \n",
      "Epoch 21/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0558 - acc: 0.9398     \n",
      "Epoch 22/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9873 - acc: 0.9399     \n",
      "Epoch 23/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9286 - acc: 0.9367     \n",
      "Epoch 24/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8754 - acc: 0.9370     \n",
      "Epoch 25/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8221 - acc: 0.9377     \n",
      "Epoch 26/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7621 - acc: 0.9422     \n",
      "Epoch 27/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7160 - acc: 0.9391     \n",
      "Epoch 28/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.6688 - acc: 0.9462     \n",
      "Epoch 29/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.6247 - acc: 0.9457     \n",
      "Epoch 30/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.5855 - acc: 0.9485     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 17s\n",
      "accuracy: 91.34020619785663\n",
      "precision: 91.21338912133892\n",
      "recall: 91.21338912133892\n",
      "f1_score: 91.21338912133892\n",
      "Training fold 2/10\n",
      "Epoch 1/30\n",
      "6192/6192 [==============================] - 3s - loss: 18.1376 - acc: 0.8236     \n",
      "Epoch 2/30\n",
      "6192/6192 [==============================] - 2s - loss: 12.6313 - acc: 0.8697     \n",
      "Epoch 3/30\n",
      "6192/6192 [==============================] - 2s - loss: 10.1603 - acc: 0.8831     \n",
      "Epoch 4/30\n",
      "6192/6192 [==============================] - 2s - loss: 8.7350 - acc: 0.8863     \n",
      "Epoch 5/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.7917 - acc: 0.8965     \n",
      "Epoch 6/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.1235 - acc: 0.9008     \n",
      "Epoch 7/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.6215 - acc: 0.8989     \n",
      "Epoch 8/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.2222 - acc: 0.9109     \n",
      "Epoch 9/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.8984 - acc: 0.9165     \n",
      "Epoch 10/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.6323 - acc: 0.9225     \n",
      "Epoch 11/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.4173 - acc: 0.9146     \n",
      "Epoch 12/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.2249 - acc: 0.9196     \n",
      "Epoch 13/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.0657 - acc: 0.9175     \n",
      "Epoch 14/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.9164 - acc: 0.9194     \n",
      "Epoch 15/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.7877 - acc: 0.9257     \n",
      "Epoch 16/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.6735 - acc: 0.9238     \n",
      "Epoch 17/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.5721 - acc: 0.9264     \n",
      "Epoch 18/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.4783 - acc: 0.9228     \n",
      "Epoch 19/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.3926 - acc: 0.9255     \n",
      "Epoch 20/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.3103 - acc: 0.9310     \n",
      "Epoch 21/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.2399 - acc: 0.9322     \n",
      "Epoch 22/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.1721 - acc: 0.9317     \n",
      "Epoch 23/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.1130 - acc: 0.9331     \n",
      "Epoch 24/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0496 - acc: 0.9401     \n",
      "Epoch 25/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9957 - acc: 0.9370     \n",
      "Epoch 26/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9426 - acc: 0.9377     \n",
      "Epoch 27/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8999 - acc: 0.9386     \n",
      "Epoch 28/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8532 - acc: 0.9369     \n",
      "Epoch 29/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8103 - acc: 0.9369     \n",
      "Epoch 30/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7690 - acc: 0.9390     \n",
      "# # # Evaluating cv-fold...\n",
      "485/485 [==============================] - 1s      \n",
      "\n",
      "accuracy: 91.13402064313594\n",
      "precision: 93.36283185840708\n",
      "recall: 88.28451882845188\n",
      "f1_score: 90.75268817204302\n",
      "Training fold 3/10\n",
      "Epoch 1/30\n",
      "6192/6192 [==============================] - 4s - loss: 18.1572 - acc: 0.8204     \n",
      "Epoch 2/30\n",
      "6192/6192 [==============================] - 2s - loss: 12.6618 - acc: 0.8664     \n",
      "Epoch 3/30\n",
      "6192/6192 [==============================] - 2s - loss: 10.1963 - acc: 0.8821     \n",
      "Epoch 4/30\n",
      "6192/6192 [==============================] - 2s - loss: 8.7608 - acc: 0.8911     \n",
      "Epoch 5/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.8101 - acc: 0.8984     \n",
      "Epoch 6/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.1293 - acc: 0.9083     \n",
      "Epoch 7/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.6207 - acc: 0.9052     \n",
      "Epoch 8/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.2247 - acc: 0.9110     \n",
      "Epoch 9/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.9063 - acc: 0.9121     \n",
      "Epoch 10/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.6317 - acc: 0.9173     \n",
      "Epoch 11/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.4092 - acc: 0.9180     \n",
      "Epoch 12/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.2192 - acc: 0.9228     \n",
      "Epoch 13/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.0537 - acc: 0.9204     \n",
      "Epoch 14/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.9048 - acc: 0.9265     \n",
      "Epoch 15/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.7747 - acc: 0.9272     \n",
      "Epoch 16/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.6583 - acc: 0.9307     \n",
      "Epoch 17/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.5508 - acc: 0.9297     \n",
      "Epoch 18/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.4586 - acc: 0.9323     \n",
      "Epoch 19/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.3690 - acc: 0.9304     \n",
      "Epoch 20/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.2932 - acc: 0.9338     \n",
      "Epoch 21/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.2157 - acc: 0.9380     \n",
      "Epoch 22/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.1466 - acc: 0.9380     \n",
      "Epoch 23/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0834 - acc: 0.9402     \n",
      "Epoch 24/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0290 - acc: 0.9393     \n",
      "Epoch 25/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9712 - acc: 0.9407     \n",
      "Epoch 26/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9130 - acc: 0.9433     \n",
      "Epoch 27/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8639 - acc: 0.9411     \n",
      "Epoch 28/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8218 - acc: 0.9420     \n",
      "Epoch 29/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7787 - acc: 0.9414     \n",
      "Epoch 30/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7343 - acc: 0.9428     \n",
      "# # # Evaluating cv-fold...\n",
      "485/485 [==============================] - 1s      \n",
      "\n",
      "accuracy: 89.69072166177415\n",
      "precision: 90.9090909090909\n",
      "recall: 87.86610878661088\n",
      "f1_score: 89.36170212765956\n",
      "Training fold 4/10\n",
      "Epoch 1/30\n",
      "6192/6192 [==============================] - 3s - loss: 18.1879 - acc: 0.8225     \n",
      "Epoch 2/30\n",
      "6192/6192 [==============================] - 2s - loss: 12.7223 - acc: 0.8685     \n",
      "Epoch 3/30\n",
      "6192/6192 [==============================] - 2s - loss: 10.2265 - acc: 0.8882     \n",
      "Epoch 4/30\n",
      "6192/6192 [==============================] - 2s - loss: 8.7795 - acc: 0.8942     \n",
      "Epoch 5/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.8231 - acc: 0.8983     \n",
      "Epoch 6/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.1393 - acc: 0.9057     \n",
      "Epoch 7/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.6356 - acc: 0.9058     \n",
      "Epoch 8/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.2318 - acc: 0.9089     \n",
      "Epoch 9/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.9073 - acc: 0.9160     \n",
      "Epoch 10/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.6410 - acc: 0.9134     \n",
      "Epoch 11/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.4184 - acc: 0.9160     \n",
      "Epoch 12/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.2152 - acc: 0.9239     \n",
      "Epoch 13/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.0659 - acc: 0.9186     \n",
      "Epoch 14/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.9089 - acc: 0.9233     \n",
      "Epoch 15/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.7750 - acc: 0.9276     \n",
      "Epoch 16/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.6553 - acc: 0.9318     \n",
      "Epoch 17/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.5547 - acc: 0.9333     \n",
      "Epoch 18/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.4643 - acc: 0.9301     \n",
      "Epoch 19/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.3700 - acc: 0.9330     \n",
      "Epoch 20/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.2933 - acc: 0.9315     \n",
      "Epoch 21/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.2173 - acc: 0.9341     \n",
      "Epoch 22/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.1472 - acc: 0.9370     \n",
      "Epoch 23/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0747 - acc: 0.9419     \n",
      "Epoch 24/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0269 - acc: 0.9349     \n",
      "Epoch 25/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9699 - acc: 0.9401     \n",
      "Epoch 26/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9174 - acc: 0.9396     \n",
      "Epoch 27/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8705 - acc: 0.9404     \n",
      "Epoch 28/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8181 - acc: 0.9456     \n",
      "Epoch 29/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7797 - acc: 0.9436     \n",
      "Epoch 30/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7325 - acc: 0.9427     \n",
      "# # # Evaluating cv-fold...\n",
      "416/485 [========================>.....] - ETA: 0s \n",
      "accuracy: 91.13402063084631\n",
      "precision: 92.24137931034483\n",
      "recall: 89.5397489539749\n",
      "f1_score: 90.87048832271762\n",
      "Training fold 5/10\n",
      "Epoch 1/30\n",
      "6192/6192 [==============================] - 4s - loss: 18.2185 - acc: 0.8296     \n",
      "Epoch 2/30\n",
      "6192/6192 [==============================] - 2s - loss: 12.7699 - acc: 0.8713     \n",
      "Epoch 3/30\n",
      "6192/6192 [==============================] - 2s - loss: 10.2993 - acc: 0.8789     \n",
      "Epoch 4/30\n",
      "6192/6192 [==============================] - 2s - loss: 8.8547 - acc: 0.8929     \n",
      "Epoch 5/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.9129 - acc: 0.8942     \n",
      "Epoch 6/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.2248 - acc: 0.9042     \n",
      "Epoch 7/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.7156 - acc: 0.9046     \n",
      "Epoch 8/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.3042 - acc: 0.9100     \n",
      "Epoch 9/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.9788 - acc: 0.9117     \n",
      "Epoch 10/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.7108 - acc: 0.9173     - ETA: 1s - loss: 5.78 - ETA: 0s - loss: 5.748\n",
      "Epoch 11/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.4755 - acc: 0.9201     \n",
      "Epoch 12/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.2837 - acc: 0.9194     \n",
      "Epoch 13/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.1057 - acc: 0.9223     \n",
      "Epoch 14/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.9626 - acc: 0.9220     \n",
      "Epoch 15/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.8221 - acc: 0.9288     \n",
      "Epoch 16/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.6996 - acc: 0.9315     \n",
      "Epoch 17/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.5902 - acc: 0.9314     \n",
      "Epoch 18/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.5017 - acc: 0.9315     \n",
      "Epoch 19/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.4101 - acc: 0.9312     \n",
      "Epoch 20/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.3288 - acc: 0.9339     \n",
      "Epoch 21/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.2550 - acc: 0.9328     \n",
      "Epoch 22/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.1798 - acc: 0.9335     \n",
      "Epoch 23/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.1197 - acc: 0.9346     \n",
      "Epoch 24/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0575 - acc: 0.9359     \n",
      "Epoch 25/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0027 - acc: 0.9354     \n",
      "Epoch 26/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9499 - acc: 0.9369     \n",
      "Epoch 27/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9013 - acc: 0.9375     \n",
      "Epoch 28/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8513 - acc: 0.9370     \n",
      "Epoch 29/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8053 - acc: 0.9412     \n",
      "Epoch 30/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7633 - acc: 0.9438     - ETA: 0s - loss: 3.7655 -\n",
      "# # # Evaluating cv-fold...\n",
      "448/485 [==========================>...] - ETA: 0s \n",
      "accuracy: 88.45360827200192\n",
      "precision: 87.96680497925311\n",
      "recall: 88.70292887029288\n",
      "f1_score: 88.33333333333333\n",
      "Training fold 6/10\n",
      "Epoch 1/30\n",
      "6192/6192 [==============================] - 4s - loss: 18.0145 - acc: 0.8306     \n",
      "Epoch 2/30\n",
      "6192/6192 [==============================] - 2s - loss: 12.4773 - acc: 0.8655     \n",
      "Epoch 3/30\n",
      "6192/6192 [==============================] - 2s - loss: 9.9929 - acc: 0.8828      \n",
      "Epoch 4/30\n",
      "6192/6192 [==============================] - 2s - loss: 8.5594 - acc: 0.8910     \n",
      "Epoch 5/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.6117 - acc: 0.9002     \n",
      "Epoch 6/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.9480 - acc: 0.8997     \n",
      "Epoch 7/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.4422 - acc: 0.9042     \n",
      "Epoch 8/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.0482 - acc: 0.9120     \n",
      "Epoch 9/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.7316 - acc: 0.9139     \n",
      "Epoch 10/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.4710 - acc: 0.9170     \n",
      "Epoch 11/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.2489 - acc: 0.9225     \n",
      "Epoch 12/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.0673 - acc: 0.9188     \n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6192/6192 [==============================] - 2s - loss: 4.9001 - acc: 0.9233     \n",
      "Epoch 14/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.7566 - acc: 0.9267     - ETA: 1s - loss:\n",
      "Epoch 15/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.6337 - acc: 0.9236     \n",
      "Epoch 16/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.5137 - acc: 0.9294     \n",
      "Epoch 17/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.4127 - acc: 0.9309     \n",
      "Epoch 18/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.3210 - acc: 0.9323     \n",
      "Epoch 19/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.2387 - acc: 0.9315     \n",
      "Epoch 20/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.1594 - acc: 0.9317     \n",
      "Epoch 21/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0899 - acc: 0.9315     \n",
      "Epoch 22/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0239 - acc: 0.9328     \n",
      "Epoch 23/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9592 - acc: 0.9339     \n",
      "Epoch 24/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9040 - acc: 0.9352     \n",
      "Epoch 25/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8483 - acc: 0.9386     \n",
      "Epoch 26/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7996 - acc: 0.9415     \n",
      "Epoch 27/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7483 - acc: 0.9402     \n",
      "Epoch 28/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7037 - acc: 0.9417     \n",
      "Epoch 29/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.6648 - acc: 0.9385     \n",
      "Epoch 30/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.6201 - acc: 0.9433     \n",
      "# # # Evaluating cv-fold...\n",
      "416/485 [========================>.....] - ETA: 0s \n",
      "accuracy: 90.30927836280507\n",
      "precision: 90.67796610169492\n",
      "recall: 89.5397489539749\n",
      "f1_score: 90.10526315789474\n",
      "Training fold 7/10\n",
      "Epoch 1/30\n",
      "6192/6192 [==============================] - 4s - loss: 18.2341 - acc: 0.8328     \n",
      "Epoch 2/30\n",
      "6192/6192 [==============================] - 2s - loss: 12.7442 - acc: 0.8682     \n",
      "Epoch 3/30\n",
      "6192/6192 [==============================] - 2s - loss: 10.2588 - acc: 0.8866     \n",
      "Epoch 4/30\n",
      "6192/6192 [==============================] - 2s - loss: 8.8066 - acc: 0.8934     \n",
      "Epoch 5/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.8386 - acc: 0.9023     \n",
      "Epoch 6/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.1560 - acc: 0.9062     \n",
      "Epoch 7/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.6415 - acc: 0.9076     \n",
      "Epoch 8/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.2312 - acc: 0.9147     \n",
      "Epoch 9/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.9094 - acc: 0.9173     \n",
      "Epoch 10/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.6457 - acc: 0.9178     \n",
      "Epoch 11/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.4099 - acc: 0.9246     \n",
      "Epoch 12/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.2189 - acc: 0.9186     \n",
      "Epoch 13/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.0454 - acc: 0.9276     \n",
      "Epoch 14/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.9036 - acc: 0.9259     \n",
      "Epoch 15/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.7651 - acc: 0.9297     \n",
      "Epoch 16/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.6453 - acc: 0.9346     \n",
      "Epoch 17/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.5429 - acc: 0.9312     \n",
      "Epoch 18/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.4480 - acc: 0.9304     \n",
      "Epoch 19/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.3567 - acc: 0.9354     \n",
      "Epoch 20/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.2771 - acc: 0.9359     \n",
      "Epoch 21/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.2007 - acc: 0.9386     \n",
      "Epoch 22/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.1295 - acc: 0.9430     \n",
      "Epoch 23/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0662 - acc: 0.9383     \n",
      "Epoch 24/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0036 - acc: 0.9433     \n",
      "Epoch 25/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9489 - acc: 0.9419     \n",
      "Epoch 26/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8988 - acc: 0.9378     \n",
      "Epoch 27/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8509 - acc: 0.9433     \n",
      "Epoch 28/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7979 - acc: 0.9454     \n",
      "Epoch 29/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7559 - acc: 0.9457     \n",
      "Epoch 30/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7116 - acc: 0.9459     \n",
      "# # # Evaluating cv-fold...\n",
      "480/485 [============================>.] - ETA: 0s \n",
      "accuracy: 90.927835063836\n",
      "precision: 92.57641921397381\n",
      "recall: 88.70292887029288\n",
      "f1_score: 90.5982905982906\n",
      "Training fold 8/10\n",
      "Epoch 1/30\n",
      "6192/6192 [==============================] - 4s - loss: 18.0975 - acc: 0.8246     \n",
      "Epoch 2/30\n",
      "6192/6192 [==============================] - 2s - loss: 12.5387 - acc: 0.8734     \n",
      "Epoch 3/30\n",
      "6192/6192 [==============================] - 2s - loss: 10.0408 - acc: 0.8807     \n",
      "Epoch 4/30\n",
      "6192/6192 [==============================] - 2s - loss: 8.5898 - acc: 0.8934     \n",
      "Epoch 5/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.6511 - acc: 0.8973     \n",
      "Epoch 6/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.9702 - acc: 0.9025     \n",
      "Epoch 7/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.4545 - acc: 0.9125     \n",
      "Epoch 8/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.0569 - acc: 0.9121     \n",
      "Epoch 9/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.7358 - acc: 0.9173     \n",
      "Epoch 10/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.4728 - acc: 0.9170     \n",
      "Epoch 11/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.2470 - acc: 0.9230     \n",
      "Epoch 12/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.0542 - acc: 0.9273     \n",
      "Epoch 13/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.8954 - acc: 0.9204     \n",
      "Epoch 14/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.7458 - acc: 0.9267     \n",
      "Epoch 15/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.6165 - acc: 0.9289     \n",
      "Epoch 16/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.5009 - acc: 0.9338     \n",
      "Epoch 17/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.3957 - acc: 0.9322     \n",
      "Epoch 18/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.3039 - acc: 0.9349     \n",
      "Epoch 19/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.2207 - acc: 0.9343     \n",
      "Epoch 20/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.1463 - acc: 0.9307     \n",
      "Epoch 21/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0710 - acc: 0.9388     \n",
      "Epoch 22/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0035 - acc: 0.9390     \n",
      "Epoch 23/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9473 - acc: 0.9336     \n",
      "Epoch 24/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8828 - acc: 0.9407     \n",
      "Epoch 25/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8273 - acc: 0.9407     \n",
      "Epoch 26/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7783 - acc: 0.9369     \n",
      "Epoch 27/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7283 - acc: 0.9404     \n",
      "Epoch 28/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.6826 - acc: 0.9435     \n",
      "Epoch 29/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.6382 - acc: 0.9451     \n",
      "Epoch 30/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.5953 - acc: 0.9498     \n",
      "# # # Evaluating cv-fold...\n",
      "485/485 [==============================] - 1s      \n",
      "\n",
      "accuracy: 90.1030928080844\n",
      "precision: 92.07048458149781\n",
      "recall: 87.44769874476988\n",
      "f1_score: 89.69957081545064\n",
      "Training fold 9/10\n",
      "Epoch 1/30\n",
      "6192/6192 [==============================] - 4s - loss: 18.0884 - acc: 0.8278     \n",
      "Epoch 2/30\n",
      "6192/6192 [==============================] - 2s - loss: 12.5918 - acc: 0.8681     \n",
      "Epoch 3/30\n",
      "6192/6192 [==============================] - 2s - loss: 10.1402 - acc: 0.8777     \n",
      "Epoch 4/30\n",
      "6192/6192 [==============================] - 2s - loss: 8.7163 - acc: 0.8889     \n",
      "Epoch 5/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.7774 - acc: 0.8987     \n",
      "Epoch 6/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.1154 - acc: 0.8950     \n",
      "Epoch 7/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.6127 - acc: 0.9008     - ETA: 0s - loss: 6.6699 \n",
      "Epoch 8/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.2113 - acc: 0.9118     \n",
      "Epoch 9/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.8942 - acc: 0.9130     \n",
      "Epoch 10/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.6294 - acc: 0.9141     \n",
      "Epoch 11/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.4093 - acc: 0.9162     \n",
      "Epoch 12/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.2156 - acc: 0.9207     \n",
      "Epoch 13/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.0499 - acc: 0.9202     \n",
      "Epoch 14/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.9061 - acc: 0.9226     \n",
      "Epoch 15/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.7751 - acc: 0.9225     \n",
      "Epoch 16/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.6652 - acc: 0.9243     \n",
      "Epoch 17/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.5608 - acc: 0.9251     \n",
      "Epoch 18/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.4582 - acc: 0.9314     \n",
      "Epoch 19/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.3701 - acc: 0.9323     \n",
      "Epoch 20/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.3015 - acc: 0.9315     \n",
      "Epoch 21/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.2224 - acc: 0.9318     \n",
      "Epoch 22/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.1566 - acc: 0.9330     \n",
      "Epoch 23/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0985 - acc: 0.9307     \n",
      "Epoch 24/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0391 - acc: 0.9343     \n",
      "Epoch 25/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9785 - acc: 0.9375     \n",
      "Epoch 26/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9307 - acc: 0.9346     \n",
      "Epoch 27/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8847 - acc: 0.9362     \n",
      "Epoch 28/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8348 - acc: 0.9380     \n",
      "Epoch 29/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7948 - acc: 0.9375     \n",
      "Epoch 30/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.7554 - acc: 0.9383     \n",
      "# # # Evaluating cv-fold...\n",
      "384/485 [======================>.......] - ETA: 0s \n",
      "accuracy: 90.51546394210501\n",
      "precision: 91.06382978723404\n",
      "recall: 89.5397489539749\n",
      "f1_score: 90.29535864978904\n",
      "Training fold 10/10\n",
      "Epoch 1/30\n",
      "6192/6192 [==============================] - 4s - loss: 18.3236 - acc: 0.8266     \n",
      "Epoch 2/30\n",
      "6192/6192 [==============================] - 2s - loss: 12.8845 - acc: 0.8724     \n",
      "Epoch 3/30\n",
      "6192/6192 [==============================] - 2s - loss: 10.4111 - acc: 0.8826     \n",
      "Epoch 4/30\n",
      "6192/6192 [==============================] - 2s - loss: 8.9640 - acc: 0.8934     \n",
      "Epoch 5/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.9939 - acc: 0.9004     \n",
      "Epoch 6/30\n",
      "6192/6192 [==============================] - 2s - loss: 7.3095 - acc: 0.9079     \n",
      "Epoch 7/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.7888 - acc: 0.9107     - ETA: 1s \n",
      "Epoch 8/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.3760 - acc: 0.9113     \n",
      "Epoch 9/30\n",
      "6192/6192 [==============================] - 2s - loss: 6.0560 - acc: 0.9107     \n",
      "Epoch 10/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.7784 - acc: 0.9175     \n",
      "Epoch 11/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.5499 - acc: 0.9188     \n",
      "Epoch 12/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.3538 - acc: 0.9175     \n",
      "Epoch 13/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.1770 - acc: 0.9214     \n",
      "Epoch 14/30\n",
      "6192/6192 [==============================] - 2s - loss: 5.0243 - acc: 0.9251     \n",
      "Epoch 15/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.8969 - acc: 0.9273     \n",
      "Epoch 16/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.7731 - acc: 0.9270     \n",
      "Epoch 17/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.6684 - acc: 0.9302     \n",
      "Epoch 18/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.5711 - acc: 0.9307     \n",
      "Epoch 19/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.4829 - acc: 0.9309     \n",
      "Epoch 20/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.3955 - acc: 0.9351     \n",
      "Epoch 21/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.3251 - acc: 0.9351     \n",
      "Epoch 22/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.2500 - acc: 0.9341     \n",
      "Epoch 23/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.1913 - acc: 0.9320     \n",
      "Epoch 24/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.1262 - acc: 0.9406     \n",
      "Epoch 25/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0646 - acc: 0.9412     \n",
      "Epoch 26/30\n",
      "6192/6192 [==============================] - 2s - loss: 4.0148 - acc: 0.9427     \n",
      "Epoch 27/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9674 - acc: 0.9432     \n",
      "Epoch 28/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.9180 - acc: 0.9404     \n",
      "Epoch 29/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8745 - acc: 0.9438     \n",
      "Epoch 30/30\n",
      "6192/6192 [==============================] - 2s - loss: 3.8314 - acc: 0.9422     \n",
      "# # # Evaluating cv-fold...\n",
      "485/485 [==============================] - 1s      \n",
      "\n",
      "accuracy: 89.89690724107408\n",
      "precision: 92.41071428571429\n",
      "recall: 86.61087866108787\n",
      "f1_score: 89.41684665226782\n",
      "\n",
      "Final cross-validation score:\n",
      "90.35051548235194 +/- 0.8288557188838325\n",
      "91.44929101485496 +/- 1.4173346070524628\n",
      "88.74476987447699 +/- 1.233422842927505\n",
      "90.06469309507852 +/- 0.8262291919635204\n"
     ]
    }
   ],
   "source": [
    "# ON THE AUGMENTED DATASET WITH FLIPLR AND FLIPUD\n",
    "\n",
    "folds = 10\n",
    "cv_accuracies = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1_score = []\n",
    "\n",
    "for fold in range(folds):\n",
    "    print(\"Training fold \" + str(fold + 1) + \"/\" + str(folds))\n",
    "    \n",
    "    shuffle(train_tactile_images, train_labels_cat)\n",
    "    shuffle(test_tactile_images, test_labels_cat) \n",
    "    \n",
    "    # build model\n",
    "    epochs = 30\n",
    "    batch = 32\n",
    "    \n",
    "    learning_rate = 0.0001\n",
    "    epsilon = 1e-08\n",
    "    decay_rate = 0.005\n",
    "    \n",
    "    l2_reg = 0.015\n",
    "    drop_prob = 0.25\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(FINGERS, TACTILE_IMAGE_ROWS, TACTILE_IMAGE_COLS), \n",
    "                     data_format='channels_first',\n",
    "                     use_bias=False, kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1024, kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(drop_prob))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # compile and train\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.Adam(lr=learning_rate, epsilon=epsilon, decay=decay_rate), \n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(train_tactile_images, train_labels_cat, epochs=epochs, batch_size=batch, verbose=1)\n",
    "    \n",
    "    # evaluate\n",
    "    print(\"# # # Evaluating cv-fold...\")\n",
    "    scores = model.evaluate(test_tactile_images, test_labels_cat, verbose=1)\n",
    "    cv_accuracies.append(scores[1] * 100)\n",
    "    \n",
    "    predictions = model.predict(test_tactile_images)\n",
    "    [precision, recall, f1_score, _] = precision_recall_fscore_support(np.argmax(test_labels_cat, axis=1), \n",
    "                                                                          np.argmax(predictions, axis=1), \n",
    "                                                                          average='binary', pos_label=1)\n",
    "    \n",
    "    cv_precision.append(precision * 100)\n",
    "    cv_recall.append(recall * 100)\n",
    "    cv_f1_score.append(f1_score * 100)\n",
    "    \n",
    "    print(\"\\naccuracy:\", scores[1] * 100)\n",
    "    print(\"precision:\", precision * 100)\n",
    "    print(\"recall:\", recall * 100)\n",
    "    print(\"f1_score:\", f1_score * 100)\n",
    "    \n",
    "print(\"\\nFinal cross-validation score:\")\n",
    "print(np.mean(cv_accuracies), \"+/-\", np.std(cv_accuracies))\n",
    "print(np.mean(cv_precision), \"+/-\", np.std(cv_precision))\n",
    "print(np.mean(cv_recall), \"+/-\", np.std(cv_recall))\n",
    "print(np.mean(cv_f1_score), \"+/-\", np.std(cv_f1_score))\n",
    "\n",
    "# IROS\n",
    "#86.0355987113 +/- 0.383259524026\n",
    "#86.47674489 +/- 0.501892412426\n",
    "#83.8644067797 +/- 0.775967670662\n",
    "#85.1477152443 +/- 0.441251814143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/10\n",
      "Epoch 1/30\n",
      "8256/8256 [==============================] - 3s - loss: 17.0007 - acc: 0.8361     \n",
      "Epoch 2/30\n",
      "8256/8256 [==============================] - 2s - loss: 11.2165 - acc: 0.8752     \n",
      "Epoch 3/30\n",
      "8256/8256 [==============================] - 2s - loss: 8.9157 - acc: 0.8801     \n",
      "Epoch 4/30\n",
      "8256/8256 [==============================] - 2s - loss: 7.6333 - acc: 0.8947     \n",
      "Epoch 5/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.7989 - acc: 0.9046     \n",
      "Epoch 6/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.2182 - acc: 0.9067     \n",
      "Epoch 7/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.7823 - acc: 0.9124     \n",
      "Epoch 8/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.4416 - acc: 0.9146     \n",
      "Epoch 9/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.1664 - acc: 0.9169     \n",
      "Epoch 10/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.9412 - acc: 0.9213     \n",
      "Epoch 11/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.7516 - acc: 0.9222     \n",
      "Epoch 12/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.5895 - acc: 0.9224     \n",
      "Epoch 13/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.4431 - acc: 0.9277     \n",
      "Epoch 14/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.3215 - acc: 0.9261     \n",
      "Epoch 15/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.2113 - acc: 0.9297     \n",
      "Epoch 16/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.1149 - acc: 0.9248     \n",
      "Epoch 17/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.0300 - acc: 0.9301     \n",
      "Epoch 18/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.9361 - acc: 0.9392     \n",
      "Epoch 19/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.8684 - acc: 0.9354     \n",
      "Epoch 20/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7983 - acc: 0.9369     \n",
      "Epoch 21/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7409 - acc: 0.9335     \n",
      "Epoch 22/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6760 - acc: 0.9398     \n",
      "Epoch 23/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6240 - acc: 0.9387     \n",
      "Epoch 24/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5740 - acc: 0.9380     \n",
      "Epoch 25/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5291 - acc: 0.9379     \n",
      "Epoch 26/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4845 - acc: 0.9363     \n",
      "Epoch 27/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4373 - acc: 0.9436     \n",
      "Epoch 28/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4012 - acc: 0.9391     \n",
      "Epoch 29/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.3646 - acc: 0.9442     \n",
      "Epoch 30/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.3257 - acc: 0.9443     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 3s\n",
      "accuracy: 90.72164949682569\n",
      "precision: 92.92035398230088\n",
      "recall: 87.86610878661088\n",
      "f1_score: 90.3225806451613\n",
      "Training fold 2/10\n",
      "Epoch 1/30\n",
      "8256/8256 [==============================] - 3s - loss: 17.2023 - acc: 0.8309     \n",
      "Epoch 2/30\n",
      "8256/8256 [==============================] - 2s - loss: 11.4731 - acc: 0.8740     \n",
      "Epoch 3/30\n",
      "8256/8256 [==============================] - 2s - loss: 9.1480 - acc: 0.8895     \n",
      "Epoch 4/30\n",
      "8256/8256 [==============================] - 2s - loss: 7.8533 - acc: 0.8947     \n",
      "Epoch 5/30\n",
      "8256/8256 [==============================] - 2s - loss: 7.0134 - acc: 0.9015     \n",
      "Epoch 6/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.4164 - acc: 0.9109     \n",
      "Epoch 7/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.9793 - acc: 0.9093     \n",
      "Epoch 8/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.6294 - acc: 0.9130     \n",
      "Epoch 9/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.3424 - acc: 0.9178     \n",
      "Epoch 10/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.1136 - acc: 0.9204     \n",
      "Epoch 11/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.9190 - acc: 0.9220     \n",
      "Epoch 12/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.7509 - acc: 0.9220     \n",
      "Epoch 13/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.5976 - acc: 0.9296     \n",
      "Epoch 14/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.4723 - acc: 0.9290     \n",
      "Epoch 15/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.3626 - acc: 0.9271     \n",
      "Epoch 16/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.2590 - acc: 0.9316     \n",
      "Epoch 17/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.1669 - acc: 0.9305     \n",
      "Epoch 18/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.0799 - acc: 0.9380     \n",
      "Epoch 19/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.0060 - acc: 0.9356     \n",
      "Epoch 20/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.9359 - acc: 0.9345     \n",
      "Epoch 21/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.8670 - acc: 0.9376     \n",
      "Epoch 22/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.8086 - acc: 0.9362     \n",
      "Epoch 23/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7538 - acc: 0.9369     \n",
      "Epoch 24/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7001 - acc: 0.9399     \n",
      "Epoch 25/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6570 - acc: 0.9360     \n",
      "Epoch 26/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6015 - acc: 0.9405     \n",
      "Epoch 27/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5620 - acc: 0.9385     \n",
      "Epoch 28/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5184 - acc: 0.9414     \n",
      "Epoch 29/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4795 - acc: 0.9459     \n",
      "Epoch 30/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4416 - acc: 0.9439     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 4s\n",
      "accuracy: 90.72164949682569\n",
      "precision: 90.75630252100841\n",
      "recall: 90.3765690376569\n",
      "f1_score: 90.56603773584906\n",
      "Training fold 3/10\n",
      "Epoch 1/30\n",
      "8256/8256 [==============================] - 3s - loss: 16.8625 - acc: 0.8343     \n",
      "Epoch 2/30\n",
      "8256/8256 [==============================] - 2s - loss: 10.9922 - acc: 0.8743     \n",
      "Epoch 3/30\n",
      "8256/8256 [==============================] - 2s - loss: 8.6871 - acc: 0.8932     \n",
      "Epoch 4/30\n",
      "8256/8256 [==============================] - 2s - loss: 7.4235 - acc: 0.8970     \n",
      "Epoch 5/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.6202 - acc: 0.9025     \n",
      "Epoch 6/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.0587 - acc: 0.9089     \n",
      "Epoch 7/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.6349 - acc: 0.9147     \n",
      "Epoch 8/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.3214 - acc: 0.9134     \n",
      "Epoch 9/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.0551 - acc: 0.9176     \n",
      "Epoch 10/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.8353 - acc: 0.9222     \n",
      "Epoch 11/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.6560 - acc: 0.9251     \n",
      "Epoch 12/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.4997 - acc: 0.9234     \n",
      "Epoch 13/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.3743 - acc: 0.9209     \n",
      "Epoch 14/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.2482 - acc: 0.9274     \n",
      "Epoch 15/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.1463 - acc: 0.9282     \n",
      "Epoch 16/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.0482 - acc: 0.9328     \n",
      "Epoch 17/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.9653 - acc: 0.9305     \n",
      "Epoch 18/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.8918 - acc: 0.9350     \n",
      "Epoch 19/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.8132 - acc: 0.9393     \n",
      "Epoch 20/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7593 - acc: 0.9340     \n",
      "Epoch 21/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6936 - acc: 0.9392     \n",
      "Epoch 22/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6370 - acc: 0.9394     \n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8256/8256 [==============================] - 2s - loss: 3.5868 - acc: 0.9396     \n",
      "Epoch 24/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5394 - acc: 0.9399     \n",
      "Epoch 25/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4908 - acc: 0.9427     - ETA: 1s -\n",
      "Epoch 26/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4527 - acc: 0.9404     \n",
      "Epoch 27/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4086 - acc: 0.9425     \n",
      "Epoch 28/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.3689 - acc: 0.9432     \n",
      "Epoch 29/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.3324 - acc: 0.9436     \n",
      "Epoch 30/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.3036 - acc: 0.9415     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 4s\n",
      "accuracy: 89.48453610705346\n",
      "precision: 91.96428571428571\n",
      "recall: 86.19246861924687\n",
      "f1_score: 88.98488120950323\n",
      "Training fold 4/10\n",
      "Epoch 1/30\n",
      "8256/8256 [==============================] - 3s - loss: 17.0946 - acc: 0.8298     \n",
      "Epoch 2/30\n",
      "8256/8256 [==============================] - 2s - loss: 11.3370 - acc: 0.8712     \n",
      "Epoch 3/30\n",
      "8256/8256 [==============================] - 2s - loss: 9.0244 - acc: 0.8860     \n",
      "Epoch 4/30\n",
      "8256/8256 [==============================] - 2s - loss: 7.7369 - acc: 0.8980     \n",
      "Epoch 5/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.9036 - acc: 0.9039     \n",
      "Epoch 6/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.3204 - acc: 0.9065     \n",
      "Epoch 7/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.8808 - acc: 0.9110     \n",
      "Epoch 8/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.5466 - acc: 0.9132     \n",
      "Epoch 9/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.2686 - acc: 0.9168     \n",
      "Epoch 10/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.0449 - acc: 0.9159     \n",
      "Epoch 11/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.8499 - acc: 0.9210     \n",
      "Epoch 12/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.6862 - acc: 0.9254     \n",
      "Epoch 13/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.5437 - acc: 0.9238     \n",
      "Epoch 14/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.4153 - acc: 0.9306     \n",
      "Epoch 15/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.3121 - acc: 0.9250     \n",
      "Epoch 16/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.2101 - acc: 0.9323     \n",
      "Epoch 17/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.1170 - acc: 0.9304     \n",
      "Epoch 18/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.0324 - acc: 0.9331     \n",
      "Epoch 19/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.9625 - acc: 0.9329     \n",
      "Epoch 20/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.8895 - acc: 0.9356     \n",
      "Epoch 21/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.8266 - acc: 0.9373     \n",
      "Epoch 22/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7654 - acc: 0.9393     \n",
      "Epoch 23/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7116 - acc: 0.9362     \n",
      "Epoch 24/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6636 - acc: 0.9388     \n",
      "Epoch 25/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6113 - acc: 0.9415     \n",
      "Epoch 26/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5668 - acc: 0.9419     \n",
      "Epoch 27/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5250 - acc: 0.9422     \n",
      "Epoch 28/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4818 - acc: 0.9411     \n",
      "Epoch 29/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4493 - acc: 0.9420     \n",
      "Epoch 30/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4073 - acc: 0.9404     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 4s\n",
      "accuracy: 90.92783507612563\n",
      "precision: 91.13924050632912\n",
      "recall: 90.3765690376569\n",
      "f1_score: 90.7563025210084\n",
      "Training fold 5/10\n",
      "Epoch 1/30\n",
      "8256/8256 [==============================] - 3s - loss: 17.0132 - acc: 0.8353     \n",
      "Epoch 2/30\n",
      "8256/8256 [==============================] - 2s - loss: 11.2855 - acc: 0.8752     \n",
      "Epoch 3/30\n",
      "8256/8256 [==============================] - 2s - loss: 8.9934 - acc: 0.8875     \n",
      "Epoch 4/30\n",
      "8256/8256 [==============================] - 2s - loss: 7.7227 - acc: 0.8987     \n",
      "Epoch 5/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.9048 - acc: 0.9041     \n",
      "Epoch 6/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.3311 - acc: 0.9086     \n",
      "Epoch 7/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.9027 - acc: 0.9062     \n",
      "Epoch 8/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.5672 - acc: 0.9112     \n",
      "Epoch 9/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.2938 - acc: 0.9188     \n",
      "Epoch 10/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.0677 - acc: 0.9218     \n",
      "Epoch 11/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.8850 - acc: 0.9193     \n",
      "Epoch 12/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.7153 - acc: 0.9237     \n",
      "Epoch 13/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.5757 - acc: 0.9256     \n",
      "Epoch 14/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.4589 - acc: 0.9234     \n",
      "Epoch 15/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.3376 - acc: 0.9314     \n",
      "Epoch 16/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.2438 - acc: 0.9283     \n",
      "Epoch 17/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.1533 - acc: 0.9317     \n",
      "Epoch 18/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.0743 - acc: 0.9310     \n",
      "Epoch 19/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.9980 - acc: 0.9357     \n",
      "Epoch 20/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.9285 - acc: 0.9373     \n",
      "Epoch 21/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.8672 - acc: 0.9353     \n",
      "Epoch 22/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.8073 - acc: 0.9358     \n",
      "Epoch 23/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7503 - acc: 0.9388     \n",
      "Epoch 24/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7016 - acc: 0.9402     \n",
      "Epoch 25/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6544 - acc: 0.9398     \n",
      "Epoch 26/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6111 - acc: 0.9367     \n",
      "Epoch 27/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5681 - acc: 0.9439     \n",
      "Epoch 28/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5267 - acc: 0.9409     \n",
      "Epoch 29/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4864 - acc: 0.9448     \n",
      "Epoch 30/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4515 - acc: 0.9440     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 5s\n",
      "accuracy: 90.927835063836\n",
      "precision: 91.84549356223177\n",
      "recall: 89.5397489539749\n",
      "f1_score: 90.6779661016949\n",
      "Training fold 6/10\n",
      "Epoch 1/30\n",
      "8256/8256 [==============================] - 3s - loss: 17.0383 - acc: 0.8343     \n",
      "Epoch 2/30\n",
      "8256/8256 [==============================] - 2s - loss: 11.2221 - acc: 0.8763     \n",
      "Epoch 3/30\n",
      "8256/8256 [==============================] - 2s - loss: 8.9059 - acc: 0.8869     \n",
      "Epoch 4/30\n",
      "8256/8256 [==============================] - 2s - loss: 7.6170 - acc: 0.9014     \n",
      "Epoch 5/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.7986 - acc: 0.9066     \n",
      "Epoch 6/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.2265 - acc: 0.9060     \n",
      "Epoch 7/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.7980 - acc: 0.9089     \n",
      "Epoch 8/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.4644 - acc: 0.9148     \n",
      "Epoch 9/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.1876 - acc: 0.9179     \n",
      "Epoch 10/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.9710 - acc: 0.9214     \n",
      "Epoch 11/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.7864 - acc: 0.9228     \n",
      "Epoch 12/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.6251 - acc: 0.9237     \n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8256/8256 [==============================] - 2s - loss: 4.4808 - acc: 0.9300     \n",
      "Epoch 14/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.3686 - acc: 0.9233     \n",
      "Epoch 15/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.2584 - acc: 0.9268     \n",
      "Epoch 16/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.1568 - acc: 0.9273     \n",
      "Epoch 17/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.0664 - acc: 0.9333     \n",
      "Epoch 18/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.9935 - acc: 0.9314     \n",
      "Epoch 19/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.9154 - acc: 0.9330     \n",
      "Epoch 20/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.8498 - acc: 0.9310     \n",
      "Epoch 21/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7893 - acc: 0.9346     \n",
      "Epoch 22/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7297 - acc: 0.9380     \n",
      "Epoch 23/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6734 - acc: 0.9403     \n",
      "Epoch 24/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6274 - acc: 0.9363     \n",
      "Epoch 25/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5744 - acc: 0.9436     \n",
      "Epoch 26/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5323 - acc: 0.9408     \n",
      "Epoch 27/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4903 - acc: 0.9432     \n",
      "Epoch 28/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4513 - acc: 0.9431     \n",
      "Epoch 29/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4146 - acc: 0.9420     \n",
      "Epoch 30/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.3806 - acc: 0.9410     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 5s\n",
      "accuracy: 89.48453610705346\n",
      "precision: 89.83050847457628\n",
      "recall: 88.70292887029288\n",
      "f1_score: 89.26315789473684\n",
      "Training fold 7/10\n",
      "Epoch 1/30\n",
      "8256/8256 [==============================] - 3s - loss: 16.9746 - acc: 0.8352     \n",
      "Epoch 2/30\n",
      "8256/8256 [==============================] - 2s - loss: 11.1879 - acc: 0.8729     \n",
      "Epoch 3/30\n",
      "8256/8256 [==============================] - 2s - loss: 8.8600 - acc: 0.8869     \n",
      "Epoch 4/30\n",
      "8256/8256 [==============================] - 2s - loss: 7.5779 - acc: 0.8974     \n",
      "Epoch 5/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.7503 - acc: 0.9002     \n",
      "Epoch 6/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.1735 - acc: 0.9027     \n",
      "Epoch 7/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.7385 - acc: 0.9099     \n",
      "Epoch 8/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.4010 - acc: 0.9093     \n",
      "Epoch 9/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.1226 - acc: 0.9152     \n",
      "Epoch 10/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.9078 - acc: 0.9169     \n",
      "Epoch 11/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.7145 - acc: 0.9231     \n",
      "Epoch 12/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.5561 - acc: 0.9227     \n",
      "Epoch 13/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.4192 - acc: 0.9226     \n",
      "Epoch 14/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.2929 - acc: 0.9289     \n",
      "Epoch 15/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.1821 - acc: 0.9282     \n",
      "Epoch 16/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.0876 - acc: 0.9282     \n",
      "Epoch 17/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.9991 - acc: 0.9295     \n",
      "Epoch 18/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.9198 - acc: 0.9283     \n",
      "Epoch 19/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.8422 - acc: 0.9334     \n",
      "Epoch 20/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7764 - acc: 0.9352     \n",
      "Epoch 21/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7100 - acc: 0.9365     - \n",
      "Epoch 22/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6534 - acc: 0.9413     \n",
      "Epoch 23/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6014 - acc: 0.9353     \n",
      "Epoch 24/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5497 - acc: 0.9376     \n",
      "Epoch 25/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5076 - acc: 0.9405     \n",
      "Epoch 26/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4625 - acc: 0.9385     \n",
      "Epoch 27/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4142 - acc: 0.9414     \n",
      "Epoch 28/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.3774 - acc: 0.9406     \n",
      "Epoch 29/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.3413 - acc: 0.9416     \n",
      "Epoch 30/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.3045 - acc: 0.9420     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 5s\n",
      "accuracy: 90.51546392981538\n",
      "precision: 92.51101321585902\n",
      "recall: 87.86610878661088\n",
      "f1_score: 90.12875536480685\n",
      "Training fold 8/10\n",
      "Epoch 1/30\n",
      "8256/8256 [==============================] - 3s - loss: 17.2287 - acc: 0.8378     \n",
      "Epoch 2/30\n",
      "8256/8256 [==============================] - 2s - loss: 11.5095 - acc: 0.8789     \n",
      "Epoch 3/30\n",
      "8256/8256 [==============================] - 2s - loss: 9.1921 - acc: 0.8891     \n",
      "Epoch 4/30\n",
      "8256/8256 [==============================] - 2s - loss: 7.8937 - acc: 0.9007     \n",
      "Epoch 5/30\n",
      "8256/8256 [==============================] - 2s - loss: 7.0502 - acc: 0.9067     \n",
      "Epoch 6/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.4520 - acc: 0.9089     \n",
      "Epoch 7/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.0059 - acc: 0.9138     \n",
      "Epoch 8/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.6639 - acc: 0.9115     \n",
      "Epoch 9/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.3811 - acc: 0.9172     \n",
      "Epoch 10/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.1481 - acc: 0.9208     \n",
      "Epoch 11/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.9540 - acc: 0.9233     \n",
      "Epoch 12/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.7831 - acc: 0.9250     \n",
      "Epoch 13/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.6392 - acc: 0.9284     \n",
      "Epoch 14/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.5081 - acc: 0.9281     \n",
      "Epoch 15/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.3887 - acc: 0.9340     \n",
      "Epoch 16/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.2853 - acc: 0.9365     \n",
      "Epoch 17/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.1948 - acc: 0.9327     \n",
      "Epoch 18/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.1064 - acc: 0.9347     \n",
      "Epoch 19/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.0321 - acc: 0.9362     \n",
      "Epoch 20/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.9654 - acc: 0.9354     \n",
      "Epoch 21/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.8941 - acc: 0.9400     \n",
      "Epoch 22/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.8357 - acc: 0.9386     \n",
      "Epoch 23/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7740 - acc: 0.9413     \n",
      "Epoch 24/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7262 - acc: 0.9422     \n",
      "Epoch 25/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6730 - acc: 0.9436     \n",
      "Epoch 26/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6279 - acc: 0.9419     \n",
      "Epoch 27/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5847 - acc: 0.9444     \n",
      "Epoch 28/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5421 - acc: 0.9434     \n",
      "Epoch 29/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5029 - acc: 0.9419     \n",
      "Epoch 30/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4593 - acc: 0.9503     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 5s\n",
      "accuracy: 90.30927836280507\n",
      "precision: 91.37931034482759\n",
      "recall: 88.70292887029288\n",
      "f1_score: 90.02123142250531\n",
      "Training fold 9/10\n",
      "Epoch 1/30\n",
      "8256/8256 [==============================] - 3s - loss: 16.9537 - acc: 0.8352     \n",
      "Epoch 2/30\n",
      "8256/8256 [==============================] - 2s - loss: 11.1615 - acc: 0.8765     \n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8256/8256 [==============================] - 2s - loss: 8.8477 - acc: 0.8909     \n",
      "Epoch 4/30\n",
      "8256/8256 [==============================] - 2s - loss: 7.5762 - acc: 0.8958     \n",
      "Epoch 5/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.7530 - acc: 0.9052     \n",
      "Epoch 6/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.1746 - acc: 0.9099     \n",
      "Epoch 7/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.7364 - acc: 0.9159     \n",
      "Epoch 8/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.4054 - acc: 0.9159     \n",
      "Epoch 9/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.1292 - acc: 0.9207     \n",
      "Epoch 10/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.9022 - acc: 0.9259     \n",
      "Epoch 11/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.7168 - acc: 0.9234     \n",
      "Epoch 12/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.5594 - acc: 0.9270     \n",
      "Epoch 13/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.4167 - acc: 0.9250     \n",
      "Epoch 14/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.2961 - acc: 0.9254     \n",
      "Epoch 15/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.1835 - acc: 0.9295     \n",
      "Epoch 16/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.0897 - acc: 0.9267     \n",
      "Epoch 17/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.9967 - acc: 0.9323     \n",
      "Epoch 18/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.9166 - acc: 0.9344     \n",
      "Epoch 19/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.8396 - acc: 0.9377     \n",
      "Epoch 20/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7755 - acc: 0.9354     \n",
      "Epoch 21/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7182 - acc: 0.9365     \n",
      "Epoch 22/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6605 - acc: 0.9359     \n",
      "Epoch 23/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5994 - acc: 0.9398     \n",
      "Epoch 24/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5534 - acc: 0.9370     \n",
      "Epoch 25/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5018 - acc: 0.9414     \n",
      "Epoch 26/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4615 - acc: 0.9414     \n",
      "Epoch 27/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4154 - acc: 0.9438     \n",
      "Epoch 28/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.3806 - acc: 0.9422     \n",
      "Epoch 29/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.3416 - acc: 0.9455     \n",
      "Epoch 30/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.3077 - acc: 0.9443     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 6s\n",
      "accuracy: 90.72164950911532\n",
      "precision: 90.41666666666667\n",
      "recall: 90.7949790794979\n",
      "f1_score: 90.6054279749478\n",
      "Training fold 10/10\n",
      "Epoch 1/30\n",
      "8256/8256 [==============================] - 3s - loss: 17.0702 - acc: 0.8287     \n",
      "Epoch 2/30\n",
      "8256/8256 [==============================] - 2s - loss: 11.2193 - acc: 0.8738     \n",
      "Epoch 3/30\n",
      "8256/8256 [==============================] - 2s - loss: 8.8745 - acc: 0.8849     \n",
      "Epoch 4/30\n",
      "8256/8256 [==============================] - 2s - loss: 7.5793 - acc: 0.8947     \n",
      "Epoch 5/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.7448 - acc: 0.9008     \n",
      "Epoch 6/30\n",
      "8256/8256 [==============================] - 2s - loss: 6.1694 - acc: 0.9052     \n",
      "Epoch 7/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.7309 - acc: 0.9104     \n",
      "Epoch 8/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.3914 - acc: 0.9142     \n",
      "Epoch 9/30\n",
      "8256/8256 [==============================] - 2s - loss: 5.1201 - acc: 0.9153     \n",
      "Epoch 10/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.8969 - acc: 0.9182     \n",
      "Epoch 11/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.7076 - acc: 0.9186     \n",
      "Epoch 12/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.5425 - acc: 0.9260     \n",
      "Epoch 13/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.4080 - acc: 0.9261     \n",
      "Epoch 14/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.2799 - acc: 0.9278     \n",
      "Epoch 15/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.1725 - acc: 0.9294     \n",
      "Epoch 16/30\n",
      "8256/8256 [==============================] - 2s - loss: 4.0764 - acc: 0.9226     \n",
      "Epoch 17/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.9869 - acc: 0.9302     \n",
      "Epoch 18/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.9018 - acc: 0.9320     \n",
      "Epoch 19/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.8319 - acc: 0.9334     \n",
      "Epoch 20/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7639 - acc: 0.9365     \n",
      "Epoch 21/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.7020 - acc: 0.9364     \n",
      "Epoch 22/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.6423 - acc: 0.9387     \n",
      "Epoch 23/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5913 - acc: 0.9370     \n",
      "Epoch 24/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.5402 - acc: 0.9363     \n",
      "Epoch 25/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4973 - acc: 0.9369     \n",
      "Epoch 26/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4462 - acc: 0.9442     \n",
      "Epoch 27/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.4071 - acc: 0.9383     \n",
      "Epoch 28/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.3716 - acc: 0.9390     \n",
      "Epoch 29/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.3308 - acc: 0.9414     \n",
      "Epoch 30/30\n",
      "8256/8256 [==============================] - 2s - loss: 3.2962 - acc: 0.9454     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 6s\n",
      "accuracy: 89.89690724107408\n",
      "precision: 89.91596638655463\n",
      "recall: 89.5397489539749\n",
      "f1_score: 89.72746331236897\n",
      "\n",
      "Final cross-validation score:\n",
      "90.37113403905298 +/- 0.5301014456427222\n",
      "91.26791413746399 +/- 1.0001808139690287\n",
      "88.99581589958159 +/- 1.349980402083822\n",
      "90.10538041825826 +/- 0.5810584004191574\n"
     ]
    }
   ],
   "source": [
    "# ON THE AUGMENTED DATASET WITH FLIPLR, FLIPUD AND ROTATE10\n",
    "\n",
    "folds = 10\n",
    "cv_accuracies = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1_score = []\n",
    "\n",
    "for fold in range(folds):\n",
    "    print(\"Training fold \" + str(fold + 1) + \"/\" + str(folds))\n",
    "    \n",
    "    shuffle(train_tactile_images, train_labels_cat)\n",
    "    shuffle(test_tactile_images, test_labels_cat) \n",
    "    \n",
    "    # build model\n",
    "    epochs = 30\n",
    "    batch = 32\n",
    "    \n",
    "    learning_rate = 0.0001\n",
    "    epsilon = 1e-08\n",
    "    decay_rate = 0.005\n",
    "    \n",
    "    l2_reg = 0.015\n",
    "    drop_prob = 0.25\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(FINGERS, TACTILE_IMAGE_ROWS, TACTILE_IMAGE_COLS), \n",
    "                     data_format='channels_first',\n",
    "                     use_bias=False, kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1024, kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(drop_prob))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # compile and train\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.Adam(lr=learning_rate, epsilon=epsilon, decay=decay_rate), \n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(train_tactile_images, train_labels_cat, epochs=epochs, batch_size=batch, verbose=1)\n",
    "    \n",
    "    # evaluate\n",
    "    print(\"# # # Evaluating cv-fold...\")\n",
    "    scores = model.evaluate(test_tactile_images, test_labels_cat, verbose=1)\n",
    "    cv_accuracies.append(scores[1] * 100)\n",
    "    \n",
    "    predictions = model.predict(test_tactile_images)\n",
    "    [precision, recall, f1_score, _] = precision_recall_fscore_support(np.argmax(test_labels_cat, axis=1), \n",
    "                                                                          np.argmax(predictions, axis=1), \n",
    "                                                                          average='binary', pos_label=1)\n",
    "    \n",
    "    cv_precision.append(precision * 100)\n",
    "    cv_recall.append(recall * 100)\n",
    "    cv_f1_score.append(f1_score * 100)\n",
    "    \n",
    "    print(\"\\naccuracy:\", scores[1] * 100)\n",
    "    print(\"precision:\", precision * 100)\n",
    "    print(\"recall:\", recall * 100)\n",
    "    print(\"f1_score:\", f1_score * 100)\n",
    "    \n",
    "print(\"\\nFinal cross-validation score:\")\n",
    "print(np.mean(cv_accuracies), \"+/-\", np.std(cv_accuracies))\n",
    "print(np.mean(cv_precision), \"+/-\", np.std(cv_precision))\n",
    "print(np.mean(cv_recall), \"+/-\", np.std(cv_recall))\n",
    "print(np.mean(cv_f1_score), \"+/-\", np.std(cv_f1_score))\n",
    "\n",
    "# IROS\n",
    "#86.0355987113 +/- 0.383259524026\n",
    "#86.47674489 +/- 0.501892412426\n",
    "#83.8644067797 +/- 0.775967670662\n",
    "#85.1477152443 +/- 0.441251814143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/10\n",
      "Epoch 1/30\n",
      "10320/10320 [==============================] - 4s - loss: 16.1067 - acc: 0.8386     \n",
      "Epoch 2/30\n",
      "10320/10320 [==============================] - 3s - loss: 10.1600 - acc: 0.8805     \n",
      "Epoch 3/30\n",
      "10320/10320 [==============================] - 3s - loss: 8.0138 - acc: 0.8849     \n",
      "Epoch 4/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.8633 - acc: 0.8969     \n",
      "Epoch 5/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.1396 - acc: 0.9042     \n",
      "Epoch 6/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.6323 - acc: 0.9063     \n",
      "Epoch 7/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.2568 - acc: 0.9121     \n",
      "Epoch 8/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.9643 - acc: 0.9178     \n",
      "Epoch 9/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.7343 - acc: 0.9151     \n",
      "Epoch 10/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.5369 - acc: 0.9170     \n",
      "Epoch 11/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.3751 - acc: 0.9239     \n",
      "Epoch 12/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.2374 - acc: 0.9242     \n",
      "Epoch 13/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.1133 - acc: 0.9276     \n",
      "Epoch 14/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.0069 - acc: 0.9283     \n",
      "Epoch 15/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.9136 - acc: 0.9292     \n",
      "Epoch 16/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.8261 - acc: 0.9274     \n",
      "Epoch 17/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.7526 - acc: 0.9300     \n",
      "Epoch 18/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6842 - acc: 0.9289     \n",
      "Epoch 19/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6191 - acc: 0.9330     \n",
      "Epoch 20/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5638 - acc: 0.9313     \n",
      "Epoch 21/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5004 - acc: 0.9398     \n",
      "Epoch 22/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4507 - acc: 0.9360     \n",
      "Epoch 23/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4086 - acc: 0.9355     \n",
      "Epoch 24/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3600 - acc: 0.9382     \n",
      "Epoch 25/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3161 - acc: 0.9397     \n",
      "Epoch 26/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2787 - acc: 0.9433     \n",
      "Epoch 27/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2421 - acc: 0.9432     \n",
      "Epoch 28/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2111 - acc: 0.9415     \n",
      "Epoch 29/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.1741 - acc: 0.9425     \n",
      "Epoch 30/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.1452 - acc: 0.9409     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 6s\n",
      "accuracy: 90.30927836280507\n",
      "precision: 90.67796610169492\n",
      "recall: 89.5397489539749\n",
      "f1_score: 90.10526315789474\n",
      "Training fold 2/10\n",
      "Epoch 1/30\n",
      "10320/10320 [==============================] - 4s - loss: 16.3718 - acc: 0.8366     \n",
      "Epoch 2/30\n",
      "10320/10320 [==============================] - 3s - loss: 10.5657 - acc: 0.8792     \n",
      "Epoch 3/30\n",
      "10320/10320 [==============================] - 3s - loss: 8.4139 - acc: 0.8858     \n",
      "Epoch 4/30\n",
      "10320/10320 [==============================] - 3s - loss: 7.2437 - acc: 0.8969     \n",
      "Epoch 5/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.4963 - acc: 0.9014     \n",
      "Epoch 6/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.9710 - acc: 0.9071     \n",
      "Epoch 7/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.5782 - acc: 0.9113     \n",
      "Epoch 8/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.2744 - acc: 0.9135     \n",
      "Epoch 9/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.0254 - acc: 0.9176     \n",
      "Epoch 10/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.8180 - acc: 0.9204     \n",
      "Epoch 11/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.6500 - acc: 0.9227     \n",
      "Epoch 12/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.4978 - acc: 0.9234     \n",
      "Epoch 13/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.3749 - acc: 0.9210     \n",
      "Epoch 14/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.2548 - acc: 0.9273     \n",
      "Epoch 15/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.1503 - acc: 0.9305     \n",
      "Epoch 16/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.0598 - acc: 0.9282     \n",
      "Epoch 17/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.9759 - acc: 0.9323     \n",
      "Epoch 18/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.9016 - acc: 0.9332     \n",
      "Epoch 19/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.8350 - acc: 0.9297     \n",
      "Epoch 20/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.7667 - acc: 0.9346     \n",
      "Epoch 21/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.7103 - acc: 0.9346     \n",
      "Epoch 22/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6544 - acc: 0.9359     \n",
      "Epoch 23/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6025 - acc: 0.9372     \n",
      "Epoch 24/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5540 - acc: 0.9362     \n",
      "Epoch 25/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5118 - acc: 0.9394     \n",
      "Epoch 26/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4704 - acc: 0.9381     \n",
      "Epoch 27/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4263 - acc: 0.9410     \n",
      "Epoch 28/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3887 - acc: 0.9386     \n",
      "Epoch 29/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3518 - acc: 0.9415     \n",
      "Epoch 30/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3212 - acc: 0.9410     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 6s\n",
      "accuracy: 90.927835063836\n",
      "precision: 94.11764705882352\n",
      "recall: 87.02928870292888\n",
      "f1_score: 90.43478260869566\n",
      "Training fold 3/10\n",
      "Epoch 1/30\n",
      "10320/10320 [==============================] - 4s - loss: 16.0795 - acc: 0.8393     \n",
      "Epoch 2/30\n",
      "10320/10320 [==============================] - 3s - loss: 10.2284 - acc: 0.8799     \n",
      "Epoch 3/30\n",
      "10320/10320 [==============================] - 3s - loss: 8.1231 - acc: 0.8823     \n",
      "Epoch 4/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.9840 - acc: 0.8987     \n",
      "Epoch 5/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.2730 - acc: 0.8991     \n",
      "Epoch 6/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.7735 - acc: 0.9047     \n",
      "Epoch 7/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.4055 - acc: 0.9062     \n",
      "Epoch 8/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.1138 - acc: 0.9132     \n",
      "Epoch 9/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.8767 - acc: 0.9160     \n",
      "Epoch 10/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.6840 - acc: 0.9178     \n",
      "Epoch 11/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.5216 - acc: 0.9218     \n",
      "Epoch 12/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.3801 - acc: 0.9230     \n",
      "Epoch 13/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.2560 - acc: 0.9233     \n",
      "Epoch 14/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.1515 - acc: 0.9241     \n",
      "Epoch 15/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.0521 - acc: 0.9266     \n",
      "Epoch 16/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.9722 - acc: 0.9247     \n",
      "Epoch 17/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.8899 - acc: 0.9273     \n",
      "Epoch 18/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.8188 - acc: 0.9329     \n",
      "Epoch 19/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.7534 - acc: 0.9317     \n",
      "Epoch 20/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6932 - acc: 0.9311     \n",
      "Epoch 21/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6343 - acc: 0.9341     \n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10320/10320 [==============================] - 3s - loss: 3.5822 - acc: 0.9350     \n",
      "Epoch 23/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5379 - acc: 0.9367     \n",
      "Epoch 24/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4909 - acc: 0.9369     \n",
      "Epoch 25/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4498 - acc: 0.9349     \n",
      "Epoch 26/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4114 - acc: 0.9349     \n",
      "Epoch 27/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3713 - acc: 0.9394     \n",
      "Epoch 28/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3381 - acc: 0.9377     \n",
      "Epoch 29/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3042 - acc: 0.9390     \n",
      "Epoch 30/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2756 - acc: 0.9364     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 7s\n",
      "accuracy: 90.72164949682569\n",
      "precision: 91.8103448275862\n",
      "recall: 89.1213389121339\n",
      "f1_score: 90.44585987261146\n",
      "Training fold 4/10\n",
      "Epoch 1/30\n",
      "10320/10320 [==============================] - 4s - loss: 16.3306 - acc: 0.8302     \n",
      "Epoch 2/30\n",
      "10320/10320 [==============================] - 3s - loss: 10.4788 - acc: 0.8757     \n",
      "Epoch 3/30\n",
      "10320/10320 [==============================] - 3s - loss: 8.3209 - acc: 0.8858     \n",
      "Epoch 4/30\n",
      "10320/10320 [==============================] - 3s - loss: 7.1614 - acc: 0.8906     \n",
      "Epoch 5/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.4271 - acc: 0.8990     \n",
      "Epoch 6/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.9124 - acc: 0.9011     \n",
      "Epoch 7/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.5334 - acc: 0.9053     \n",
      "Epoch 8/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.2311 - acc: 0.9112     \n",
      "Epoch 9/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.9851 - acc: 0.9198     \n",
      "Epoch 10/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.7907 - acc: 0.9156     \n",
      "Epoch 11/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.6225 - acc: 0.9199     \n",
      "Epoch 12/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.4777 - acc: 0.9214     \n",
      "Epoch 13/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.3483 - acc: 0.9227     \n",
      "Epoch 14/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.2405 - acc: 0.9234     \n",
      "Epoch 15/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.1392 - acc: 0.9236     \n",
      "Epoch 16/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.0458 - acc: 0.9288     \n",
      "Epoch 17/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.9713 - acc: 0.9284     \n",
      "Epoch 18/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.8990 - acc: 0.9283     \n",
      "Epoch 19/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.8365 - acc: 0.9278     \n",
      "Epoch 20/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.7660 - acc: 0.9328     \n",
      "Epoch 21/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.7051 - acc: 0.9350     \n",
      "Epoch 22/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6578 - acc: 0.9344     \n",
      "Epoch 23/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6069 - acc: 0.9350     \n",
      "Epoch 24/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5607 - acc: 0.9312     \n",
      "Epoch 25/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5179 - acc: 0.9340     \n",
      "Epoch 26/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4754 - acc: 0.9363     \n",
      "Epoch 27/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4366 - acc: 0.9401     \n",
      "Epoch 28/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4014 - acc: 0.9373     \n",
      "Epoch 29/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3738 - acc: 0.9360     \n",
      "Epoch 30/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3358 - acc: 0.9396     \n",
      "# # # Evaluating cv-fold...\n",
      "320/485 [==================>...........] - ETA: 0s\n",
      "accuracy: 90.10309279579477\n",
      "precision: 91.34199134199135\n",
      "recall: 88.28451882845188\n",
      "f1_score: 89.7872340425532\n",
      "Training fold 5/10\n",
      "Epoch 1/30\n",
      "10320/10320 [==============================] - 4s - loss: 16.0537 - acc: 0.8362     \n",
      "Epoch 2/30\n",
      "10320/10320 [==============================] - 3s - loss: 10.1689 - acc: 0.8752     \n",
      "Epoch 3/30\n",
      "10320/10320 [==============================] - 3s - loss: 8.0391 - acc: 0.8866     \n",
      "Epoch 4/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.9041 - acc: 0.8956     \n",
      "Epoch 5/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.1830 - acc: 0.9026     \n",
      "Epoch 6/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.6840 - acc: 0.9024     \n",
      "Epoch 7/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.3167 - acc: 0.9097     \n",
      "Epoch 8/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.0220 - acc: 0.9141     \n",
      "Epoch 9/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.7918 - acc: 0.9149     \n",
      "Epoch 10/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.6023 - acc: 0.9158     \n",
      "Epoch 11/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.4406 - acc: 0.9203     \n",
      "Epoch 12/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.2972 - acc: 0.9245     \n",
      "Epoch 13/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.1856 - acc: 0.9205     \n",
      "Epoch 14/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.0741 - acc: 0.9247     \n",
      "Epoch 15/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.9795 - acc: 0.9277     \n",
      "Epoch 16/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.8934 - acc: 0.9285     \n",
      "Epoch 17/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.8157 - acc: 0.9299     \n",
      "Epoch 18/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.7469 - acc: 0.9282     \n",
      "Epoch 19/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6838 - acc: 0.9304     \n",
      "Epoch 20/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6232 - acc: 0.9338     \n",
      "Epoch 21/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5702 - acc: 0.9341     \n",
      "Epoch 22/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5159 - acc: 0.9340     \n",
      "Epoch 23/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4694 - acc: 0.9350     \n",
      "Epoch 24/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4241 - acc: 0.9356     \n",
      "Epoch 25/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3794 - acc: 0.9396     \n",
      "Epoch 26/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3442 - acc: 0.9360     \n",
      "Epoch 27/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3109 - acc: 0.9373     \n",
      "Epoch 28/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2736 - acc: 0.9374     \n",
      "Epoch 29/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2356 - acc: 0.9410     \n",
      "Epoch 30/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2069 - acc: 0.9409     \n",
      "# # # Evaluating cv-fold...\n",
      "384/485 [======================>.......] - ETA: 0s \n",
      "accuracy: 90.72164949682569\n",
      "precision: 92.54385964912281\n",
      "recall: 88.28451882845188\n",
      "f1_score: 90.36402569593149\n",
      "Training fold 6/10\n",
      "Epoch 1/30\n",
      "10320/10320 [==============================] - 4s - loss: 16.1527 - acc: 0.8408     \n",
      "Epoch 2/30\n",
      "10320/10320 [==============================] - 3s - loss: 10.2784 - acc: 0.8734     \n",
      "Epoch 3/30\n",
      "10320/10320 [==============================] - 3s - loss: 8.1394 - acc: 0.8907     \n",
      "Epoch 4/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.9934 - acc: 0.8986     \n",
      "Epoch 5/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.2671 - acc: 0.9071     \n",
      "Epoch 6/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.7599 - acc: 0.9069     \n",
      "Epoch 7/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.3761 - acc: 0.9154     \n",
      "Epoch 8/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.0816 - acc: 0.9167     \n",
      "Epoch 9/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.8494 - acc: 0.9162     \n",
      "Epoch 10/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.6499 - acc: 0.9212     \n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10320/10320 [==============================] - 3s - loss: 4.4822 - acc: 0.9221     \n",
      "Epoch 12/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.3434 - acc: 0.9249     \n",
      "Epoch 13/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.2151 - acc: 0.9270     \n",
      "Epoch 14/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.1083 - acc: 0.9280     \n",
      "Epoch 15/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.0164 - acc: 0.9239     \n",
      "Epoch 16/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.9275 - acc: 0.9274     \n",
      "Epoch 17/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.8437 - acc: 0.9332     \n",
      "Epoch 18/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.7707 - acc: 0.9329     \n",
      "Epoch 19/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.7077 - acc: 0.9339     \n",
      "Epoch 20/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6459 - acc: 0.9337     \n",
      "Epoch 21/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5902 - acc: 0.9352     \n",
      "Epoch 22/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5368 - acc: 0.9399     \n",
      "Epoch 23/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4905 - acc: 0.9350     \n",
      "Epoch 24/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4421 - acc: 0.9391     \n",
      "Epoch 25/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4005 - acc: 0.9396     \n",
      "Epoch 26/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3628 - acc: 0.9376     \n",
      "Epoch 27/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3215 - acc: 0.9390     \n",
      "Epoch 28/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2881 - acc: 0.9393     \n",
      "Epoch 29/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2475 - acc: 0.9444     \n",
      "Epoch 30/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2178 - acc: 0.9411     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 7s\n",
      "accuracy: 90.72164949682569\n",
      "precision: 91.10169491525424\n",
      "recall: 89.9581589958159\n",
      "f1_score: 90.52631578947368\n",
      "Training fold 7/10\n",
      "Epoch 1/30\n",
      "10320/10320 [==============================] - 4s - loss: 16.0998 - acc: 0.8377     \n",
      "Epoch 2/30\n",
      "10320/10320 [==============================] - 3s - loss: 10.1964 - acc: 0.8777     \n",
      "Epoch 3/30\n",
      "10320/10320 [==============================] - 3s - loss: 8.0742 - acc: 0.8855     \n",
      "Epoch 4/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.9372 - acc: 0.8940     \n",
      "Epoch 5/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.2144 - acc: 0.9024     \n",
      "Epoch 6/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.7064 - acc: 0.9077     \n",
      "Epoch 7/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.3357 - acc: 0.9086     \n",
      "Epoch 8/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.0372 - acc: 0.9175     \n",
      "Epoch 9/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.8100 - acc: 0.9128     \n",
      "Epoch 10/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.6146 - acc: 0.9183     \n",
      "Epoch 11/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.4529 - acc: 0.9194     \n",
      "Epoch 12/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.3143 - acc: 0.9206     \n",
      "Epoch 13/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.1909 - acc: 0.9248     \n",
      "Epoch 14/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.0794 - acc: 0.9276     \n",
      "Epoch 15/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.9906 - acc: 0.9253     \n",
      "Epoch 16/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.9055 - acc: 0.9251     \n",
      "Epoch 17/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.8260 - acc: 0.9277     \n",
      "Epoch 18/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.7530 - acc: 0.9317     \n",
      "Epoch 19/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6924 - acc: 0.9293     \n",
      "Epoch 20/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6322 - acc: 0.9298     \n",
      "Epoch 21/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5726 - acc: 0.9382     \n",
      "Epoch 22/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5273 - acc: 0.9326     \n",
      "Epoch 23/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4783 - acc: 0.9328     \n",
      "Epoch 24/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4324 - acc: 0.9354     \n",
      "Epoch 25/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3906 - acc: 0.9380     \n",
      "Epoch 26/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3568 - acc: 0.9364     \n",
      "Epoch 27/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3106 - acc: 0.9407     \n",
      "Epoch 28/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2815 - acc: 0.9384     \n",
      "Epoch 29/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2452 - acc: 0.9402     \n",
      "Epoch 30/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2136 - acc: 0.9401     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 8s\n",
      "accuracy: 90.51546394210501\n",
      "precision: 91.77489177489177\n",
      "recall: 88.70292887029288\n",
      "f1_score: 90.21276595744682\n",
      "Training fold 8/10\n",
      "Epoch 1/30\n",
      "10320/10320 [==============================] - 4s - loss: 16.0888 - acc: 0.8354     \n",
      "Epoch 2/30\n",
      "10320/10320 [==============================] - 3s - loss: 10.1754 - acc: 0.8703     \n",
      "Epoch 3/30\n",
      "10320/10320 [==============================] - 3s - loss: 8.0289 - acc: 0.8884     \n",
      "Epoch 4/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.8940 - acc: 0.8904     \n",
      "Epoch 5/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.1736 - acc: 0.8991     \n",
      "Epoch 6/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.6727 - acc: 0.9047     \n",
      "Epoch 7/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.3063 - acc: 0.9053     \n",
      "Epoch 8/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.0104 - acc: 0.9142     \n",
      "Epoch 9/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.7877 - acc: 0.9108     \n",
      "Epoch 10/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.5890 - acc: 0.9154     \n",
      "Epoch 11/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.4310 - acc: 0.9165     \n",
      "Epoch 12/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.2903 - acc: 0.9180     \n",
      "Epoch 13/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.1708 - acc: 0.9213     \n",
      "Epoch 14/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.0624 - acc: 0.9238     \n",
      "Epoch 15/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.9712 - acc: 0.9240     \n",
      "Epoch 16/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.8823 - acc: 0.9272     \n",
      "Epoch 17/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.8099 - acc: 0.9253     \n",
      "Epoch 18/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.7341 - acc: 0.9295     \n",
      "Epoch 19/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6679 - acc: 0.9324     \n",
      "Epoch 20/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6095 - acc: 0.9344     \n",
      "Epoch 21/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5543 - acc: 0.9326     \n",
      "Epoch 22/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5080 - acc: 0.9324     \n",
      "Epoch 23/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4596 - acc: 0.9324     \n",
      "Epoch 24/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4117 - acc: 0.9361     \n",
      "Epoch 25/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3675 - acc: 0.9389     \n",
      "Epoch 26/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3294 - acc: 0.9379     \n",
      "Epoch 27/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2932 - acc: 0.9382     \n",
      "Epoch 28/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2600 - acc: 0.9407     \n",
      "Epoch 29/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2293 - acc: 0.9365     \n",
      "Epoch 30/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.1962 - acc: 0.9391     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 8s\n",
      "accuracy: 89.89690724107408\n",
      "precision: 93.18181818181817\n",
      "recall: 85.77405857740585\n",
      "f1_score: 89.32461873638343\n",
      "Training fold 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10320/10320 [==============================] - 5s - loss: 15.9906 - acc: 0.8371     \n",
      "Epoch 2/30\n",
      "10320/10320 [==============================] - 3s - loss: 10.0379 - acc: 0.8785     \n",
      "Epoch 3/30\n",
      "10320/10320 [==============================] - 3s - loss: 7.9059 - acc: 0.8893     \n",
      "Epoch 4/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.7823 - acc: 0.8937     \n",
      "Epoch 5/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.0709 - acc: 0.9007     \n",
      "Epoch 6/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.5684 - acc: 0.9077     \n",
      "Epoch 7/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.1973 - acc: 0.9105     \n",
      "Epoch 8/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.9158 - acc: 0.9140     \n",
      "Epoch 9/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.6785 - acc: 0.9197     \n",
      "Epoch 10/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.4976 - acc: 0.9187     \n",
      "Epoch 11/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.3315 - acc: 0.9216     \n",
      "Epoch 12/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.1950 - acc: 0.9234     \n",
      "Epoch 13/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.0779 - acc: 0.9249     \n",
      "Epoch 14/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.9731 - acc: 0.9244     \n",
      "Epoch 15/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.8777 - acc: 0.9261     \n",
      "Epoch 16/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.7918 - acc: 0.9282     \n",
      "Epoch 17/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.7182 - acc: 0.9300     \n",
      "Epoch 18/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6455 - acc: 0.9328     \n",
      "Epoch 19/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5849 - acc: 0.9312     \n",
      "Epoch 20/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5253 - acc: 0.9349     \n",
      "Epoch 21/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4714 - acc: 0.9343     \n",
      "Epoch 22/30\n",
      "10320/10320 [==============================] - 4s - loss: 3.4157 - acc: 0.9357     \n",
      "Epoch 23/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3765 - acc: 0.9345     \n",
      "Epoch 24/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3334 - acc: 0.9344     \n",
      "Epoch 25/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2931 - acc: 0.9354     - ETA: 0s - loss: 3.2964 - \n",
      "Epoch 26/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2504 - acc: 0.9374     \n",
      "Epoch 27/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2175 - acc: 0.9356     \n",
      "Epoch 28/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.1814 - acc: 0.9408     \n",
      "Epoch 29/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.1448 - acc: 0.9400     \n",
      "Epoch 30/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.1133 - acc: 0.9426     \n",
      "# # # Evaluating cv-fold...\n",
      " 32/485 [>.............................] - ETA: 8s\n",
      "accuracy: 90.51546394210501\n",
      "precision: 90.3765690376569\n",
      "recall: 90.3765690376569\n",
      "f1_score: 90.3765690376569\n",
      "Training fold 10/10\n",
      "Epoch 1/30\n",
      "10320/10320 [==============================] - 4s - loss: 16.1013 - acc: 0.8395     \n",
      "Epoch 2/30\n",
      "10320/10320 [==============================] - 3s - loss: 10.2497 - acc: 0.8772     \n",
      "Epoch 3/30\n",
      "10320/10320 [==============================] - 3s - loss: 8.1230 - acc: 0.8891     \n",
      "Epoch 4/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.9870 - acc: 0.8953     \n",
      "Epoch 5/30\n",
      "10320/10320 [==============================] - 3s - loss: 6.2716 - acc: 0.9031     \n",
      "Epoch 6/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.7699 - acc: 0.9073     \n",
      "Epoch 7/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.3965 - acc: 0.9097     \n",
      "Epoch 8/30\n",
      "10320/10320 [==============================] - 3s - loss: 5.1042 - acc: 0.9157     \n",
      "Epoch 9/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.8756 - acc: 0.9129     \n",
      "Epoch 10/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.6821 - acc: 0.9193     \n",
      "Epoch 11/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.5217 - acc: 0.9192     \n",
      "Epoch 12/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.3785 - acc: 0.9234     \n",
      "Epoch 13/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.2570 - acc: 0.9242     \n",
      "Epoch 14/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.1489 - acc: 0.9264     \n",
      "Epoch 15/30\n",
      "10320/10320 [==============================] - 3s - loss: 4.0582 - acc: 0.9246     \n",
      "Epoch 16/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.9667 - acc: 0.9315     \n",
      "Epoch 17/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.8944 - acc: 0.9276     \n",
      "Epoch 18/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.8194 - acc: 0.9294     \n",
      "Epoch 19/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.7516 - acc: 0.9348     \n",
      "Epoch 20/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6942 - acc: 0.9333     \n",
      "Epoch 21/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.6366 - acc: 0.9358     \n",
      "Epoch 22/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5900 - acc: 0.9325     \n",
      "Epoch 23/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.5410 - acc: 0.9357     \n",
      "Epoch 24/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4955 - acc: 0.9354     \n",
      "Epoch 25/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4519 - acc: 0.9365     \n",
      "Epoch 26/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.4104 - acc: 0.9377     \n",
      "Epoch 27/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3760 - acc: 0.9373     \n",
      "Epoch 28/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3370 - acc: 0.9387     \n",
      "Epoch 29/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.3037 - acc: 0.9407     \n",
      "Epoch 30/30\n",
      "10320/10320 [==============================] - 3s - loss: 3.2736 - acc: 0.9372     \n",
      "# # # Evaluating cv-fold...\n",
      "485/485 [==============================] - 0s      \n",
      "\n",
      "accuracy: 90.10309279579477\n",
      "precision: 91.70305676855895\n",
      "recall: 87.86610878661088\n",
      "f1_score: 89.74358974358974\n",
      "\n",
      "Final cross-validation score:\n",
      "90.45360826339918 +/- 0.32008607454909416\n",
      "91.86298396573989 +/- 1.085689637019251\n",
      "88.49372384937239 +/- 1.313167767905875\n",
      "90.13210246422372 +/- 0.37257867605410355\n"
     ]
    }
   ],
   "source": [
    "# ON THE AUGMENTED DATASET WITH FLIPLR, FLIPUD, ROTATE10 AND ROTATE 10 MIRROR\n",
    "\n",
    "folds = 10\n",
    "cv_accuracies = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1_score = []\n",
    "\n",
    "for fold in range(folds):\n",
    "    print(\"Training fold \" + str(fold + 1) + \"/\" + str(folds))\n",
    "    \n",
    "    shuffle(train_tactile_images, train_labels_cat)\n",
    "    shuffle(test_tactile_images, test_labels_cat) \n",
    "    \n",
    "    # build model\n",
    "    epochs = 30\n",
    "    batch = 32\n",
    "    \n",
    "    learning_rate = 0.0001\n",
    "    epsilon = 1e-08\n",
    "    decay_rate = 0.005\n",
    "    \n",
    "    l2_reg = 0.015\n",
    "    drop_prob = 0.25\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(FINGERS, TACTILE_IMAGE_ROWS, TACTILE_IMAGE_COLS), \n",
    "                     data_format='channels_first',\n",
    "                     use_bias=False, kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1024, kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(drop_prob))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # compile and train\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.Adam(lr=learning_rate, epsilon=epsilon, decay=decay_rate), \n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(train_tactile_images, train_labels_cat, epochs=epochs, batch_size=batch, verbose=1)\n",
    "    \n",
    "    # evaluate\n",
    "    print(\"# # # Evaluating cv-fold...\")\n",
    "    scores = model.evaluate(test_tactile_images, test_labels_cat, verbose=1)\n",
    "    cv_accuracies.append(scores[1] * 100)\n",
    "    \n",
    "    predictions = model.predict(test_tactile_images)\n",
    "    [precision, recall, f1_score, _] = precision_recall_fscore_support(np.argmax(test_labels_cat, axis=1), \n",
    "                                                                          np.argmax(predictions, axis=1), \n",
    "                                                                          average='binary', pos_label=1)\n",
    "    \n",
    "    cv_precision.append(precision * 100)\n",
    "    cv_recall.append(recall * 100)\n",
    "    cv_f1_score.append(f1_score * 100)\n",
    "    \n",
    "    print(\"\\naccuracy:\", scores[1] * 100)\n",
    "    print(\"precision:\", precision * 100)\n",
    "    print(\"recall:\", recall * 100)\n",
    "    print(\"f1_score:\", f1_score * 100)\n",
    "    \n",
    "print(\"\\nFinal cross-validation score:\")\n",
    "print(np.mean(cv_accuracies), \"+/-\", np.std(cv_accuracies))\n",
    "print(np.mean(cv_precision), \"+/-\", np.std(cv_precision))\n",
    "print(np.mean(cv_recall), \"+/-\", np.std(cv_recall))\n",
    "print(np.mean(cv_f1_score), \"+/-\", np.std(cv_f1_score))\n",
    "\n",
    "# IROS\n",
    "#86.0355987113 +/- 0.383259524026\n",
    "#86.47674489 +/- 0.501892412426\n",
    "#83.8644067797 +/- 0.775967670662\n",
    "#85.1477152443 +/- 0.441251814143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'known' train, 'unknown' test - Classic ML Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2064, 72)\n",
      "(485, 72)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LAYING_RAW_DATA_FILE = 'laying_grasps.csv'\n",
    "STANDING_RAW_DATA_FILE = 'standing_grasps.csv'\n",
    "\n",
    "laying_raw_df = pd.read_csv(LAYING_RAW_DATA_FILE)\n",
    "standing_raw_df = pd.read_csv(STANDING_RAW_DATA_FILE)\n",
    "whole_raw_df = pd.concat([laying_raw_df, standing_raw_df])\n",
    "\n",
    "whole_raw_df['object'].value_counts().plot(kind='bar', figsize=(15, 10))\n",
    "\n",
    "#unknown_objects = ['metal_box', 'juice', 'aquarius', 'green_gel', 'tennis', 'football', 'milk', 'metal_pen_case', 'train', 'budha']\n",
    "#unknown_objects = ['metal_box', 'football', 'budha']\n",
    "unknown_objects = ['juice', 'aquarius', 'green_gel', 'tennis', 'football', 'milk', 'metal_pen_case', 'train']\n",
    "\n",
    "unknown_raw_df = whole_raw_df.loc[whole_raw_df['object'].isin(unknown_objects)]\n",
    "known_raw_df = whole_raw_df.loc[~whole_raw_df['object'].isin(unknown_objects)]\n",
    "\n",
    "known_labels = known_raw_df['slipped'].values\n",
    "known_tactiles = known_raw_df[['ff_biotac_1', 'ff_biotac_2', 'ff_biotac_3', 'ff_biotac_4', 'ff_biotac_5', \n",
    "                   'ff_biotac_6', 'ff_biotac_7', 'ff_biotac_8', 'ff_biotac_9', 'ff_biotac_10', 'ff_biotac_11', \n",
    "                   'ff_biotac_12', 'ff_biotac_13', 'ff_biotac_14', 'ff_biotac_15', 'ff_biotac_16', 'ff_biotac_17', \n",
    "                   'ff_biotac_18', 'ff_biotac_19', 'ff_biotac_20', 'ff_biotac_21', 'ff_biotac_22', 'ff_biotac_23', \n",
    "                   'ff_biotac_24', 'mf_biotac_1', 'mf_biotac_2', 'mf_biotac_3', 'mf_biotac_4', 'mf_biotac_5', \n",
    "                   'mf_biotac_6', 'mf_biotac_7', 'mf_biotac_8', 'mf_biotac_9', 'mf_biotac_10', 'mf_biotac_11', \n",
    "                   'mf_biotac_12', 'mf_biotac_13', 'mf_biotac_14', 'mf_biotac_15', 'mf_biotac_16', 'mf_biotac_17', \n",
    "                   'mf_biotac_18', 'mf_biotac_19', 'mf_biotac_20', 'mf_biotac_21', 'mf_biotac_22', 'mf_biotac_23', \n",
    "                   'mf_biotac_24', 'th_biotac_1', 'th_biotac_2', 'th_biotac_3', 'th_biotac_4', 'th_biotac_5', \n",
    "                   'th_biotac_6', 'th_biotac_7', 'th_biotac_8', 'th_biotac_9', 'th_biotac_10', 'th_biotac_11', \n",
    "                   'th_biotac_12', 'th_biotac_13', 'th_biotac_14', 'th_biotac_15', 'th_biotac_16', 'th_biotac_17', \n",
    "                   'th_biotac_18', 'th_biotac_19', 'th_biotac_20', 'th_biotac_21', 'th_biotac_22', 'th_biotac_23', \n",
    "                   'th_biotac_24']].values\n",
    "\n",
    "unknown_labels = unknown_raw_df['slipped'].values\n",
    "unknown_tactiles = unknown_raw_df[['ff_biotac_1', 'ff_biotac_2', 'ff_biotac_3', 'ff_biotac_4', 'ff_biotac_5', \n",
    "                   'ff_biotac_6', 'ff_biotac_7', 'ff_biotac_8', 'ff_biotac_9', 'ff_biotac_10', 'ff_biotac_11', \n",
    "                   'ff_biotac_12', 'ff_biotac_13', 'ff_biotac_14', 'ff_biotac_15', 'ff_biotac_16', 'ff_biotac_17', \n",
    "                   'ff_biotac_18', 'ff_biotac_19', 'ff_biotac_20', 'ff_biotac_21', 'ff_biotac_22', 'ff_biotac_23', \n",
    "                   'ff_biotac_24', 'mf_biotac_1', 'mf_biotac_2', 'mf_biotac_3', 'mf_biotac_4', 'mf_biotac_5', \n",
    "                   'mf_biotac_6', 'mf_biotac_7', 'mf_biotac_8', 'mf_biotac_9', 'mf_biotac_10', 'mf_biotac_11', \n",
    "                   'mf_biotac_12', 'mf_biotac_13', 'mf_biotac_14', 'mf_biotac_15', 'mf_biotac_16', 'mf_biotac_17', \n",
    "                   'mf_biotac_18', 'mf_biotac_19', 'mf_biotac_20', 'mf_biotac_21', 'mf_biotac_22', 'mf_biotac_23', \n",
    "                   'mf_biotac_24', 'th_biotac_1', 'th_biotac_2', 'th_biotac_3', 'th_biotac_4', 'th_biotac_5', \n",
    "                   'th_biotac_6', 'th_biotac_7', 'th_biotac_8', 'th_biotac_9', 'th_biotac_10', 'th_biotac_11', \n",
    "                   'th_biotac_12', 'th_biotac_13', 'th_biotac_14', 'th_biotac_15', 'th_biotac_16', 'th_biotac_17', \n",
    "                   'th_biotac_18', 'th_biotac_19', 'th_biotac_20', 'th_biotac_21', 'th_biotac_22', 'th_biotac_23', \n",
    "                   'th_biotac_24']].values\n",
    "\n",
    "print(known_tactiles.shape)\n",
    "print(unknown_tactiles.shape)\n",
    "\n",
    "known_tactiles = (known_tactiles - np.mean(known_tactiles)) / (np.std(known_tactiles))\n",
    "unknown_tactiles = (unknown_tactiles - np.mean(unknown_tactiles)) / (np.std(unknown_tactiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 89.89690721649485\n",
      "->precision: 88.30645161290323\n",
      "->recall: 91.63179916317992\n",
      "->f1_score: 89.93839835728953\n",
      "\n",
      "\n",
      "Training fold 2/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 89.89690721649485\n",
      "->precision: 88.30645161290323\n",
      "->recall: 91.63179916317992\n",
      "->f1_score: 89.93839835728953\n",
      "\n",
      "\n",
      "Training fold 3/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 89.89690721649485\n",
      "->precision: 88.30645161290323\n",
      "->recall: 91.63179916317992\n",
      "->f1_score: 89.93839835728953\n",
      "\n",
      "\n",
      "Training fold 4/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 89.89690721649485\n",
      "->precision: 88.30645161290323\n",
      "->recall: 91.63179916317992\n",
      "->f1_score: 89.93839835728953\n",
      "\n",
      "\n",
      "Training fold 5/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 89.89690721649485\n",
      "->precision: 88.30645161290323\n",
      "->recall: 91.63179916317992\n",
      "->f1_score: 89.93839835728953\n",
      "\n",
      "\n",
      "Training fold 6/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 89.89690721649485\n",
      "->precision: 88.30645161290323\n",
      "->recall: 91.63179916317992\n",
      "->f1_score: 89.93839835728953\n",
      "\n",
      "\n",
      "Training fold 7/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 89.89690721649485\n",
      "->precision: 88.30645161290323\n",
      "->recall: 91.63179916317992\n",
      "->f1_score: 89.93839835728953\n",
      "\n",
      "\n",
      "Training fold 8/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 89.89690721649485\n",
      "->precision: 88.30645161290323\n",
      "->recall: 91.63179916317992\n",
      "->f1_score: 89.93839835728953\n",
      "\n",
      "\n",
      "Training fold 9/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 89.89690721649485\n",
      "->precision: 88.30645161290323\n",
      "->recall: 91.63179916317992\n",
      "->f1_score: 89.93839835728953\n",
      "\n",
      "\n",
      "Training fold 10/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 89.89690721649485\n",
      "->precision: 88.30645161290323\n",
      "->recall: 91.63179916317992\n",
      "->f1_score: 89.93839835728953\n",
      "\n",
      "\n",
      "\n",
      "@ Final cross-validation score @\n",
      "89.89690721649484 +/- 1.4210854715202004e-14\n",
      "88.30645161290322 +/- 1.4210854715202004e-14\n",
      "91.63179916317992 +/- 0.0\n",
      "89.93839835728953 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# TESTING SVM\n",
    "\n",
    "folds = 10\n",
    "\n",
    "cv_accuracy = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1_score = []\n",
    "\n",
    "for fold in range(folds):\n",
    "    print(\"Training fold \" + str(fold + 1) + \"/\" + str(folds))\n",
    "    \n",
    "    shuffle(known_tactiles, known_labels)\n",
    "    shuffle(unknown_tactiles, unknown_labels)\n",
    "\n",
    "    # train\n",
    "    param_grid = {'C': [0.01, 0.1, 1, 1e1, 1e2, 1e3, 5e3], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "    svm = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid, n_jobs=12)\n",
    "    \n",
    "    print(svm)\n",
    "    \n",
    "    svm.fit(known_tactiles, known_labels)\n",
    "    \n",
    "    # evaluate\n",
    "    print(\"+ Evaluating cv-fold...\")\n",
    "    \n",
    "    predictions = svm.predict(unknown_tactiles)\n",
    "    \n",
    "    accuracy = accuracy_score(unknown_labels, predictions)\n",
    "    [precision, recall, f1_score, _] = precision_recall_fscore_support(unknown_labels, predictions, average='binary', \n",
    "                                                                       pos_label=1)\n",
    "    cv_accuracy.append(accuracy * 100)\n",
    "    cv_precision.append(precision * 100)\n",
    "    cv_recall.append(recall * 100)\n",
    "    cv_f1_score.append(f1_score * 100)\n",
    "\n",
    "    print(svm.best_params_)\n",
    "    print(\"->accuracy:\", accuracy * 100)\n",
    "    print(\"->precision:\", precision * 100)\n",
    "    print(\"->recall:\", recall * 100)\n",
    "    print(\"->f1_score:\", f1_score * 100)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"\\n@ Final cross-validation score @\")\n",
    "print(np.mean(cv_accuracy), \"+/-\", np.std(cv_accuracy))\n",
    "print(np.mean(cv_precision), \"+/-\", np.std(cv_precision))\n",
    "print(np.mean(cv_recall), \"+/-\", np.std(cv_recall))\n",
    "print(np.mean(cv_f1_score), \"+/-\", np.std(cv_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'max_depth': None, 'n_estimators': 150}\n",
      "->accuracy: 90.9278350515464\n",
      "->precision: 92.95154185022027\n",
      "->recall: 88.28451882845188\n",
      "->f1_score: 90.55793991416309\n",
      "\n",
      "\n",
      "Training fold 2/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'max_depth': None, 'n_estimators': 200}\n",
      "->accuracy: 90.51546391752578\n",
      "->precision: 92.51101321585902\n",
      "->recall: 87.86610878661088\n",
      "->f1_score: 90.12875536480685\n",
      "\n",
      "\n",
      "Training fold 3/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'max_depth': 5, 'n_estimators': 150}\n",
      "->accuracy: 90.9278350515464\n",
      "->precision: 90.7949790794979\n",
      "->recall: 90.7949790794979\n",
      "->f1_score: 90.7949790794979\n",
      "\n",
      "\n",
      "Training fold 4/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'max_depth': 15, 'n_estimators': 150}\n",
      "->accuracy: 90.30927835051547\n",
      "->precision: 92.47787610619469\n",
      "->recall: 87.44769874476988\n",
      "->f1_score: 89.89247311827957\n",
      "\n",
      "\n",
      "Training fold 5/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'max_depth': 20, 'n_estimators': 150}\n",
      "->accuracy: 90.9278350515464\n",
      "->precision: 93.33333333333333\n",
      "->recall: 87.86610878661088\n",
      "->f1_score: 90.51724137931035\n",
      "\n",
      "\n",
      "Training fold 6/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'max_depth': 15, 'n_estimators': 150}\n",
      "->accuracy: 90.30927835051547\n",
      "->precision: 92.10526315789474\n",
      "->recall: 87.86610878661088\n",
      "->f1_score: 89.93576017130621\n",
      "\n",
      "\n",
      "Training fold 7/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'max_depth': 10, 'n_estimators': 200}\n",
      "->accuracy: 90.51546391752578\n",
      "->precision: 92.88888888888889\n",
      "->recall: 87.44769874476988\n",
      "->f1_score: 90.08620689655173\n",
      "\n",
      "\n",
      "Training fold 8/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'max_depth': 5, 'n_estimators': 200}\n",
      "->accuracy: 90.72164948453609\n",
      "->precision: 91.45299145299145\n",
      "->recall: 89.5397489539749\n",
      "->f1_score: 90.48625792811839\n",
      "\n",
      "\n",
      "Training fold 9/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Evaluating cv-fold...\n",
      "{'max_depth': None, 'n_estimators': 100}\n",
      "->accuracy: 89.69072164948454\n",
      "->precision: 93.15068493150685\n",
      "->recall: 85.35564853556485\n",
      "->f1_score: 89.08296943231441\n",
      "\n",
      "\n",
      "Training fold 10/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'max_depth': 30, 'n_estimators': 150}\n",
      "->accuracy: 90.72164948453609\n",
      "->precision: 92.92035398230088\n",
      "->recall: 87.86610878661088\n",
      "->f1_score: 90.3225806451613\n",
      "\n",
      "\n",
      "\n",
      "@ Final cross-validation score @\n",
      "90.55670103092784 +/- 0.36652348112641475\n",
      "92.4586925998688 +/- 0.7610746061517851\n",
      "88.03347280334728 +/- 1.3389121338912122\n",
      "90.18051639295098 +/- 0.4589241891760952\n"
     ]
    }
   ],
   "source": [
    "# TESTING RF\n",
    "\n",
    "folds = 10\n",
    "\n",
    "cv_accuracy = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1_score = []\n",
    "\n",
    "for fold in range(folds):\n",
    "    print(\"Training fold \" + str(fold + 1) + \"/\" + str(folds))\n",
    "    \n",
    "    shuffle(known_tactiles, known_labels)\n",
    "    shuffle(unknown_tactiles, unknown_labels) \n",
    "\n",
    "    # train\n",
    "    param_grid = {'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]}\n",
    "    rf = GridSearchCV(RandomForestClassifier(oob_score=False), param_grid, n_jobs=12)\n",
    "    \n",
    "    print(rf)\n",
    "    \n",
    "    rf.fit(known_tactiles, known_labels)\n",
    "    \n",
    "    # evaluate\n",
    "    print(\"+ Evaluating cv-fold...\")\n",
    "    \n",
    "    predictions = rf.predict(unknown_tactiles)\n",
    "    \n",
    "    accuracy = accuracy_score(unknown_labels, predictions)\n",
    "    [precision, recall, f1_score, _] = precision_recall_fscore_support(unknown_labels, predictions, average='binary', \n",
    "                                                                       pos_label=1)\n",
    "    cv_accuracy.append(accuracy * 100)\n",
    "    cv_precision.append(precision * 100)\n",
    "    cv_recall.append(recall * 100)\n",
    "    cv_f1_score.append(f1_score * 100)\n",
    "\n",
    "    print(rf.best_params_)\n",
    "    print(\"->accuracy:\", accuracy * 100)\n",
    "    print(\"->precision:\", precision * 100)\n",
    "    print(\"->recall:\", recall * 100)\n",
    "    print(\"->f1_score:\", f1_score * 100)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"\\n@ Final cross-validation score @\")\n",
    "print(np.mean(cv_accuracy), \"+/-\", np.std(cv_accuracy))\n",
    "print(np.mean(cv_precision), \"+/-\", np.std(cv_precision))\n",
    "print(np.mean(cv_recall), \"+/-\", np.std(cv_recall))\n",
    "print(np.mean(cv_f1_score), \"+/-\", np.std(cv_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 11}\n",
      "->accuracy: 81.85567010309278\n",
      "->precision: 76.86832740213522\n",
      "->recall: 90.3765690376569\n",
      "->f1_score: 83.07692307692308\n",
      "\n",
      "\n",
      "Training fold 2/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 11}\n",
      "->accuracy: 81.85567010309278\n",
      "->precision: 76.86832740213522\n",
      "->recall: 90.3765690376569\n",
      "->f1_score: 83.07692307692308\n",
      "\n",
      "\n",
      "Training fold 3/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 11}\n",
      "->accuracy: 81.85567010309278\n",
      "->precision: 76.86832740213522\n",
      "->recall: 90.3765690376569\n",
      "->f1_score: 83.07692307692308\n",
      "\n",
      "\n",
      "Training fold 4/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 11}\n",
      "->accuracy: 81.85567010309278\n",
      "->precision: 76.86832740213522\n",
      "->recall: 90.3765690376569\n",
      "->f1_score: 83.07692307692308\n",
      "\n",
      "\n",
      "Training fold 5/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 11}\n",
      "->accuracy: 81.85567010309278\n",
      "->precision: 76.86832740213522\n",
      "->recall: 90.3765690376569\n",
      "->f1_score: 83.07692307692308\n",
      "\n",
      "\n",
      "Training fold 6/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 11}\n",
      "->accuracy: 81.85567010309278\n",
      "->precision: 76.86832740213522\n",
      "->recall: 90.3765690376569\n",
      "->f1_score: 83.07692307692308\n",
      "\n",
      "\n",
      "Training fold 7/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 11}\n",
      "->accuracy: 81.85567010309278\n",
      "->precision: 76.86832740213522\n",
      "->recall: 90.3765690376569\n",
      "->f1_score: 83.07692307692308\n",
      "\n",
      "\n",
      "Training fold 8/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 11}\n",
      "->accuracy: 81.85567010309278\n",
      "->precision: 76.86832740213522\n",
      "->recall: 90.3765690376569\n",
      "->f1_score: 83.07692307692308\n",
      "\n",
      "\n",
      "Training fold 9/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 11}\n",
      "->accuracy: 81.85567010309278\n",
      "->precision: 76.86832740213522\n",
      "->recall: 90.3765690376569\n",
      "->f1_score: 83.07692307692308\n",
      "\n",
      "\n",
      "Training fold 10/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 11}\n",
      "->accuracy: 81.85567010309278\n",
      "->precision: 76.86832740213522\n",
      "->recall: 90.3765690376569\n",
      "->f1_score: 83.07692307692308\n",
      "\n",
      "\n",
      "\n",
      "@ Final cross-validation score @\n",
      "81.85567010309276 +/- 1.4210854715202004e-14\n",
      "76.86832740213524 +/- 1.4210854715202004e-14\n",
      "90.37656903765692 +/- 1.4210854715202004e-14\n",
      "83.07692307692308 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# TESTING K-NN\n",
    "\n",
    "folds = 10\n",
    "\n",
    "cv_accuracy = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1_score = []\n",
    "\n",
    "for fold in range(folds):\n",
    "    print(\"Training fold \" + str(fold + 1) + \"/\" + str(folds))\n",
    "    \n",
    "    shuffle(known_tactiles, known_labels)\n",
    "    shuffle(unknown_tactiles, unknown_labels) \n",
    "\n",
    "    # train\n",
    "    param_grid = {'n_neighbors' : [1, 3, 5, 7, 9, 11, 13], }\n",
    "    neigh = GridSearchCV(KNeighborsClassifier(), param_grid, n_jobs=12)\n",
    "    \n",
    "    print(neigh)\n",
    "    \n",
    "    neigh.fit(known_tactiles, known_labels)\n",
    "    \n",
    "    # evaluate\n",
    "    print(\"+ Evaluating cv-fold...\")\n",
    "    \n",
    "    predictions = neigh.predict(unknown_tactiles)\n",
    "    \n",
    "    accuracy = accuracy_score(unknown_labels, predictions)\n",
    "    [precision, recall, f1_score, _] = precision_recall_fscore_support(unknown_labels, predictions, average='binary', \n",
    "                                                                       pos_label=1)\n",
    "    cv_accuracy.append(accuracy * 100)\n",
    "    cv_precision.append(precision * 100)\n",
    "    cv_recall.append(recall * 100)\n",
    "    cv_f1_score.append(f1_score * 100)\n",
    "    \n",
    "    print(neigh.best_params_)\n",
    "    print(\"->accuracy:\", accuracy * 100)\n",
    "    print(\"->precision:\", precision * 100)\n",
    "    print(\"->recall:\", recall * 100)\n",
    "    print(\"->f1_score:\", f1_score * 100)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"\\n@ Final cross-validation score @\")\n",
    "print(np.mean(cv_accuracy), \"+/-\", np.std(cv_accuracy))\n",
    "print(np.mean(cv_precision), \"+/-\", np.std(cv_precision))\n",
    "print(np.mean(cv_recall), \"+/-\", np.std(cv_recall))\n",
    "print(np.mean(cv_f1_score), \"+/-\", np.std(cv_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'hidden_layer_sizes': [(100,), (1000,), (100, 1000)], 'activation': ['relu', 'logistic', 'tanh']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (100, 1000)}\n",
      "->accuracy: 89.48453608247424\n",
      "->precision: 90.51724137931035\n",
      "->recall: 87.86610878661088\n",
      "->f1_score: 89.17197452229298\n",
      "\n",
      "\n",
      "Training fold 2/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'hidden_layer_sizes': [(100,), (1000,), (100, 1000)], 'activation': ['relu', 'logistic', 'tanh']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (1000,)}\n",
      "->accuracy: 89.07216494845362\n",
      "->precision: 85.76923076923076\n",
      "->recall: 93.30543933054393\n",
      "->f1_score: 89.37875751503006\n",
      "\n",
      "\n",
      "Training fold 3/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'hidden_layer_sizes': [(100,), (1000,), (100, 1000)], 'activation': ['relu', 'logistic', 'tanh']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (100, 1000)}\n",
      "->accuracy: 89.48453608247424\n",
      "->precision: 95.1923076923077\n",
      "->recall: 82.84518828451883\n",
      "->f1_score: 88.59060402684564\n",
      "\n",
      "\n",
      "Training fold 4/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'hidden_layer_sizes': [(100,), (1000,), (100, 1000)], 'activation': ['relu', 'logistic', 'tanh']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (100, 1000)}\n",
      "->accuracy: 90.10309278350516\n",
      "->precision: 88.66396761133603\n",
      "->recall: 91.63179916317992\n",
      "->f1_score: 90.12345679012346\n",
      "\n",
      "\n",
      "Training fold 5/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'hidden_layer_sizes': [(100,), (1000,), (100, 1000)], 'activation': ['relu', 'logistic', 'tanh']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (100,)}\n",
      "->accuracy: 89.89690721649485\n",
      "->precision: 91.66666666666666\n",
      "->recall: 87.44769874476988\n",
      "->f1_score: 89.50749464668094\n",
      "\n",
      "\n",
      "Training fold 6/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'hidden_layer_sizes': [(100,), (1000,), (100, 1000)], 'activation': ['relu', 'logistic', 'tanh']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (100,)}\n",
      "->accuracy: 89.89690721649485\n",
      "->precision: 91.66666666666666\n",
      "->recall: 87.44769874476988\n",
      "->f1_score: 89.50749464668094\n",
      "\n",
      "\n",
      "Training fold 7/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'hidden_layer_sizes': [(100,), (1000,), (100, 1000)], 'activation': ['relu', 'logistic', 'tanh']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (100, 1000)}\n",
      "->accuracy: 91.1340206185567\n",
      "->precision: 88.28125\n",
      "->recall: 94.56066945606695\n",
      "->f1_score: 91.31313131313131\n",
      "\n",
      "\n",
      "Training fold 8/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'hidden_layer_sizes': [(100,), (1000,), (100, 1000)], 'activation': ['relu', 'logistic', 'tanh']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (100,)}\n",
      "->accuracy: 90.51546391752578\n",
      "->precision: 88.75502008032129\n",
      "->recall: 92.46861924686193\n",
      "->f1_score: 90.57377049180329\n",
      "\n",
      "\n",
      "Training fold 9/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'hidden_layer_sizes': [(100,), (1000,), (100, 1000)], 'activation': ['relu', 'logistic', 'tanh']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Evaluating cv-fold...\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (100, 1000)}\n",
      "->accuracy: 90.51546391752578\n",
      "->precision: 90.71729957805907\n",
      "->recall: 89.9581589958159\n",
      "->f1_score: 90.33613445378151\n",
      "\n",
      "\n",
      "Training fold 10/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=12,\n",
      "       param_grid={'hidden_layer_sizes': [(100,), (1000,), (100, 1000)], 'activation': ['relu', 'logistic', 'tanh']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (100,)}\n",
      "->accuracy: 88.65979381443299\n",
      "->precision: 84.58646616541353\n",
      "->recall: 94.14225941422593\n",
      "->f1_score: 89.1089108910891\n",
      "\n",
      "\n",
      "\n",
      "@ Final cross-validation score @\n",
      "89.87628865979381 +/- 0.6989052064609604\n",
      "89.5816116609312 +/- 2.9161961525644826\n",
      "90.1673640167364 +/- 3.5515594732905442\n",
      "89.76117292974591 +/- 0.7712651262761747\n"
     ]
    }
   ],
   "source": [
    "# TESTING MLP\n",
    "\n",
    "folds = 10\n",
    "\n",
    "cv_accuracy = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1_score = []\n",
    "\n",
    "for fold in range(folds):\n",
    "    print(\"Training fold \" + str(fold + 1) + \"/\" + str(folds))\n",
    "    \n",
    "    shuffle(known_tactiles, known_labels)\n",
    "    shuffle(unknown_tactiles, unknown_labels)  \n",
    "\n",
    "    # train\n",
    "    param_grid = {'hidden_layer_sizes' : [(100,), (1000,), (100, 1000)], \n",
    "                 'activation' : ['relu', 'logistic', 'tanh']}\n",
    "    mlp = GridSearchCV(MLPClassifier(), param_grid, n_jobs=12)\n",
    "    \n",
    "    print(mlp)\n",
    "    \n",
    "    mlp.fit(known_tactiles, known_labels)\n",
    "    \n",
    "    # evaluate\n",
    "    print(\"+ Evaluating cv-fold...\")\n",
    "    \n",
    "    predictions = mlp.predict(unknown_tactiles)\n",
    "    \n",
    "    accuracy = accuracy_score(unknown_labels, predictions)\n",
    "    [precision, recall, f1_score, _] = precision_recall_fscore_support(unknown_labels, predictions, average='binary', \n",
    "                                                                       pos_label=1)\n",
    "    cv_accuracy.append(accuracy * 100)\n",
    "    cv_precision.append(precision * 100)\n",
    "    cv_recall.append(recall * 100)\n",
    "    cv_f1_score.append(f1_score * 100)\n",
    "    \n",
    "    print(mlp.best_params_)\n",
    "    print(\"->accuracy:\", accuracy * 100)\n",
    "    print(\"->precision:\", precision * 100)\n",
    "    print(\"->recall:\", recall * 100)\n",
    "    print(\"->f1_score:\", f1_score * 100)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"\\n@ Final cross-validation score @\")\n",
    "print(np.mean(cv_accuracy), \"+/-\", np.std(cv_accuracy))\n",
    "print(np.mean(cv_precision), \"+/-\", np.std(cv_precision))\n",
    "print(np.mean(cv_recall), \"+/-\", np.std(cv_recall))\n",
    "print(np.mean(cv_f1_score), \"+/-\", np.std(cv_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
