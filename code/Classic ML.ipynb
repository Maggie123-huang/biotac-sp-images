{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import seaborn.apionly as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYING_RAW_DATA_FILE = 'laying_grasps.csv'\n",
    "STANDING_RAW_DATA_FILE = 'standing_grasps.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slipped</th>\n",
       "      <th>ff_biotac_1</th>\n",
       "      <th>ff_biotac_2</th>\n",
       "      <th>ff_biotac_3</th>\n",
       "      <th>ff_biotac_4</th>\n",
       "      <th>ff_biotac_5</th>\n",
       "      <th>ff_biotac_6</th>\n",
       "      <th>ff_biotac_7</th>\n",
       "      <th>ff_biotac_8</th>\n",
       "      <th>ff_biotac_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ffj4</th>\n",
       "      <th>mfj1</th>\n",
       "      <th>mfj2</th>\n",
       "      <th>mfj3</th>\n",
       "      <th>mfj4</th>\n",
       "      <th>thj1</th>\n",
       "      <th>thj2</th>\n",
       "      <th>thj3</th>\n",
       "      <th>thj4</th>\n",
       "      <th>thj5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.501765</td>\n",
       "      <td>2830.368772</td>\n",
       "      <td>3075.929384</td>\n",
       "      <td>3196.102785</td>\n",
       "      <td>3019.753629</td>\n",
       "      <td>2715.173794</td>\n",
       "      <td>2554.994508</td>\n",
       "      <td>2824.701844</td>\n",
       "      <td>2336.045900</td>\n",
       "      <td>2277.734013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002457</td>\n",
       "      <td>0.276731</td>\n",
       "      <td>0.909609</td>\n",
       "      <td>0.454230</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>0.659161</td>\n",
       "      <td>0.208783</td>\n",
       "      <td>1.100880</td>\n",
       "      <td>-0.082937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500095</td>\n",
       "      <td>125.550345</td>\n",
       "      <td>108.155053</td>\n",
       "      <td>530.117536</td>\n",
       "      <td>161.080763</td>\n",
       "      <td>202.028945</td>\n",
       "      <td>239.250934</td>\n",
       "      <td>332.620979</td>\n",
       "      <td>583.571487</td>\n",
       "      <td>710.769351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>0.187840</td>\n",
       "      <td>0.197881</td>\n",
       "      <td>0.162288</td>\n",
       "      <td>0.025765</td>\n",
       "      <td>0.024353</td>\n",
       "      <td>0.053251</td>\n",
       "      <td>0.013578</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.170738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2074.000000</td>\n",
       "      <td>1955.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1506.000000</td>\n",
       "      <td>845.000000</td>\n",
       "      <td>1783.000000</td>\n",
       "      <td>368.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061761</td>\n",
       "      <td>0.018474</td>\n",
       "      <td>0.465782</td>\n",
       "      <td>0.069760</td>\n",
       "      <td>-0.053829</td>\n",
       "      <td>-0.045752</td>\n",
       "      <td>0.228575</td>\n",
       "      <td>0.160750</td>\n",
       "      <td>1.016740</td>\n",
       "      <td>-0.479484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2753.000000</td>\n",
       "      <td>3030.000000</td>\n",
       "      <td>2794.000000</td>\n",
       "      <td>2954.000000</td>\n",
       "      <td>2662.000000</td>\n",
       "      <td>2381.000000</td>\n",
       "      <td>2723.000000</td>\n",
       "      <td>2026.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011191</td>\n",
       "      <td>0.118426</td>\n",
       "      <td>0.725957</td>\n",
       "      <td>0.310211</td>\n",
       "      <td>-0.009091</td>\n",
       "      <td>-0.011539</td>\n",
       "      <td>0.649343</td>\n",
       "      <td>0.200356</td>\n",
       "      <td>1.067870</td>\n",
       "      <td>-0.221440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2842.000000</td>\n",
       "      <td>3094.000000</td>\n",
       "      <td>2988.000000</td>\n",
       "      <td>3046.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2542.000000</td>\n",
       "      <td>2901.000000</td>\n",
       "      <td>2483.000000</td>\n",
       "      <td>2504.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003021</td>\n",
       "      <td>0.200376</td>\n",
       "      <td>0.977605</td>\n",
       "      <td>0.460124</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.668651</td>\n",
       "      <td>0.209902</td>\n",
       "      <td>1.090760</td>\n",
       "      <td>-0.087077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2924.000000</td>\n",
       "      <td>3143.000000</td>\n",
       "      <td>3954.000000</td>\n",
       "      <td>3126.000000</td>\n",
       "      <td>2844.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>3028.000000</td>\n",
       "      <td>2819.000000</td>\n",
       "      <td>2812.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.445097</td>\n",
       "      <td>1.084480</td>\n",
       "      <td>0.577948</td>\n",
       "      <td>0.022175</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>0.685965</td>\n",
       "      <td>0.218086</td>\n",
       "      <td>1.130530</td>\n",
       "      <td>0.053396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3112.000000</td>\n",
       "      <td>3246.000000</td>\n",
       "      <td>3975.000000</td>\n",
       "      <td>3311.000000</td>\n",
       "      <td>2944.000000</td>\n",
       "      <td>3104.000000</td>\n",
       "      <td>3215.000000</td>\n",
       "      <td>2964.000000</td>\n",
       "      <td>3020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063842</td>\n",
       "      <td>0.659297</td>\n",
       "      <td>1.198030</td>\n",
       "      <td>0.885681</td>\n",
       "      <td>0.106736</td>\n",
       "      <td>0.082056</td>\n",
       "      <td>0.729736</td>\n",
       "      <td>0.242082</td>\n",
       "      <td>1.289330</td>\n",
       "      <td>0.356695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           slipped  ff_biotac_1  ff_biotac_2  ff_biotac_3  ff_biotac_4  \\\n",
       "count  2549.000000  2549.000000  2549.000000  2549.000000  2549.000000   \n",
       "mean      0.501765  2830.368772  3075.929384  3196.102785  3019.753629   \n",
       "std       0.500095   125.550345   108.155053   530.117536   161.080763   \n",
       "min       0.000000  2074.000000  1955.000000  1988.000000  1506.000000   \n",
       "25%       0.000000  2753.000000  3030.000000  2794.000000  2954.000000   \n",
       "50%       1.000000  2842.000000  3094.000000  2988.000000  3046.000000   \n",
       "75%       1.000000  2924.000000  3143.000000  3954.000000  3126.000000   \n",
       "max       1.000000  3112.000000  3246.000000  3975.000000  3311.000000   \n",
       "\n",
       "       ff_biotac_5  ff_biotac_6  ff_biotac_7  ff_biotac_8  ff_biotac_9  \\\n",
       "count  2549.000000  2549.000000  2549.000000  2549.000000  2549.000000   \n",
       "mean   2715.173794  2554.994508  2824.701844  2336.045900  2277.734013   \n",
       "std     202.028945   239.250934   332.620979   583.571487   710.769351   \n",
       "min     845.000000  1783.000000   368.000000   154.000000    98.000000   \n",
       "25%    2662.000000  2381.000000  2723.000000  2026.000000  2018.000000   \n",
       "50%    2771.000000  2542.000000  2901.000000  2483.000000  2504.000000   \n",
       "75%    2844.000000  2748.000000  3028.000000  2819.000000  2812.000000   \n",
       "max    2944.000000  3104.000000  3215.000000  2964.000000  3020.000000   \n",
       "\n",
       "          ...              ffj4         mfj1         mfj2         mfj3  \\\n",
       "count     ...       2549.000000  2549.000000  2549.000000  2549.000000   \n",
       "mean      ...         -0.002457     0.276731     0.909609     0.454230   \n",
       "std       ...          0.015563     0.187840     0.197881     0.162288   \n",
       "min       ...         -0.061761     0.018474     0.465782     0.069760   \n",
       "25%       ...         -0.011191     0.118426     0.725957     0.310211   \n",
       "50%       ...         -0.003021     0.200376     0.977605     0.460124   \n",
       "75%       ...          0.005113     0.445097     1.084480     0.577948   \n",
       "max       ...          0.063842     0.659297     1.198030     0.885681   \n",
       "\n",
       "              mfj4         thj1         thj2         thj3         thj4  \\\n",
       "count  2549.000000  2549.000000  2549.000000  2549.000000  2549.000000   \n",
       "mean      0.007649     0.006226     0.659161     0.208783     1.100880   \n",
       "std       0.025765     0.024353     0.053251     0.013578     0.043669   \n",
       "min      -0.053829    -0.045752     0.228575     0.160750     1.016740   \n",
       "25%      -0.009091    -0.011539     0.649343     0.200356     1.067870   \n",
       "50%       0.001119     0.002227     0.668651     0.209902     1.090760   \n",
       "75%       0.022175     0.016884     0.685965     0.218086     1.130530   \n",
       "max       0.106736     0.082056     0.729736     0.242082     1.289330   \n",
       "\n",
       "              thj5  \n",
       "count  2549.000000  \n",
       "mean     -0.082937  \n",
       "std       0.170738  \n",
       "min      -0.479484  \n",
       "25%      -0.221440  \n",
       "50%      -0.087077  \n",
       "75%       0.053396  \n",
       "max       0.356695  \n",
       "\n",
       "[8 rows x 101 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laying_raw_df = pd.read_csv(LAYING_RAW_DATA_FILE)\n",
    "standing_raw_df = pd.read_csv(STANDING_RAW_DATA_FILE)\n",
    "whole_raw_df = pd.concat([laying_raw_df, standing_raw_df])\n",
    "\n",
    "whole_raw_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa3a2d113d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2QAAAKsCAYAAACDJH6lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa3a2cfba10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole_raw_df['object'].value_counts().plot(kind='bar', figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa3a0caa650>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa3a0cb4ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole_raw_df['slipped'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = whole_raw_df['slipped'].values\n",
    "tactiles = whole_raw_df[['ff_biotac_1', 'ff_biotac_2', 'ff_biotac_3', 'ff_biotac_4', 'ff_biotac_5', \n",
    "                   'ff_biotac_6', 'ff_biotac_7', 'ff_biotac_8', 'ff_biotac_9', 'ff_biotac_10', 'ff_biotac_11', \n",
    "                   'ff_biotac_12', 'ff_biotac_13', 'ff_biotac_14', 'ff_biotac_15', 'ff_biotac_16', 'ff_biotac_17', \n",
    "                   'ff_biotac_18', 'ff_biotac_19', 'ff_biotac_20', 'ff_biotac_21', 'ff_biotac_22', 'ff_biotac_23', \n",
    "                   'ff_biotac_24', 'mf_biotac_1', 'mf_biotac_2', 'mf_biotac_3', 'mf_biotac_4', 'mf_biotac_5', \n",
    "                   'mf_biotac_6', 'mf_biotac_7', 'mf_biotac_8', 'mf_biotac_9', 'mf_biotac_10', 'mf_biotac_11', \n",
    "                   'mf_biotac_12', 'mf_biotac_13', 'mf_biotac_14', 'mf_biotac_15', 'mf_biotac_16', 'mf_biotac_17', \n",
    "                   'mf_biotac_18', 'mf_biotac_19', 'mf_biotac_20', 'mf_biotac_21', 'mf_biotac_22', 'mf_biotac_23', \n",
    "                   'mf_biotac_24', 'th_biotac_1', 'th_biotac_2', 'th_biotac_3', 'th_biotac_4', 'th_biotac_5', \n",
    "                   'th_biotac_6', 'th_biotac_7', 'th_biotac_8', 'th_biotac_9', 'th_biotac_10', 'th_biotac_11', \n",
    "                   'th_biotac_12', 'th_biotac_13', 'th_biotac_14', 'th_biotac_15', 'th_biotac_16', 'th_biotac_17', \n",
    "                   'th_biotac_18', 'th_biotac_19', 'th_biotac_20', 'th_biotac_21', 'th_biotac_22', 'th_biotac_23', \n",
    "                   'th_biotac_24']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2549, 72)\n"
     ]
    }
   ],
   "source": [
    "print tactiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tactiles = (tactiles - np.mean(tactiles)) / (np.std(tactiles))\n",
    "#tactiles = (tactiles - np.min(tactiles)) / (np.max(tactiles) - np.min(tactiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Training fold 1/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 0.01}\n",
      "->accuracy: 87.0588235294\n",
      "->precision: 89.2561983471\n",
      "->recall: 84.375\n",
      "->f1_score: 86.7469879518\n",
      "\n",
      "\n",
      "+ Training fold 2/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 85.8823529412\n",
      "->precision: 88.9830508475\n",
      "->recall: 82.03125\n",
      "->f1_score: 85.3658536585\n",
      "\n",
      "\n",
      "+ Training fold 3/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 0.01}\n",
      "->accuracy: 86.2745098039\n",
      "->precision: 86.0465116279\n",
      "->recall: 86.71875\n",
      "->f1_score: 86.3813229572\n",
      "\n",
      "\n",
      "+ Training fold 4/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 87.8431372549\n",
      "->precision: 88.188976378\n",
      "->recall: 87.5\n",
      "->f1_score: 87.8431372549\n",
      "\n",
      "\n",
      "+ Training fold 5/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 91.3725490196\n",
      "->precision: 91.40625\n",
      "->recall: 91.40625\n",
      "->f1_score: 91.40625\n",
      "\n",
      "\n",
      "+ Training fold 6/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 89.0196078431\n",
      "->precision: 90.3225806452\n",
      "->recall: 87.5\n",
      "->f1_score: 88.8888888889\n",
      "\n",
      "\n",
      "+ Training fold 7/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 88.6274509804\n",
      "->precision: 89.6\n",
      "->recall: 87.5\n",
      "->f1_score: 88.5375494071\n",
      "\n",
      "\n",
      "+ Training fold 8/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 87.8431372549\n",
      "->precision: 90.0826446281\n",
      "->recall: 85.15625\n",
      "->f1_score: 87.5502008032\n",
      "\n",
      "\n",
      "+ Training fold 9/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 92.5490196078\n",
      "->precision: 92.9133858268\n",
      "->recall: 92.1875\n",
      "->f1_score: 92.5490196078\n",
      "\n",
      "\n",
      "+ Training fold 10/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'C': [0.01, 0.1, 1, 10.0, 100.0, 1000.0, 5000.0], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'C': 1, 'gamma': 'auto'}\n",
      "->accuracy: 86.6141732283\n",
      "->precision: 87.8048780488\n",
      "->recall: 85.0393700787\n",
      "->f1_score: 86.4\n",
      "\n",
      "\n",
      "\n",
      "@ Final cross-validation score @\n",
      "88.3084761464 +/- 2.07042681962\n",
      "89.4604476349 +/- 1.8204653423\n",
      "86.9414370079 +/- 2.93159659482\n",
      "88.166921053 +/- 2.16823388143\n"
     ]
    }
   ],
   "source": [
    "folds = 10\n",
    "kfold = StratifiedKFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "cv_accuracy = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1_score = []\n",
    "\n",
    "for index, (train_indices, val_indices) in enumerate(kfold.split(tactiles, labels)):    \n",
    "    print \"+ Training fold \" + str(index + 1) + \"/\" + str(folds)\n",
    "\n",
    "    # split data\n",
    "    tactiles_train, tactiles_val = tactiles[train_indices], tactiles[val_indices]\n",
    "    labels_train, labels_val = labels[train_indices], labels[val_indices]  \n",
    "\n",
    "    # train\n",
    "    param_grid = {'C': [0.01, 0.1, 1, 1e1, 1e2, 1e3, 5e3], 'gamma': ['auto', 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "    svm = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "    \n",
    "    print svm\n",
    "    \n",
    "    svm.fit(tactiles_train, labels_train)\n",
    "    \n",
    "    # evaluate\n",
    "    print \"+ Evaluating cv-fold...\"\n",
    "    \n",
    "    predictions = svm.predict(tactiles_val)\n",
    "    \n",
    "    accuracy = accuracy_score(labels_val, predictions)\n",
    "    [precision, recall, f1_score, _] = precision_recall_fscore_support(labels_val, predictions, average='binary', \n",
    "                                                                       pos_label=1)\n",
    "    cv_accuracy.append(accuracy * 100)\n",
    "    cv_precision.append(precision * 100)\n",
    "    cv_recall.append(recall * 100)\n",
    "    cv_f1_score.append(f1_score * 100)\n",
    "\n",
    "    print svm.best_params_\n",
    "    print \"->accuracy:\", accuracy * 100\n",
    "    print \"->precision:\", precision * 100\n",
    "    print \"->recall:\", recall * 100\n",
    "    print \"->f1_score:\", f1_score * 100\n",
    "    print \"\\n\"\n",
    "\n",
    "print \"\\n@ Final cross-validation score @\"\n",
    "print np.mean(cv_accuracy), \"+/-\", np.std(cv_accuracy)\n",
    "print np.mean(cv_precision), \"+/-\", np.std(cv_precision)\n",
    "print np.mean(cv_recall), \"+/-\", np.std(cv_recall)\n",
    "print np.mean(cv_f1_score), \"+/-\", np.std(cv_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Training fold 1/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_estimators': 150, 'max_depth': 20}\n",
      "->accuracy: 92.9411764706\n",
      "->precision: 92.96875\n",
      "->recall: 92.96875\n",
      "->f1_score: 92.96875\n",
      "\n",
      "\n",
      "+ Training fold 2/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_estimators': 100, 'max_depth': 15}\n",
      "->accuracy: 95.6862745098\n",
      "->precision: 98.347107438\n",
      "->recall: 92.96875\n",
      "->f1_score: 95.5823293173\n",
      "\n",
      "\n",
      "+ Training fold 3/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_estimators': 150, 'max_depth': 15}\n",
      "->accuracy: 90.5882352941\n",
      "->precision: 90.625\n",
      "->recall: 90.625\n",
      "->f1_score: 90.625\n",
      "\n",
      "\n",
      "+ Training fold 4/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_estimators': 50, 'max_depth': 10}\n",
      "->accuracy: 92.9411764706\n",
      "->precision: 91.0447761194\n",
      "->recall: 95.3125\n",
      "->f1_score: 93.1297709924\n",
      "\n",
      "\n",
      "+ Training fold 5/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_estimators': 150, 'max_depth': 10}\n",
      "->accuracy: 92.1568627451\n",
      "->precision: 90.9090909091\n",
      "->recall: 93.75\n",
      "->f1_score: 92.3076923077\n",
      "\n",
      "\n",
      "+ Training fold 6/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_estimators': 50, 'max_depth': 30}\n",
      "->accuracy: 92.1568627451\n",
      "->precision: 96.5517241379\n",
      "->recall: 87.5\n",
      "->f1_score: 91.8032786885\n",
      "\n",
      "\n",
      "+ Training fold 7/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_estimators': 100, 'max_depth': 20}\n",
      "->accuracy: 93.3333333333\n",
      "->precision: 95.1219512195\n",
      "->recall: 91.40625\n",
      "->f1_score: 93.2270916335\n",
      "\n",
      "\n",
      "+ Training fold 8/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_estimators': 100, 'max_depth': None}\n",
      "->accuracy: 91.7647058824\n",
      "->precision: 93.4959349593\n",
      "->recall: 89.84375\n",
      "->f1_score: 91.6334661355\n",
      "\n",
      "\n",
      "+ Training fold 9/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_estimators': 200, 'max_depth': 10}\n",
      "->accuracy: 90.5882352941\n",
      "->precision: 91.935483871\n",
      "->recall: 89.0625\n",
      "->f1_score: 90.4761904762\n",
      "\n",
      "\n",
      "+ Training fold 10/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Evaluating cv-fold...\n",
      "{'n_estimators': 200, 'max_depth': 25}\n",
      "->accuracy: 94.4881889764\n",
      "->precision: 95.2\n",
      "->recall: 93.7007874016\n",
      "->f1_score: 94.4444444444\n",
      "\n",
      "\n",
      "\n",
      "@ Final cross-validation score @\n",
      "92.6645051721 +/- 1.51671260673\n",
      "93.6199818654 +/- 2.48838809341\n",
      "91.7138287402 +/- 2.31856273661\n",
      "92.6198013995 +/- 1.52209751772\n"
     ]
    }
   ],
   "source": [
    "folds = 10\n",
    "kfold = StratifiedKFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "cv_accuracy = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1_score = []\n",
    "\n",
    "for index, (train_indices, val_indices) in enumerate(kfold.split(tactiles, labels)):    \n",
    "    print \"+ Training fold \" + str(index + 1) + \"/\" + str(folds)\n",
    "\n",
    "    # split data\n",
    "    tactiles_train, tactiles_val = tactiles[train_indices], tactiles[val_indices]\n",
    "    labels_train, labels_val = labels[train_indices], labels[val_indices]  \n",
    "\n",
    "    # train\n",
    "    param_grid = {'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [None, 5, 10, 15, 20, 25, 30]}\n",
    "    rf = GridSearchCV(RandomForestClassifier(oob_score=False), param_grid)\n",
    "    \n",
    "    print rf\n",
    "    \n",
    "    rf.fit(tactiles_train, labels_train)\n",
    "    \n",
    "    # evaluate\n",
    "    print \"+ Evaluating cv-fold...\"\n",
    "    \n",
    "    predictions = rf.predict(tactiles_val)\n",
    "    \n",
    "    accuracy = accuracy_score(labels_val, predictions)\n",
    "    [precision, recall, f1_score, _] = precision_recall_fscore_support(labels_val, predictions, average='binary', \n",
    "                                                                       pos_label=1)\n",
    "    cv_accuracy.append(accuracy * 100)\n",
    "    cv_precision.append(precision * 100)\n",
    "    cv_recall.append(recall * 100)\n",
    "    cv_f1_score.append(f1_score * 100)\n",
    "\n",
    "    print rf.best_params_\n",
    "    print \"->accuracy:\", accuracy * 100\n",
    "    print \"->precision:\", precision * 100\n",
    "    print \"->recall:\", recall * 100\n",
    "    print \"->f1_score:\", f1_score * 100\n",
    "    print \"\\n\"\n",
    "\n",
    "print \"\\n@ Final cross-validation score @\"\n",
    "print np.mean(cv_accuracy), \"+/-\", np.std(cv_accuracy)\n",
    "print np.mean(cv_precision), \"+/-\", np.std(cv_precision)\n",
    "print np.mean(cv_recall), \"+/-\", np.std(cv_recall)\n",
    "print np.mean(cv_f1_score), \"+/-\", np.std(cv_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Training fold 1/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 11}\n",
      "->accuracy: 85.8823529412\n",
      "->precision: 82.3943661972\n",
      "->recall: 91.40625\n",
      "->f1_score: 86.6666666667\n",
      "\n",
      "\n",
      "+ Training fold 2/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 3}\n",
      "->accuracy: 90.9803921569\n",
      "->precision: 87.2340425532\n",
      "->recall: 96.09375\n",
      "->f1_score: 91.4498141264\n",
      "\n",
      "\n",
      "+ Training fold 3/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 11}\n",
      "->accuracy: 91.3725490196\n",
      "->precision: 88.9705882353\n",
      "->recall: 94.53125\n",
      "->f1_score: 91.6666666667\n",
      "\n",
      "\n",
      "+ Training fold 4/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 13}\n",
      "->accuracy: 83.9215686275\n",
      "->precision: 81.7518248175\n",
      "->recall: 87.5\n",
      "->f1_score: 84.5283018868\n",
      "\n",
      "\n",
      "+ Training fold 5/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 11}\n",
      "->accuracy: 90.5882352941\n",
      "->precision: 86.6197183099\n",
      "->recall: 96.09375\n",
      "->f1_score: 91.1111111111\n",
      "\n",
      "\n",
      "+ Training fold 6/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 5}\n",
      "->accuracy: 88.6274509804\n",
      "->precision: 85.6115107914\n",
      "->recall: 92.96875\n",
      "->f1_score: 89.138576779\n",
      "\n",
      "\n",
      "+ Training fold 7/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 9}\n",
      "->accuracy: 87.8431372549\n",
      "->precision: 85.9259259259\n",
      "->recall: 90.625\n",
      "->f1_score: 88.2129277567\n",
      "\n",
      "\n",
      "+ Training fold 8/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 11}\n",
      "->accuracy: 84.3137254902\n",
      "->precision: 80.5555555556\n",
      "->recall: 90.625\n",
      "->f1_score: 85.2941176471\n",
      "\n",
      "\n",
      "+ Training fold 9/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 11}\n",
      "->accuracy: 87.0588235294\n",
      "->precision: 84.1726618705\n",
      "->recall: 91.40625\n",
      "->f1_score: 87.6404494382\n",
      "\n",
      "\n",
      "+ Training fold 10/10\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "+ Evaluating cv-fold...\n",
      "{'n_neighbors': 5}\n",
      "->accuracy: 88.5826771654\n",
      "->precision: 87.1212121212\n",
      "->recall: 90.5511811024\n",
      "->f1_score: 88.8030888031\n",
      "\n",
      "\n",
      "\n",
      "@ Final cross-validation score @\n",
      "87.9170912459 +/- 2.51470327058\n",
      "85.0357406378 +/- 2.58603170896\n",
      "92.1801181102 +/- 2.59565522049\n",
      "88.4511720882 +/- 2.37186214152\n"
     ]
    }
   ],
   "source": [
    "folds = 10\n",
    "kfold = StratifiedKFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "cv_accuracy = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1_score = []\n",
    "\n",
    "for index, (train_indices, val_indices) in enumerate(kfold.split(tactiles, labels)):    \n",
    "    print \"+ Training fold \" + str(index + 1) + \"/\" + str(folds)\n",
    "\n",
    "    # split data\n",
    "    tactiles_train, tactiles_val = tactiles[train_indices], tactiles[val_indices]\n",
    "    labels_train, labels_val = labels[train_indices], labels[val_indices]  \n",
    "\n",
    "    # train\n",
    "    param_grid = {'n_neighbors' : [1, 3, 5, 7, 9, 11, 13], }\n",
    "    neigh = GridSearchCV(KNeighborsClassifier(), param_grid)\n",
    "    \n",
    "    print neigh\n",
    "    \n",
    "    neigh.fit(tactiles_train, labels_train)\n",
    "    \n",
    "    # evaluate\n",
    "    print \"+ Evaluating cv-fold...\"\n",
    "    \n",
    "    predictions = neigh.predict(tactiles_val)\n",
    "    \n",
    "    accuracy = accuracy_score(labels_val, predictions)\n",
    "    [precision, recall, f1_score, _] = precision_recall_fscore_support(labels_val, predictions, average='binary', \n",
    "                                                                       pos_label=1)\n",
    "    cv_accuracy.append(accuracy * 100)\n",
    "    cv_precision.append(precision * 100)\n",
    "    cv_recall.append(recall * 100)\n",
    "    cv_f1_score.append(f1_score * 100)\n",
    "    \n",
    "    print neigh.best_params_\n",
    "    print \"->accuracy:\", accuracy * 100\n",
    "    print \"->precision:\", precision * 100\n",
    "    print \"->recall:\", recall * 100\n",
    "    print \"->f1_score:\", f1_score * 100\n",
    "    print \"\\n\"\n",
    "\n",
    "print \"\\n@ Final cross-validation score @\"\n",
    "print np.mean(cv_accuracy), \"+/-\", np.std(cv_accuracy)\n",
    "print np.mean(cv_precision), \"+/-\", np.std(cv_precision)\n",
    "print np.mean(cv_recall), \"+/-\", np.std(cv_recall)\n",
    "print np.mean(cv_f1_score), \"+/-\", np.std(cv_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
